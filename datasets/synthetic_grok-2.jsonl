{"query_id":"synthetic-001","query_text":"Write a Python function named `binary_search` that implements binary search on a sorted list. The function should return the index of the target element if found, or -1 if not found. Handle edge cases like empty lists and single element lists. Language: Python. Function name: binary_search","reference_answer":"def binary_search(arr, target):\n    if not arr:\n        return -1\n    \n    left, right = 0, len(arr) - 1\n    \n    while left <= right:\n        mid = left + (right - left) // 2\n        \n        if arr[mid] == target:\n            return mid\n        elif arr[mid] < target:\n            left = mid + 1\n        else:\n            right = mid - 1\n    \n    return -1","assertions":"assert binary_search([], 5) == -1\nassert binary_search([1], 1) == 0\nassert binary_search([1], 2) == -1\nassert binary_search([1, 2, 3, 4, 5], 3) == 2\nassert binary_search([1, 2, 3, 4, 5], 6) == -1\nassert binary_search([1, 3, 5, 7, 9], 7) == 3","metadata":{"language":"Python","function_name":"binary_search","difficulty":"medium","category":"algorithms","complexity":0.4}}
{"query_id":"synthetic-002","query_text":"Write a Python function named `merge_sort` that implements the merge sort algorithm to sort a list of integers in ascending order. The function should use a recursive approach and return a new sorted list without modifying the original. Language: Python. Function name: merge_sort","reference_answer":"def merge_sort(arr):\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left = merge_sort(arr[:mid])\n    right = merge_sort(arr[mid:])\n    \n    return merge(left, right)\n\ndef merge(left, right):\n    result = []\n    i = j = 0\n    \n    while i < len(left) and j < len(right):\n        if left[i] <= right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n    \n    result.extend(left[i:])\n    result.extend(right[j:])\n    return result","assertions":"assert merge_sort([]) == []\nassert merge_sort([1]) == [1]\nassert merge_sort([3, 1, 4, 1, 5]) == [1, 1, 3, 4, 5]\nassert merge_sort([5, 4, 3, 2, 1]) == [1, 2, 3, 4, 5]\nassert merge_sort([1, 3, 2, 5, 4]) == [1, 2, 3, 4, 5]","metadata":{"language":"Python","function_name":"merge_sort","difficulty":"medium","category":"algorithms","complexity":0.45}}
{"query_id":"synthetic-003","query_text":"Write a Python function named `is_valid_parentheses` that checks if a string containing only parentheses characters '(', ')', '{', '}', '[', ']' is valid. A string is valid if all brackets are properly closed and nested. Language: Python. Function name: is_valid_parentheses","reference_answer":"def is_valid_parentheses(s):\n    stack = []\n    bracket_map = {')': '(', '}': '{', ']': '['}\n    \n    for char in s:\n        if char in bracket_map:\n            top_element = stack.pop() if stack else '#'\n            if bracket_map[char] != top_element:\n                return False\n        else:\n            stack.append(char)\n    \n    return not stack","assertions":"assert is_valid_parentheses(\"\") == True\nassert is_valid_parentheses(\"()\") == True\nassert is_valid_parentheses(\"()[]{}\") == True\nassert is_valid_parentheses(\"(]\") == False\nassert is_valid_parentheses(\"([)]\") == False\nassert is_valid_parentheses(\"{[]}\") == True\nassert is_valid_parentheses(\"[\") == False\nassert is_valid_parentheses(\"]\") == False","metadata":{"language":"Python","function_name":"is_valid_parentheses","difficulty":"medium","category":"data_structures","complexity":0.4}}
{"query_id":"synthetic-004","query_text":"Write a Python function named `fibonacci_memo` that calculates the nth Fibonacci number using memoization to optimize performance. The function should handle large n values efficiently and return the result. Language: Python. Function name: fibonacci_memo","reference_answer":"def fibonacci_memo(n):\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    \n    memo = {}\n    \n    def fib(k):\n        if k in memo:\n            return memo[k]\n        if k <= 1:\n            return k\n        memo[k] = fib(k - 1) + fib(k - 2)\n        return memo[k]\n    \n    return fib(n)","assertions":"assert fibonacci_memo(0) == 0\nassert fibonacci_memo(1) == 1\nassert fibonacci_memo(2) == 1\nassert fibonacci_memo(5) == 5\nassert fibonacci_memo(10) == 55\nassert fibonacci_memo(20) == 6765","metadata":{"language":"Python","function_name":"fibonacci_memo","difficulty":"medium","category":"algorithms","complexity":0.45}}
{"query_id":"synthetic-005","query_text":"Write a Python function named `reverse_linked_list` that reverses a singly linked list. The function should take the head of the linked list as input and return the new head of the reversed list. You can assume a Node class with val and next attributes. Language: Python. Function name: reverse_linked_list","reference_answer":"class Node:\n    def __init__(self, val=0, next=None):\n        self.val = val\n        self.next = next\n\ndef reverse_linked_list(head):\n    prev = None\n    current = head\n    \n    while current:\n        next_node = current.next\n        current.next = prev\n        prev = current\n        current = next_node\n    \n    return prev","assertions":"def list_to_linked_list(arr):\n    if not arr:\n        return None\n    head = Node(arr[0])\n    current = head\n    for val in arr[1:]:\n        current.next = Node(val)\n        current = current.next\n    return head\n\ndef linked_list_to_list(head):\n    result = []\n    current = head\n    while current:\n        result.append(current.val)\n        current = current.next\n    return result\n\nassert linked_list_to_list(reverse_linked_list(list_to_linked_list([]))) == []\nassert linked_list_to_list(reverse_linked_list(list_to_linked_list([1]))) == [1]\nassert linked_list_to_list(reverse_linked_list(list_to_linked_list([1, 2, 3]))) == [3, 2, 1]\nassert linked_list_to_list(reverse_linked_list(list_to_linked_list([1, 2, 3, 4, 5]))) == [5, 4, 3, 2, 1]","metadata":{"language":"Python","function_name":"reverse_linked_list","difficulty":"medium","category":"data_structures","complexity":0.5}}
{"query_id":"synthetic-006","query_text":"Write a Python function named `word_frequency` that takes a string of text and returns a dictionary with word frequencies, ignoring case and punctuation. Words should be normalized to lowercase and punctuation should be removed. Language: Python. Function name: word_frequency","reference_answer":"import re\n\ndef word_frequency(text):\n    if not text:\n        return {}\n    \n    # Remove punctuation and convert to lowercase\n    cleaned_text = re.sub(r'[^\\w\\s]', '', text.lower())\n    \n    # Split into words and count\n    words = cleaned_text.split()\n    frequency = {}\n    \n    for word in words:\n        frequency[word] = frequency.get(word, 0) + 1\n    \n    return frequency","assertions":"assert word_frequency(\"\") == {}\nassert word_frequency(\"hello world\") == {\"hello\": 1, \"world\": 1}\nassert word_frequency(\"Hello, hello!\") == {\"hello\": 2}\nassert word_frequency(\"The quick brown fox jumps over the lazy dog.\") == {\"the\": 2, \"quick\": 1, \"brown\": 1, \"fox\": 1, \"jumps\": 1, \"over\": 1, \"lazy\": 1, \"dog\": 1}\nassert word_frequency(\"test, test. TEST!\") == {\"test\": 3}","metadata":{"language":"Python","function_name":"word_frequency","difficulty":"medium","category":"algorithms","complexity":0.4}}
{"query_id":"synthetic-007","query_text":"Write a Python function named `async_download` that downloads multiple URLs concurrently using asyncio and aiohttp. The function should take a list of URLs and return a list of responses or error messages. Handle timeouts and connection errors gracefully. Language: Python. Function name: async_download","reference_answer":"import asyncio\nimport aiohttp\nfrom typing import List, Union\n\nasync def async_download(urls: List[str], timeout: float = 10.0) -> List[Union[str, Exception]]:\n    async def download_single(url: str) -> Union[str, Exception]:\n        try:\n            async with aiohttp.ClientSession() as session:\n                async with session.get(url, timeout=aiohttp.ClientTimeout(total=timeout)) as response:\n                    if response.status == 200:\n                        return await response.text()\n                    else:\n                        return Exception(f\"HTTP {response.status}\")\n        except Exception as e:\n            return e\n    \n    tasks = [download_single(url) for url in urls]\n    return await asyncio.gather(*tasks, return_exceptions=True)","assertions":"import asyncio\n\nasync def test_downloads():\n    # Mock URLs that will fail\n    urls = [\"http://invalid-url-12345.com\", \"http://another-invalid-url.com\"]\n    results = await async_download(urls, timeout=1.0)\n    \n    # All results should be exceptions\n    assert all(isinstance(r, Exception) for r in results)\n    assert len(results) == 2\n\nasyncio.run(test_downloads())","metadata":{"language":"Python","function_name":"async_download","difficulty":"advanced","category":"concurrency","complexity":0.65}}
{"query_id":"synthetic-008","query_text":"Write a Python function named `knapsack_01` that solves the 0/1 knapsack problem using dynamic programming. Given weights, values, and capacity, return the maximum value that can be achieved without exceeding capacity. Language: Python. Function name: knapsack_01","reference_answer":"def knapsack_01(weights, values, capacity):\n    n = len(weights)\n    if n == 0 or capacity == 0:\n        return 0\n    \n    # Initialize DP table\n    dp = [[0 for _ in range(capacity + 1)] for _ in range(n + 1)]\n    \n    # Fill DP table\n    for i in range(1, n + 1):\n        for w in range(1, capacity + 1):\n            if weights[i-1] <= w:\n                dp[i][w] = max(dp[i-1][w], dp[i-1][w - weights[i-1]] + values[i-1])\n            else:\n                dp[i][w] = dp[i-1][w]\n    \n    return dp[n][capacity]","assertions":"assert knapsack_01([], [], 10) == 0\nassert knapsack_01([1], [1], 0) == 0\nassert knapsack_01([1, 2, 3], [6, 10, 12], 5) == 22\nassert knapsack_01([2, 3, 4], [3, 4, 5], 6) == 7\nassert knapsack_01([1, 1, 1], [1, 2, 3], 2) == 4","metadata":{"language":"Python","function_name":"knapsack_01","difficulty":"advanced","category":"algorithms","complexity":0.7}}
{"query_id":"synthetic-009","query_text":"Write a Python function named `implement_lru_cache` that implements an LRU (Least Recently Used) cache with get and put operations. The cache should have a maximum capacity and evict the least recently used item when full. Language: Python. Function name: implement_lru_cache","reference_answer":"from collections import OrderedDict\n\nclass LRUCache:\n    def __init__(self, capacity: int):\n        self.capacity = capacity\n        self.cache = OrderedDict()\n    \n    def get(self, key: int) -> int:\n        if key not in self.cache:\n            return -1\n        # Move to end (most recently used)\n        self.cache.move_to_end(key)\n        return self.cache[key]\n    \n    def put(self, key: int, value: int) -> None:\n        if key in self.cache:\n            # Update existing key\n            self.cache.move_to_end(key)\n        elif len(self.cache) >= self.capacity:\n            # Remove least recently used\n            self.cache.popitem(last=False)\n        \n        self.cache[key] = value\n\ndef implement_lru_cache(capacity):\n    return LRUCache(capacity)","assertions":"cache = implement_lru_cache(2)\ncache.put(1, 1)\ncache.put(2, 2)\nassert cache.get(1) == 1\ncache.put(3, 3)  # evicts key 2\nassert cache.get(2) == -1\ncache.put(4, 4)  # evicts key 1\nassert cache.get(1) == -1\nassert cache.get(3) == 3\nassert cache.get(4) == 4","metadata":{"language":"Python","function_name":"implement_lru_cache","difficulty":"advanced","category":"data_structures","complexity":0.65}}
{"query_id":"synthetic-010","query_text":"Write a Python function named `find_median_sorted_arrays` that finds the median of two sorted arrays using a binary search approach. The function should run in O(log(min(n,m))) time and handle edge cases. Language: Python. Function name: find_median_sorted_arrays","reference_answer":"def find_median_sorted_arrays(nums1, nums2):\n    if len(nums1) > len(nums2):\n        nums1, nums2 = nums2, nums1\n    \n    m, n = len(nums1), len(nums2)\n    total = m + n\n    half = (total + 1) // 2\n    \n    left, right = 0, m\n    \n    while left <= right:\n        i = (left + right) // 2\n        j = half - i\n        \n        nums1_left = float('-inf') if i == 0 else nums1[i-1]\n        nums1_right = float('inf') if i == m else nums1[i]\n        nums2_left = float('-inf') if j == 0 else nums2[j-1]\n        nums2_right = float('inf') if j == n else nums2[j]\n        \n        if nums1_left <= nums2_right and nums2_left <= nums1_right:\n            if total % 2 == 1:\n                return max(nums1_left, nums2_left)\n            else:\n                return (max(nums1_left, nums2_left) + min(nums1_right, nums2_right)) / 2\n        elif nums1_left > nums2_right:\n            right = i - 1\n        else:\n            left = i + 1\n    \n    raise ValueError(\"Input arrays are not sorted\")","assertions":"assert find_median_sorted_arrays([1, 3], [2]) == 2.0\nassert find_median_sorted_arrays([1, 2], [3, 4]) == 2.5\nassert find_median_sorted_arrays([0, 0], [0, 0]) == 0.0\nassert find_median_sorted_arrays([], [1]) == 1.0\nassert find_median_sorted_arrays([2], []) == 2.0","metadata":{"language":"Python","function_name":"find_median_sorted_arrays","difficulty":"advanced","category":"algorithms","complexity":0.75}}
{"query_id":"synthetic-011","query_text":"Write a Python function named `parallel_matrix_multiply` that multiplies two matrices using concurrent.futures for parallel computation across multiple CPU cores. Handle matrix dimension validation and return the result matrix. Language: Python. Function name: parallel_matrix_multiply","reference_answer":"import concurrent.futures\nimport numpy as np\n\ndef parallel_matrix_multiply(A, B):\n    # Validate dimensions\n    if not A or not B or not A[0] or not B[0]:\n        raise ValueError(\"Empty matrices not allowed\")\n    \n    rows_A, cols_A = len(A), len(A[0])\n    rows_B, cols_B = len(B), len(B[0])\n    \n    if cols_A != rows_B:\n        raise ValueError(\"Matrix dimensions incompatible\")\n    \n    # Initialize result matrix\n    result = [[0 for _ in range(cols_B)] for _ in range(rows_A)]\n    \n    def compute_element(i, j):\n        return sum(A[i][k] * B[k][j] for k in range(cols_A))\n    \n    # Parallel computation\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        futures = []\n        for i in range(rows_A):\n            for j in range(cols_B):\n                futures.append(executor.submit(compute_element, i, j))\n        \n        # Collect results\n        idx = 0\n        for i in range(rows_A):\n            for j in range(cols_B):\n                result[i][j] = futures[idx].result()\n                idx += 1\n    \n    return result","assertions":"result = parallel_matrix_multiply([[1, 2], [3, 4]], [[5, 6], [7, 8]])\nexpected = [[19, 22], [43, 50]]\nassert result == expected\n\n# Test dimension validation\ntry:\n    parallel_matrix_multiply([[1, 2]], [[1], [2], [3]])\n    assert False, \"Should raise ValueError\"\nexcept ValueError:\n    pass","metadata":{"language":"Python","function_name":"parallel_matrix_multiply","difficulty":"advanced","category":"concurrency","complexity":0.7}}
{"query_id":"synthetic-012","query_text":"Write a Python function named `implement_trie` that implements a Trie (prefix tree) data structure with insert and search operations. The Trie should support exact word search and prefix search. Language: Python. Function name: implement_trie","reference_answer":"class TrieNode:\n    def __init__(self):\n        self.children = {}\n        self.is_end_of_word = False\n\nclass Trie:\n    def __init__(self):\n        self.root = TrieNode()\n    \n    def insert(self, word: str) -> None:\n        node = self.root\n        for char in word:\n            if char not in node.children:\n                node.children[char] = TrieNode()\n            node = node.children[char]\n        node.is_end_of_word = True\n    \n    def search(self, word: str) -> bool:\n        node = self.root\n        for char in word:\n            if char not in node.children:\n                return False\n            node = node.children[char]\n        return node.is_end_of_word\n    \n    def starts_with(self, prefix: str) -> bool:\n        node = self.root\n        for char in prefix:\n            if char not in node.children:\n                return False\n            node = node.children[char]\n        return True\n\ndef implement_trie():\n    return Trie()","assertions":"trie = implement_trie()\ntrie.insert(\"apple\")\nassert trie.search(\"apple\") == True\nassert trie.search(\"app\") == False\nassert trie.starts_with(\"app\") == True\ntrie.insert(\"app\")\nassert trie.search(\"app\") == True","metadata":{"language":"Python","function_name":"implement_trie","difficulty":"advanced","category":"data_structures","complexity":0.6}}
{"query_id":"synthetic-013","query_text":"Write a Python function named `longest_common_subsequence` that finds the length of the longest common subsequence between two strings using dynamic programming. The function should return the length of the LCS. Language: Python. Function name: longest_common_subsequence","reference_answer":"def longest_common_subsequence(text1: str, text2: str) -> int:\n    m, n = len(text1), len(text2)\n    if m == 0 or n == 0:\n        return 0\n    \n    # Initialize DP table\n    dp = [[0] * (n + 1) for _ in range(m + 1)]\n    \n    # Fill DP table\n    for i in range(1, m + 1):\n        for j in range(1, n + 1):\n            if text1[i-1] == text2[j-1]:\n                dp[i][j] = dp[i-1][j-1] + 1\n            else:\n                dp[i][j] = max(dp[i-1][j], dp[i][j-1])\n    \n    return dp[m][n]","assertions":"assert longest_common_subsequence(\"\", \"\") == 0\nassert longest_common_subsequence(\"abc\", \"\") == 0\nassert longest_common_subsequence(\"abc\", \"abc\") == 3\nassert longest_common_subsequence(\"abc\", \"def\") == 0\nassert longest_common_subsequence(\"abcde\", \"ace\") == 3\nassert longest_common_subsequence(\"AGGTAB\", \"GXTXAYB\") == 4","metadata":{"language":"Python","function_name":"longest_common_subsequence","difficulty":"advanced","category":"algorithms","complexity":0.7}}
{"query_id":"synthetic-014","query_text":"Write a Python function named `async_file_processor` that processes multiple files concurrently using asyncio. The function should read files, apply a transformation function to each, and write results to new files. Handle file I/O errors gracefully. Language: Python. Function name: async_file_processor","reference_answer":"import asyncio\nimport aiofiles\nimport os\nfrom typing import List, Callable, Any\nfrom pathlib import Path\n\nasync def async_file_processor(\n    file_paths: List[str], \n    transform_func: Callable[[str], str],\n    output_dir: str = \"output\"\n) -> List[str]:\n    \n    async def process_file(file_path: str) -> str:\n        try:\n            async with aiofiles.open(file_path, 'r') as f:\n                content = await f.read()\n            \n            transformed = transform_func(content)\n            \n            output_path = os.path.join(output_dir, os.path.basename(file_path))\n            os.makedirs(output_dir, exist_ok=True)\n            \n            async with aiofiles.open(output_path, 'w') as f:\n                await f.write(transformed)\n            \n            return output_path\n        except Exception as e:\n            return f\"Error processing {file_path}: {str(e)}\"\n    \n    # Create tasks for all files\n    tasks = [process_file(fp) for fp in file_paths]\n    results = await asyncio.gather(*tasks, return_exceptions=True)\n    \n    # Filter out exceptions and return successful results\n    return [r for r in results if isinstance(r, str) and not r.startswith(\"Error\")]","assertions":"import tempfile\nimport os\n\nasync def test_processor():\n    # Create temporary files\n    with tempfile.TemporaryDirectory() as tmpdir:\n        # Create test files\n        file1 = os.path.join(tmpdir, \"test1.txt\")\n        file2 = os.path.join(tmpdir, \"test2.txt\")\n        \n        with open(file1, 'w') as f:\n            f.write(\"hello world\")\n        with open(file2, 'w') as f:\n            f.write(\"foo bar\")\n        \n        # Process files\n        results = await async_file_processor(\n            [file1, file2],\n            lambda x: x.upper(),\n            os.path.join(tmpdir, \"output\")\n        )\n        \n        assert len(results) == 2\n        \n        # Check output files\n        with open(os.path.join(tmpdir, \"output\", \"test1.txt\"), 'r') as f:\n            assert f.read() == \"HELLO WORLD\"\n        \n        with open(os.path.join(tmpdir, \"output\", \"test2.txt\"), 'r') as f:\n            assert f.read() == \"FOO BAR\"\n\nasyncio.run(test_processor())","metadata":{"language":"Python","function_name":"async_file_processor","difficulty":"advanced","category":"concurrency","complexity":0.7}}
{"query_id":"synthetic-015","query_text":"Write a Python function named `red_black_tree_insert` that implements insertion into a Red-Black Tree. The function should maintain all Red-Black Tree properties and return the root of the tree. Language: Python. Function name: red_black_tree_insert","reference_answer":"class RBNode:\n    def __init__(self, key, color=\"red\", left=None, right=None, parent=None):\n        self.key = key\n        self.color = color\n        self.left = left\n        self.right = right\n        self.parent = parent\n\nclass RedBlackTree:\n    def __init__(self):\n        self.NIL = RBNode(None, \"black\")\n        self.root = self.NIL\n    \n    def insert(self, key):\n        new_node = RBNode(key, \"red\", self.NIL, self.NIL, self.NIL)\n        \n        parent = None\n        current = self.root\n        \n        while current != self.NIL:\n            parent = current\n            if new_node.key < current.key:\n                current = current.left\n            else:\n                current = current.right\n        \n        new_node.parent = parent\n        \n        if parent is None:\n            self.root = new_node\n        elif new_node.key < parent.key:\n            parent.left = new_node\n        else:\n            parent.right = new_node\n        \n        if new_node.parent is None:\n            new_node.color = \"black\"\n            return\n        \n        if new_node.parent.parent is None:\n            return\n        \n        self._fix_insert(new_node)\n    \n    def _fix_insert(self, k):\n        while k.parent.color == \"red\":\n            if k.parent == k.parent.parent.right:\n                u = k.parent.parent.left\n                if u.color == \"red\":\n                    u.color = \"black\"\n                    k.parent.color = \"black\"\n                    k.parent.parent.color = \"red\"\n                    k = k.parent.parent\n                else:\n                    if k == k.parent.left:\n                        k = k.parent\n                        self._right_rotate(k)\n                    k.parent.color = \"black\"\n                    k.parent.parent.color = \"red\"\n                    self._left_rotate(k.parent.parent)\n            else:\n                u = k.parent.parent.right\n                if u.color == \"red\":\n                    u.color = \"black\"\n                    k.parent.color = \"black\"\n                    k.parent.parent.color = \"red\"\n                    k = k.parent.parent\n                else:\n                    if k == k.parent.right:\n                        k = k.parent\n                        self._left_rotate(k)\n                    k.parent.color = \"black\"\n                    k.parent.parent.color = \"red\"\n                    self._right_rotate(k.parent.parent)\n            \n            if k == self.root:\n                break\n        \n        self.root.color = \"black\"\n    \n    def _left_rotate(self, x):\n        y = x.right\n        x.right = y.left\n        if y.left != self.NIL:\n            y.left.parent = x\n        y.parent = x.parent\n        if x.parent is None:\n            self.root = y\n        elif x == x.parent.left:\n            x.parent.left = y\n        else:\n            x.parent.right = y\n        y.left = x\n        x.parent = y\n    \n    def _right_rotate(self, x):\n        y = x.left\n        x.left = y.right\n        if y.right != self.NIL:\n            y.right.parent = x\n        y.parent = x.parent\n        if x.parent is None:\n            self.root = y\n        elif x == x.parent.right:\n            x.parent.right = y\n        else:\n            x.parent.left = y\n        y.right = x\n        x.parent = y\n\ndef red_black_tree_insert(root, key):\n    if not hasattr(root, 'insert'):\n        tree = RedBlackTree()\n        tree.insert(key)\n        return tree\n    else:\n        root.insert(key)\n        return root","assertions":"tree = red_black_tree_insert(None, 10)\nred_black_tree_insert(tree, 20)\nred_black_tree_insert(tree, 30)\nred_black_tree_insert(tree, 15)\nred_black_tree_insert(tree, 25)\n\n# Verify basic structure (this is a simplified check)\ndef inorder_traversal(node, result):\n    if node and node.key is not None:\n        inorder_traversal(node.left, result)\n        result.append(node.key)\n        inorder_traversal(node.right, result)\n\nresult = []\ninorder_traversal(tree.root, result)\nassert result == [10, 15, 20, 25, 30]","metadata":{"language":"Python","function_name":"red_black_tree_insert","difficulty":"very_advanced","category":"data_structures","complexity":0.9}}
{"query_id":"synthetic-016","query_text":"Write a Python function named `distributed_cache` that implements a distributed LRU cache using Redis as the backend. The cache should support get, set, and delete operations with proper TTL handling and connection pooling. Language: Python. Function name: distributed_cache","reference_answer":"import redis\nimport json\nfrom typing import Any, Optional\n\nclass DistributedCache:\n    def __init__(self, host: str = \"localhost\", port: int = 6379, db: int = 0, max_connections: int = 10):\n        self.pool = redis.ConnectionPool(\n            host=host, port=port, db=db, max_connections=max_connections,\n            decode_responses=True\n        )\n        self.redis = redis.Redis(connection_pool=self.pool)\n    \n    def get(self, key: str) -> Optional[Any]:\n        try:\n            value = self.redis.get(key)\n            return json.loads(value) if value else None\n        except Exception:\n            return None\n    \n    def set(self, key: str, value: Any, ttl_seconds: Optional[int] = None) -> bool:\n        try:\n            json_value = json.dumps(value)\n            if ttl_seconds:\n                return bool(self.redis.setex(key, ttl_seconds, json_value))\n            else:\n                return bool(self.redis.set(key, json_value))\n        except Exception:\n            return False\n    \n    def delete(self, key: str) -> bool:\n        try:\n            return bool(self.redis.delete(key))\n        except Exception:\n            return False\n    \n    def exists(self, key: str) -> bool:\n        try:\n            return bool(self.redis.exists(key))\n        except Exception:\n            return False\n\ndef distributed_cache(host=\"localhost\", port=6379):\n    return DistributedCache(host, port)","assertions":"import time\n\n# Test with mock Redis (would need redis-server running for real test)\ncache = distributed_cache()\n\n# Test basic operations (these would work with real Redis)\n# Note: In real testing, you'd need a Redis server running\ntry:\n    # These operations should not raise exceptions even without Redis\n    result = cache.get(\"nonexistent\")\n    assert result is None\n    \n    set_result = cache.set(\"test_key\", {\"data\": \"value\"}, 60)\n    # set_result may be False if Redis not available\n    \n    exists_result = cache.exists(\"test_key\")\n    # exists_result may be False if Redis not available\n    \n    delete_result = cache.delete(\"test_key\")\n    # delete_result may be False if Redis not available\n    \nexcept Exception as e:\n    # Should handle connection errors gracefully\n    pass","metadata":{"language":"Python","function_name":"distributed_cache","difficulty":"very_advanced","category":"concurrency","complexity":0.85}}
{"query_id":"synthetic-017","query_text":"Write a Python function named `concurrent_web_crawler` that crawls web pages concurrently with rate limiting, respecting robots.txt, and handling various error conditions. The function should return a dictionary of URL to content mappings. Language: Python. Function name: concurrent_web_crawler","reference_answer":"import asyncio\nimport aiohttp\nfrom urllib.robotparser import RobotFileParser\nfrom urllib.parse import urlparse, urljoin\nimport time\nfrom typing import Dict, Set, List\nfrom collections import deque\n\nclass WebCrawler:\n    def __init__(self, max_concurrent: int = 10, delay: float = 1.0):\n        self.max_concurrent = max_concurrent\n        self.delay = delay\n        self.visited: Set[str] = set()\n        self.results: Dict[str, str] = {}\n        self.robot_parsers: Dict[str, RobotFileParser] = {}\n        self.last_request_time = 0\n        self.semaphore = asyncio.Semaphore(max_concurrent)\n    \n    async def _can_fetch(self, url: str, user_agent: str = \"*\") -> bool:\n        try:\n            parsed = urlparse(url)\n            base_url = f\"{parsed.scheme}://{parsed.netloc}\"\n            \n            if base_url not in self.robot_parsers:\n                rp = RobotFileParser()\n                rp.set_url(urljoin(base_url, \"/robots.txt\"))\n                try:\n                    await asyncio.get_event_loop().run_in_executor(None, rp.read)\n                except:\n                    pass  # If robots.txt fails, assume we can crawl\n                self.robot_parsers[base_url] = rp\n            \n            return self.robot_parsers[base_url].can_fetch(user_agent, url)\n        except:\n            return True  # Default to allowing if robots.txt check fails\n    \n    async def _fetch_page(self, session: aiohttp.ClientSession, url: str) -> str:\n        try:\n            # Rate limiting\n            elapsed = time.time() - self.last_request_time\n            if elapsed < self.delay:\n                await asyncio.sleep(self.delay - elapsed)\n            \n            async with self.semaphore:\n                async with session.get(url, timeout=aiohttp.ClientTimeout(total=10)) as response:\n                    self.last_request_time = time.time()\n                    if response.status == 200:\n                        return await response.text()\n                    else:\n                        return f\"HTTP {response.status}\"\n        except Exception as e:\n            return f\"Error: {str(e)}\"\n    \n    async def crawl(self, start_urls: List[str], max_pages: int = 50) -> Dict[str, str]:\n        queue = deque(start_urls)\n        \n        async with aiohttp.ClientSession() as session:\n            while queue and len(self.results) < max_pages:\n                url = queue.popleft()\n                \n                if url in self.visited:\n                    continue\n                \n                self.visited.add(url)\n                \n                if not await self._can_fetch(url):\n                    continue\n                \n                content = await self._fetch_page(session, url)\n                self.results[url] = content\n                \n                # Simple link extraction (in real implementation, use BeautifulSoup)\n                # For this example, we'll skip link extraction\n        \n        return self.results\n\ndef concurrent_web_crawler(start_urls, max_pages=10):\n    crawler = WebCrawler()\n    return asyncio.run(crawler.crawl(start_urls, max_pages))","assertions":"import asyncio\n\nasync def test_crawler():\n    # Test with invalid URLs (should handle gracefully)\n    urls = [\"http://invalid-domain-12345.com\", \"http://another-invalid.com\"]\n    \n    crawler = WebCrawler(max_concurrent=2, delay=0.1)\n    results = await crawler.crawl(urls, max_pages=2)\n    \n    # Should have attempted to fetch both URLs\n    assert len(results) == 2\n    \n    # Both should have error messages\n    for url, content in results.items():\n        assert \"Error\" in content or \"HTTP\" in content\n\nasyncio.run(test_crawler())","metadata":{"language":"Python","function_name":"concurrent_web_crawler","difficulty":"very_advanced","category":"concurrency","complexity":0.9}}
{"query_id":"synthetic-018","query_text":"Write a Python function named `neural_network_backprop` that implements a simple neural network with backpropagation for binary classification. The function should train on given data and return the trained weights and biases. Language: Python. Function name: neural_network_backprop","reference_answer":"import numpy as np\nfrom typing import Tuple\n\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\ndef sigmoid_derivative(x):\n    return x * (1 - x)\n\nclass SimpleNeuralNetwork:\n    def __init__(self, input_size: int, hidden_size: int, output_size: int, learning_rate: float = 0.1):\n        self.learning_rate = learning_rate\n        \n        # Initialize weights and biases\n        self.weights_input_hidden = np.random.randn(input_size, hidden_size)\n        self.bias_hidden = np.zeros((1, hidden_size))\n        \n        self.weights_hidden_output = np.random.randn(hidden_size, output_size)\n        self.bias_output = np.zeros((1, output_size))\n    \n    def forward(self, X):\n        # Hidden layer\n        self.hidden_activation = sigmoid(np.dot(X, self.weights_input_hidden) + self.bias_hidden)\n        \n        # Output layer\n        self.output_activation = sigmoid(np.dot(self.hidden_activation, self.weights_hidden_output) + self.bias_output)\n        \n        return self.output_activation\n    \n    def backward(self, X, y, output):\n        # Calculate output layer error\n        output_error = y - output\n        output_delta = output_error * sigmoid_derivative(output)\n        \n        # Calculate hidden layer error\n        hidden_error = np.dot(output_delta, self.weights_hidden_output.T)\n        hidden_delta = hidden_error * sigmoid_derivative(self.hidden_activation)\n        \n        # Update weights and biases\n        self.weights_hidden_output += np.dot(self.hidden_activation.T, output_delta) * self.learning_rate\n        self.bias_output += np.sum(output_delta, axis=0, keepdims=True) * self.learning_rate\n        \n        self.weights_input_hidden += np.dot(X.T, hidden_delta) * self.learning_rate\n        self.bias_hidden += np.sum(hidden_delta, axis=0, keepdims=True) * self.learning_rate\n    \n    def train(self, X, y, epochs: int = 1000):\n        for _ in range(epochs):\n            output = self.forward(X)\n            self.backward(X, y, output)\n        \n        return {\n            'weights_input_hidden': self.weights_input_hidden,\n            'bias_hidden': self.bias_hidden,\n            'weights_hidden_output': self.weights_hidden_output,\n            'bias_output': self.bias_output\n        }\n\ndef neural_network_backprop(X, y, hidden_size=4, epochs=1000):\n    if len(X) == 0 or len(y) == 0:\n        raise ValueError(\"Empty training data\")\n    \n    input_size = X.shape[1] if hasattr(X, 'shape') else len(X[0])\n    output_size = y.shape[1] if hasattr(y, 'shape') else 1\n    \n    nn = SimpleNeuralNetwork(input_size, hidden_size, output_size)\n    return nn.train(X, y, epochs)","assertions":"import numpy as np\n\n# Create simple XOR dataset\nX = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\ny = np.array([[0], [1], [1], [0]])\n\n# Train network\nresult = neural_network_backprop(X, y, hidden_size=4, epochs=10000)\n\n# Check that weights are updated (not all zeros)\nassert not np.allclose(result['weights_input_hidden'], 0)\nassert not np.allclose(result['weights_hidden_output'], 0)\n\n# Check shapes\nassert result['weights_input_hidden'].shape == (2, 4)\nassert result['bias_hidden'].shape == (1, 4)\nassert result['weights_hidden_output'].shape == (4, 1)\nassert result['bias_output'].shape == (1, 1)","metadata":{"language":"Python","function_name":"neural_network_backprop","difficulty":"very_advanced","category":"algorithms","complexity":0.95}}
{"query_id":"synthetic-019","query_text":"Write a Python function named `async_task_scheduler` that implements a priority-based task scheduler with deadline support. Tasks should be executed asynchronously with proper priority queuing and deadline enforcement. Language: Python. Function name: async_task_scheduler","reference_answer":"import asyncio\nimport heapq\nfrom typing import List, Callable, Any, Optional\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timedelta\n\n@dataclass(order=True)\nclass Task:\n    priority: int\n    deadline: Optional[datetime] = field(compare=False)\n    func: Callable = field(compare=False)\n    args: tuple = field(compare=False, default_factory=tuple)\n    id: int = field(compare=False, default_factory=lambda: id(object()))\n\nclass AsyncTaskScheduler:\n    def __init__(self, max_concurrent: int = 5):\n        self.max_concurrent = max_concurrent\n        self.tasks: List[Task] = []\n        self.running_tasks: set = set()\n        self.semaphore = asyncio.Semaphore(max_concurrent)\n        self.completed_tasks: List[Task] = []\n    \n    def add_task(self, func: Callable, args: tuple = (), priority: int = 0, \n                 deadline: Optional[datetime] = None) -> None:\n        task = Task(priority, deadline, func, args)\n        heapq.heappush(self.tasks, task)\n    \n    async def _execute_task(self, task: Task) -> Any:\n        async with self.semaphore:\n            try:\n                if task.deadline and datetime.now() > task.deadline:\n                    raise asyncio.TimeoutError(f\"Task {task.id} missed deadline\")\n                \n                # Execute with timeout if deadline is set\n                if task.deadline:\n                    timeout = (task.deadline - datetime.now()).total_seconds()\n                    if timeout <= 0:\n                        raise asyncio.TimeoutError(f\"Task {task.id} already past deadline\")\n                    \n                    result = await asyncio.wait_for(\n                        asyncio.get_event_loop().run_in_executor(None, task.func, *task.args),\n                        timeout=timeout\n                    )\n                else:\n                    result = await asyncio.get_event_loop().run_in_executor(None, task.func, *task.args)\n                \n                return result\n            except Exception as e:\n                return e\n    \n    async def run(self) -> List[Any]:\n        results = []\n        \n        while self.tasks:\n            # Get highest priority task\n            task = heapq.heappop(self.tasks)\n            \n            # Execute task\n            result = await self._execute_task(task)\n            results.append(result)\n            self.completed_tasks.append(task)\n        \n        return results\n\ndef async_task_scheduler(max_concurrent=3):\n    return AsyncTaskScheduler(max_concurrent)","assertions":"import time\n\nscheduler = async_task_scheduler(max_concurrent=2)\n\n# Add tasks with different priorities\ndef task_func(x):\n    time.sleep(0.1)\n    return x * 2\n\nscheduler.add_task(task_func, (1,), priority=2)\nscheduler.add_task(task_func, (2,), priority=1)  # Higher priority (lower number)\nscheduler.add_task(task_func, (3,), priority=3)\n\n# Run scheduler\nresults = asyncio.run(scheduler.run())\n\n# Should have 3 results\nassert len(results) == 3\n\n# Results should be in priority order (lower priority number first)\n# Note: actual order depends on execution timing, so we just check completion\nassert 2 in results  # task_func(1) result\nassert 4 in results  # task_func(2) result\nassert 6 in results  # task_func(3) result","metadata":{"language":"Python","function_name":"async_task_scheduler","difficulty":"very_advanced","category":"concurrency","complexity":0.85}}
{"query_id":"synthetic-020","query_text":"Write a Python function named `implement_graph_dijkstra` that implements Dijkstra's algorithm for finding shortest paths in a weighted graph. The function should handle graphs with non-negative weights and return distances and paths. Language: Python. Function name: implement_graph_dijkstra","reference_answer":"import heapq\nfrom typing import Dict, List, Tuple, Optional\n\ndef implement_graph_dijkstra(graph: Dict[str, List[Tuple[str, int]]], start: str) -> Tuple[Dict[str, int], Dict[str, Optional[str]]]:\n    # Priority queue for (distance, node)\n    pq = [(0, start)]\n    distances = {node: float('inf') for node in graph}\n    distances[start] = 0\n    previous = {node: None for node in graph}\n    \n    while pq:\n        current_distance, current_node = heapq.heappop(pq)\n        \n        if current_distance > distances[current_node]:\n            continue\n        \n        for neighbor, weight in graph.get(current_node, []):\n            distance = current_distance + weight\n            \n            if distance < distances.get(neighbor, float('inf')):\n                distances[neighbor] = distance\n                previous[neighbor] = current_node\n                heapq.heappush(pq, (distance, neighbor))\n    \n    return distances, previous","assertions":"graph = {\n    'A': [('B', 4), ('C', 2)],\n    'B': [('A', 4), ('C', 5), ('D', 10)],\n    'C': [('A', 2), ('B', 5), ('D', 3)],\n    'D': [('B', 10), ('C', 3)]\n}\n\ndistances, previous = implement_graph_dijkstra(graph, 'A')\n\nassert distances['A'] == 0\nassert distances['B'] == 4\nassert distances['C'] == 2\nassert distances['D'] == 5\n\n# Verify path reconstruction\npath = []\ncurrent = 'D'\nwhile current:\n    path.append(current)\n    current = previous[current]\npath.reverse()\nassert path == ['A', 'C', 'D']","metadata":{"language":"Python","function_name":"implement_graph_dijkstra","difficulty":"very_advanced","category":"algorithms","complexity":0.8}}
{"query_id":"synthetic-021","query_text":"Write a Python function named `bloom_filter` that implements a Bloom filter for set membership testing. The function should support add and check operations with configurable false positive rates. Language: Python. Function name: bloom_filter","reference_answer":"import hashlib\nimport math\nfrom typing import List\n\nclass BloomFilter:\n    def __init__(self, expected_items: int, false_positive_rate: float = 0.01):\n        # Calculate optimal size and hash functions\n        self.size = self._optimal_size(expected_items, false_positive_rate)\n        self.hash_count = self._optimal_hash_count(expected_items, self.size)\n        \n        # Initialize bit array\n        self.bit_array = [False] * self.size\n        \n    def _optimal_size(self, n: int, p: float) -> int:\n        return int(-n * math.log(p) / (math.log(2) ** 2))\n    \n    def _optimal_hash_count(self, n: int, m: int) -> int:\n        return int((m / n) * math.log(2))\n    \n    def _hash_functions(self, item: str) -> List[int]:\n        # Use multiple hash functions\n        hashes = []\n        item_bytes = item.encode('utf-8')\n        \n        for i in range(self.hash_count):\n            # Use different hash algorithms and combine with seed\n            h1 = int(hashlib.md5((str(i) + item).encode()).hexdigest(), 16)\n            h2 = int(hashlib.sha1((str(i) + item).encode()).hexdigest(), 16)\n            # Double hashing\n            hash_val = (h1 + i * h2) % self.size\n            hashes.append(hash_val)\n        \n        return hashes\n    \n    def add(self, item: str) -> None:\n        for hash_val in self._hash_functions(item):\n            self.bit_array[hash_val] = True\n    \n    def check(self, item: str) -> bool:\n        return all(self.bit_array[hash_val] for hash_val in self._hash_functions(item))\n    \n    def estimate_false_positive_rate(self) -> float:\n        # Estimate current false positive rate\n        filled_bits = sum(self.bit_array)\n        if filled_bits == 0:\n            return 0.0\n        return (filled_bits / self.size) ** self.hash_count\n\ndef bloom_filter(expected_items=1000, false_positive_rate=0.01):\n    return BloomFilter(expected_items, false_positive_rate)","assertions":"bf = bloom_filter(expected_items=100, false_positive_rate=0.01)\n\n# Test basic operations\ntest_items = ['apple', 'banana', 'cherry', 'date']\n\n# Add items\nfor item in test_items:\n    bf.add(item)\n\n# Check existing items (should return True)\nfor item in test_items:\n    assert bf.check(item) == True\n\n# Check non-existing items (may return True due to false positives, but unlikely for small set)\nnon_existing = ['grape', 'kiwi', 'lemon']\nfalse_positives = sum(1 for item in non_existing if bf.check(item))\n\n# False positive rate should be low\nassert false_positives / len(non_existing) < 0.1  # Allow some false positives","metadata":{"language":"Python","function_name":"bloom_filter","difficulty":"very_advanced","category":"data_structures","complexity":0.8}}
{"query_id":"synthetic-022","query_text":"Write a Python function named `concurrent_merge_sort` that implements merge sort using concurrent.futures for parallel sorting of large arrays. The function should automatically choose the optimal level of parallelism. Language: Python. Function name: concurrent_merge_sort","reference_answer":"import concurrent.futures\nimport math\nfrom typing import List\n\ndef concurrent_merge_sort(arr: List[int]) -> List[int]:\n    if len(arr) <= 1:\n        return arr\n    \n    # Determine optimal parallelism based on array size\n    # Use parallelism for arrays larger than 1000 elements\n    use_parallel = len(arr) > 1000\n    \n    if not use_parallel:\n        return _merge_sort_sequential(arr)\n    \n    # Split array into chunks for parallel processing\n    num_workers = min(4, len(arr) // 1000 + 1)  # Max 4 workers\n    chunk_size = math.ceil(len(arr) / num_workers)\n    \n    # Create chunks\n    chunks = [arr[i:i + chunk_size] for i in range(0, len(arr), chunk_size)]\n    \n    # Sort chunks in parallel\n    with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:\n        sorted_chunks = list(executor.map(_merge_sort_sequential, chunks))\n    \n    # Merge sorted chunks\n    while len(sorted_chunks) > 1:\n        merged = []\n        for i in range(0, len(sorted_chunks), 2):\n            if i + 1 < len(sorted_chunks):\n                merged.append(_merge(sorted_chunks[i], sorted_chunks[i + 1]))\n            else:\n                merged.append(sorted_chunks[i])\n        sorted_chunks = merged\n    \n    return sorted_chunks[0]\n\ndef _merge_sort_sequential(arr: List[int]) -> List[int]:\n    if len(arr) <= 1:\n        return arr\n    \n    mid = len(arr) // 2\n    left = _merge_sort_sequential(arr[:mid])\n    right = _merge_sort_sequential(arr[mid:])\n    \n    return _merge(left, right)\n\ndef _merge(left: List[int], right: List[int]) -> List[int]:\n    result = []\n    i = j = 0\n    \n    while i < len(left) and j < len(right):\n        if left[i] <= right[j]:\n            result.append(left[i])\n            i += 1\n        else:\n            result.append(right[j])\n            j += 1\n    \n    result.extend(left[i:])\n    result.extend(right[j:])\n    return result","assertions":"import random\n\n# Test with small array\nsmall_arr = [3, 1, 4, 1, 5, 9, 2, 6]\nresult = concurrent_merge_sort(small_arr)\nassert result == [1, 1, 2, 3, 4, 5, 6, 9]\n\n# Test with larger array (should use parallel processing)\nlarge_arr = random.sample(range(10000), 2000)\nresult_large = concurrent_merge_sort(large_arr)\nassert result_large == sorted(large_arr)\n\n# Test edge cases\nassert concurrent_merge_sort([]) == []\nassert concurrent_merge_sort([1]) == [1]\nassert concurrent_merge_sort([2, 1]) == [1, 2]","metadata":{"language":"Python","function_name":"concurrent_merge_sort","difficulty":"very_advanced","category":"algorithms","complexity":0.85}}
{"query_id":"synthetic-023","query_text":"Write a Python function named `async_database_connection_pool` that implements a connection pool for async database operations with proper resource management, connection health checks, and graceful degradation. Language: Python. Function name: async_database_connection_pool","reference_answer":"import asyncio\nimport time\nfrom typing import Optional, List, Any, Callable\nfrom dataclasses import dataclass\nfrom contextlib import asynccontextmanager\n\n@dataclass\nclass Connection:\n    id: int\n    created_at: float\n    last_used: float\n    is_healthy: bool = True\n\nclass AsyncConnectionPool:\n    def __init__(self, max_connections: int = 10, max_idle_time: float = 300.0, \n                 health_check_interval: float = 60.0):\n        self.max_connections = max_connections\n        self.max_idle_time = max_idle_time\n        self.health_check_interval = health_check_interval\n        \n        self._pool: List[Connection] = []\n        self._available: List[Connection] = []\n        self._in_use: set = set()\n        self._lock = asyncio.Lock()\n        self._connection_id_counter = 0\n        \n        # Start background health check\n        self._health_check_task: Optional[asyncio.Task] = None\n    \n    async def _create_connection(self) -> Connection:\n        # Simulate connection creation\n        await asyncio.sleep(0.01)  # Simulate network latency\n        self._connection_id_counter += 1\n        now = time.time()\n        return Connection(\n            id=self._connection_id_counter,\n            created_at=now,\n            last_used=now\n        )\n    \n    async def _health_check(self) -> None:\n        while True:\n            await asyncio.sleep(self.health_check_interval)\n            \n            async with self._lock:\n                current_time = time.time()\n                \n                # Check for idle connections to close\n                to_remove = []\n                for conn in self._available:\n                    if current_time - conn.last_used > self.max_idle_time:\n                        to_remove.append(conn)\n                \n                for conn in to_remove:\n                    self._available.remove(conn)\n                    self._pool.remove(conn)\n    \n    async def acquire(self) -> Connection:\n        async with self._lock:\n            # Try to get available connection\n            if self._available:\n                conn = self._available.pop()\n                if self._is_connection_healthy(conn):\n                    conn.last_used = time.time()\n                    self._in_use.add(conn.id)\n                    return conn\n                else:\n                    # Remove unhealthy connection\n                    self._pool.remove(conn)\n            \n            # Create new connection if under limit\n            if len(self._pool) < self.max_connections:\n                conn = await self._create_connection()\n                self._pool.append(conn)\n                self._in_use.add(conn.id)\n                return conn\n            \n            # Wait for connection to become available\n            while not self._available:\n                await asyncio.sleep(0.01)\n            \n            return await self.acquire()\n    \n    async def release(self, connection: Connection) -> None:\n        async with self._lock:\n            if connection.id in self._in_use:\n                self._in_use.remove(connection.id)\n                connection.last_used = time.time()\n                \n                if self._is_connection_healthy(connection):\n                    self._available.append(connection)\n                else:\n                    # Remove unhealthy connection\n                    self._pool.remove(connection)\n    \n    def _is_connection_healthy(self, connection: Connection) -> bool:\n        # Simple health check based on age\n        current_time = time.time()\n        max_age = 3600.0  # 1 hour\n        return (current_time - connection.created_at) < max_age and connection.is_healthy\n    \n    @asynccontextmanager\n    async def connection(self):\n        conn = await self.acquire()\n        try:\n            yield conn\n        finally:\n            await self.release(conn)\n    \n    async def close(self) -> None:\n        async with self._lock:\n            self._pool.clear()\n            self._available.clear()\n            self._in_use.clear()\n            \n            if self._health_check_task:\n                self._health_check_task.cancel()\n                try:\n                    await self._health_check_task\n                except asyncio.CancelledError:\n                    pass\n    \n    async def __aenter__(self):\n        # Start health check when entering context\n        self._health_check_task = asyncio.create_task(self._health_check())\n        return self\n    \n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        await self.close()\n\ndef async_database_connection_pool(max_connections=10):\n    return AsyncConnectionPool(max_connections)","assertions":"import asyncio\n\nasync def test_pool():\n    async with AsyncConnectionPool(max_connections=3) as pool:\n        # Test acquiring connections\n        conn1 = await pool.acquire()\n        conn2 = await pool.acquire()\n        conn3 = await pool.acquire()\n        \n        assert conn1.id != conn2.id\n        assert conn2.id != conn3.id\n        \n        # Test releasing and reusing\n        await pool.release(conn1)\n        conn1_reacquired = await pool.acquire()\n        assert conn1_reacquired.id == conn1.id\n        \n        await pool.release(conn2)\n        await pool.release(conn3)\n        await pool.release(conn1_reacquired)\n\nasyncio.run(test_pool())","metadata":{"language":"Python","function_name":"async_database_connection_pool","difficulty":"very_advanced","category":"concurrency","complexity":0.9}}
{"query_id":"synthetic-024","query_text":"Write a Python function named `parallel_map_reduce` that implements a parallel map-reduce framework using concurrent.futures. The function should handle large datasets by chunking and parallel processing. Language: Python. Function name: parallel_map_reduce","reference_answer":"import concurrent.futures\nimport math\nfrom typing import List, Callable, Any, TypeVar, Iterable\nfrom functools import reduce\n\nT = TypeVar('T')\nU = TypeVar('U')\nV = TypeVar('V')\n\ndef parallel_map_reduce(\n    data: Iterable[T],\n    mapper: Callable[[T], U],\n    reducer: Callable[[U, U], U],\n    initial_value: U,\n    chunk_size: int = 1000,\n    max_workers: Optional[int] = None\n) -> U:\n    \n    # Convert to list for chunking\n    data_list = list(data)\n    if not data_list:\n        return initial_value\n    \n    # Determine optimal worker count\n    if max_workers is None:\n        max_workers = min(8, max(1, len(data_list) // chunk_size))\n    \n    # Split data into chunks\n    chunks = [data_list[i:i + chunk_size] \n             for i in range(0, len(data_list), chunk_size)]\n    \n    # Parallel map phase\n    def map_chunk(chunk: List[T]) -> U:\n        chunk_results = [mapper(item) for item in chunk]\n        # Reduce within chunk\n        return reduce(reducer, chunk_results, initial_value)\n    \n    # Execute map phase in parallel\n    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n        chunk_results = list(executor.map(map_chunk, chunks))\n    \n    # Final reduce phase\n    return reduce(reducer, chunk_results, initial_value)","assertions":"import math\n\n# Test word count example\ndef word_mapper(text):\n    words = text.split()\n    return {word: 1 for word in words}\n\ndef dict_reducer(d1, d2):\n    result = d1.copy()\n    for word, count in d2.items():\n        result[word] = result.get(word, 0) + count\n    return result\n\ndocuments = [\n    \"hello world hello\",\n    \"world test world\",\n    \"hello test hello test\"\n]\n\nresult = parallel_map_reduce(\n    documents,\n    word_mapper,\n    dict_reducer,\n    {}\n)\n\nassert result[\"hello\"] == 4\nassert result[\"world\"] == 3\nassert result[\"test\"] == 3\n\n# Test sum of squares\ndef square_mapper(x):\n    return x * x\n\ndef sum_reducer(a, b):\n    return a + b\n\nnumbers = list(range(1, 101))  # 1 to 100\nsum_squares = parallel_map_reduce(numbers, square_mapper, sum_reducer, 0)\nexpected = sum(x*x for x in range(1, 101))\nassert sum_squares == expected","metadata":{"language":"Python","function_name":"parallel_map_reduce","difficulty":"very_advanced","category":"concurrency","complexity":0.85}}
{"query_id":"synthetic-025","query_text":"Write a Python function named `distributed_lock_manager` that implements a distributed lock manager using Redis with proper lease management, deadlock detection, and automatic cleanup of expired locks. Language: Python. Function name: distributed_lock_manager","reference_answer":"import redis\nimport time\nimport uuid\nfrom typing import Optional, Callable, Any\nfrom contextlib import contextmanager\n\nclass DistributedLock:\n    def __init__(self, redis_client: redis.Redis, lock_key: str, \n                 owner_id: Optional[str] = None, ttl_seconds: int = 30):\n        self.redis = redis_client\n        self.lock_key = lock_key\n        self.owner_id = owner_id or str(uuid.uuid4())\n        self.ttl_seconds = ttl_seconds\n        self.lock_value = f\"{self.owner_id}:{time.time()}\"\n    \n    def acquire(self, timeout_seconds: int = 10) -> bool:\n        deadline = time.time() + timeout_seconds\n        \n        while time.time() < deadline:\n            # Try to acquire lock\n            if self.redis.set(self.lock_key, self.lock_value, \n                            ex=self.ttl_seconds, nx=True):\n                return True\n            \n            # Check if lock is expired and steal it\n            current_value = self.redis.get(self.lock_key)\n            if current_value and self._is_lock_expired(current_value):\n                # Try to steal expired lock\n                old_value = current_value\n                if self.redis.getset(self.lock_key, self.lock_value):\n                    # Successfully stole lock\n                    self.redis.expire(self.lock_key, self.ttl_seconds)\n                    return True\n            \n            time.sleep(0.01)  # Small delay to avoid busy waiting\n        \n        return False\n    \n    def release(self) -> bool:\n        # Only release if we own the lock\n        current_value = self.redis.get(self.lock_key)\n        if current_value and current_value.startswith(self.owner_id):\n            return bool(self.redis.delete(self.lock_key))\n        return False\n    \n    def extend(self, additional_seconds: int = 30) -> bool:\n        # Only extend if we own the lock\n        current_value = self.redis.get(self.lock_key)\n        if current_value and current_value.startswith(self.owner_id):\n            return bool(self.redis.expire(self.lock_key, additional_seconds))\n        return False\n    \n    def _is_lock_expired(self, lock_value: str) -> bool:\n        try:\n            owner_id, timestamp_str = lock_value.split(':', 1)\n            timestamp = float(timestamp_str)\n            return time.time() - timestamp > self.ttl_seconds\n        except (ValueError, IndexError):\n            return True  # Malformed lock value\n    \n    @contextmanager\n    def lock(self, timeout_seconds: int = 10):\n        acquired = self.acquire(timeout_seconds)\n        if not acquired:\n            raise TimeoutError(f\"Could not acquire lock {self.lock_key}\")\n        try:\n            yield\n        finally:\n            self.release()\n\nclass DistributedLockManager:\n    def __init__(self, redis_host: str = \"localhost\", redis_port: int = 6379):\n        self.redis = redis.Redis(host=redis_host, port=redis_port, decode_responses=True)\n        self.locks: dict = {}\n    \n    def get_lock(self, lock_key: str, ttl_seconds: int = 30) -> DistributedLock:\n        if lock_key not in self.locks:\n            self.locks[lock_key] = DistributedLock(self.redis, lock_key, ttl_seconds=ttl_seconds)\n        return self.locks[lock_key]\n    \n    def cleanup_expired_locks(self) -> int:\n        # Scan for expired locks and clean them up\n        cleaned = 0\n        for key in self.redis.scan_iter(\"lock:*\"):\n            value = self.redis.get(key)\n            if value:\n                owner_id, timestamp_str = value.split(':', 1)\n                try:\n                    timestamp = float(timestamp_str)\n                    if time.time() - timestamp > 60:  # 60 second grace period\n                        self.redis.delete(key)\n                        cleaned += 1\n                except (ValueError, IndexError):\n                    self.redis.delete(key)  # Remove malformed locks\n                    cleaned += 1\n        return cleaned\n\ndef distributed_lock_manager(redis_host=\"localhost\", redis_port=6379):\n    return DistributedLockManager(redis_host, redis_port)","assertions":"import time\n\n# Test basic lock operations (would need Redis running)\nmanager = distributed_lock_manager()\nlock = manager.get_lock(\"test_lock\", ttl_seconds=5)\n\n# Test acquiring lock\nacquired = lock.acquire(timeout_seconds=1)\n# Result depends on Redis availability\n\n# Test releasing lock\nreleased = lock.release()\n# Result depends on Redis availability\n\n# Test cleanup\ncleaned = manager.cleanup_expired_locks()\n# Result depends on Redis state\n\n# Basic structure test\nassert hasattr(manager, 'get_lock')\nassert hasattr(lock, 'acquire')\nassert hasattr(lock, 'release')","metadata":{"language":"Python","function_name":"distributed_lock_manager","difficulty":"very_advanced","category":"concurrency","complexity":0.9}}
{"query_id":"synthetic-026","query_text":"Write a Python function named `implement_skip_list` that implements a skip list data structure with search, insert, and delete operations. The skip list should provide O(log n) average time complexity. Language: Python. Function name: implement_skip_list","reference_answer":"import random\nfrom typing import Optional, Any\n\nclass SkipListNode:\n    def __init__(self, key: Any, value: Any, level: int):\n        self.key = key\n        self.value = value\n        self.forward = [None] * (level + 1)\n\nclass SkipList:\n    def __init__(self, max_level: int = 16, p: float = 0.5):\n        self.max_level = max_level\n        self.p = p\n        self.header = SkipListNode(None, None, max_level)\n        self.level = 0\n    \n    def _random_level(self) -> int:\n        level = 0\n        while random.random() < self.p and level < self.max_level:\n            level += 1\n        return level\n    \n    def search(self, key: Any) -> Optional[Any]:\n        current = self.header\n        for i in range(self.level, -1, -1):\n            while (current.forward[i] and \n                   current.forward[i].key < key):\n                current = current.forward[i]\n        \n        current = current.forward[0]\n        if current and current.key == key:\n            return current.value\n        return None\n    \n    def insert(self, key: Any, value: Any) -> None:\n        update = [None] * (self.max_level + 1)\n        current = self.header\n        \n        for i in range(self.level, -1, -1):\n            while (current.forward[i] and \n                   current.forward[i].key < key):\n                current = current.forward[i]\n            update[i] = current\n        \n        current = current.forward[0]\n        \n        if current and current.key == key:\n            current.value = value\n            return\n        \n        new_level = self._random_level()\n        \n        if new_level > self.level:\n            for i in range(self.level + 1, new_level + 1):\n                update[i] = self.header\n            self.level = new_level\n        \n        new_node = SkipListNode(key, value, new_level)\n        \n        for i in range(new_level + 1):\n            new_node.forward[i] = update[i].forward[i]\n            update[i].forward[i] = new_node\n    \n    def delete(self, key: Any) -> bool:\n        update = [None] * (self.max_level + 1)\n        current = self.header\n        \n        for i in range(self.level, -1, -1):\n            while (current.forward[i] and \n                   current.forward[i].key < key):\n                current = current.forward[i]\n            update[i] = current\n        \n        current = current.forward[0]\n        \n        if current and current.key == key:\n            for i in range(self.level + 1):\n                if update[i].forward[i] != current:\n                    break\n                update[i].forward[i] = current.forward[i]\n            \n            while self.level > 0 and self.header.forward[self.level] is None:\n                self.level -= 1\n            \n            return True\n        \n        return False\n\ndef implement_skip_list(max_level=16):\n    return SkipList(max_level)","assertions":"skip_list = implement_skip_list()\n\n# Test insert and search\nskip_list.insert(1, \"one\")\nskip_list.insert(3, \"three\")\nskip_list.insert(2, \"two\")\n\nassert skip_list.search(1) == \"one\"\nassert skip_list.search(2) == \"two\"\nassert skip_list.search(3) == \"three\"\nassert skip_list.search(4) is None\n\n# Test delete\nassert skip_list.delete(2) == True\nassert skip_list.search(2) is None\nassert skip_list.delete(2) == False\n\n# Test update\nskip_list.insert(1, \"uno\")\nassert skip_list.search(1) == \"uno\"","metadata":{"language":"Python","function_name":"implement_skip_list","difficulty":"very_advanced","category":"data_structures","complexity":0.85}}
{"query_id":"synthetic-027","query_text":"Write a Python function named `concurrent_priority_queue` that implements a thread-safe priority queue with concurrent access, priority updates, and efficient blocking operations. Language: Python. Function name: concurrent_priority_queue","reference_answer":"import heapq\nimport threading\nimport time\nfrom typing import Any, List, Tuple, Optional\n\nclass ConcurrentPriorityQueue:\n    def __init__(self, max_size: Optional[int] = None):\n        self._heap: List[Tuple[int, int, Any]] = []  # (priority, seq_num, item)\n        self._lock = threading.RLock()\n        self._not_empty = threading.Condition(self._lock)\n        self._not_full = threading.Condition(self._lock)\n        self._max_size = max_size\n        self._seq_num = 0\n        self._item_to_entry: dict = {}  # item -> (priority, seq_num)\n    \n    def put(self, item: Any, priority: int = 0, timeout: Optional[float] = None) -> bool:\n        with self._lock:\n            if self._max_size is not None:\n                while len(self._heap) >= self._max_size:\n                    if not self._not_full.wait(timeout):\n                        return False\n            \n            # Remove old entry if item already exists\n            if item in self._item_to_entry:\n                old_priority, old_seq = self._item_to_entry[item]\n                # Mark old entry as invalid (lazy deletion)\n                self._item_to_entry[item] = (-1, -1)\n            \n            self._seq_num += 1\n            entry = (priority, self._seq_num, item)\n            heapq.heappush(self._heap, entry)\n            self._item_to_entry[item] = (priority, self._seq_num)\n            \n            self._not_empty.notify()\n            return True\n    \n    def get(self, timeout: Optional[float] = None) -> Optional[Any]:\n        with self._lock:\n            while not self._heap:\n                if not self._not_empty.wait(timeout):\n                    return None\n            \n            while self._heap:\n                priority, seq_num, item = heapq.heappop(self._heap)\n                \n                # Check if this entry is still valid\n                if item in self._item_to_entry:\n                    current_priority, current_seq = self._item_to_entry[item]\n                    if current_seq == seq_num:\n                        del self._item_to_entry[item]\n                        \n                        if self._max_size is not None:\n                            self._not_full.notify()\n                        \n                        return item\n            \n            return None  # All entries were invalidated\n    \n    def update_priority(self, item: Any, new_priority: int) -> bool:\n        with self._lock:\n            if item not in self._item_to_entry:\n                return False\n            \n            # Invalidate old entry and add new one\n            self._item_to_entry[item] = (-1, -1)  # Mark as invalid\n            self._seq_num += 1\n            entry = (new_priority, self._seq_num, item)\n            heapq.heappush(self._heap, entry)\n            self._item_to_entry[item] = (new_priority, self._seq_num)\n            \n            return True\n    \n    def peek(self) -> Optional[Any]:\n        with self._lock:\n            while self._heap:\n                priority, seq_num, item = self._heap[0]\n                if item in self._item_to_entry:\n                    current_priority, current_seq = self._item_to_entry[item]\n                    if current_seq == seq_num:\n                        return item\n                else:\n                    heapq.heappop(self._heap)  # Remove invalid entry\n            return None\n    \n    def empty(self) -> bool:\n        with self._lock:\n            return len(self._valid_items()) == 0\n    \n    def qsize(self) -> int:\n        with self._lock:\n            return len(self._valid_items())\n    \n    def _valid_items(self) -> List[Any]:\n        valid = []\n        for _, _, item in self._heap:\n            if item in self._item_to_entry:\n                priority, seq_num = self._item_to_entry[item]\n                if seq_num != -1:  # Not invalidated\n                    valid.append(item)\n        return valid\n\ndef concurrent_priority_queue(max_size=None):\n    return ConcurrentPriorityQueue(max_size)","assertions":"import threading\nimport time\n\n# Test basic operations\nqueue = concurrent_priority_queue()\n\n# Test put and get\nqueue.put(\"low\", priority=2)\nqueue.put(\"high\", priority=1)\nqueue.put(\"medium\", priority=1)\n\n# Should get highest priority items first\nitem1 = queue.get()\nitem2 = queue.get()\n\n# Priority 1 items should come before priority 2\nassert item1 in [\"high\", \"medium\"]\nassert item2 in [\"high\", \"medium\"]\nassert item1 != item2\n\n# Test priority update\nqueue.put(\"updatable\", priority=3)\nqueue.update_priority(\"updatable\", 0)  # Highest priority\nnext_item = queue.get()\nassert next_item == \"updatable\"\n\n# Test size\nassert queue.qsize() >= 0","metadata":{"language":"Python","function_name":"concurrent_priority_queue","difficulty":"very_advanced","category":"concurrency","complexity":0.9}}
{"query_id":"synthetic-028","query_text":"Write a Python function named `implement_b_tree` that implements a B-Tree data structure with search, insert, and delete operations. The B-Tree should maintain balance and provide efficient disk-based storage characteristics. Language: Python. Function name: implement_b_tree","reference_answer":"from typing import List, Optional, Any\n\nclass BTreeNode:\n    def __init__(self, t: int, leaf: bool = False):\n        self.t = t  # Minimum degree\n        self.leaf = leaf\n        self.keys: List[Any] = []\n        self.children: List['BTreeNode'] = []\n    \n    def is_full(self) -> bool:\n        return len(self.keys) == 2 * self.t - 1\n\nclass BTree:\n    def __init__(self, t: int = 2):\n        self.t = t  # Minimum degree\n        self.root: Optional[BTreeNode] = None\n    \n    def search(self, key: Any) -> Optional[BTreeNode]:\n        if not self.root:\n            return None\n        return self._search(self.root, key)\n    \n    def _search(self, node: BTreeNode, key: Any) -> Optional[BTreeNode]:\n        i = 0\n        while i < len(node.keys) and key > node.keys[i]:\n            i += 1\n        \n        if i < len(node.keys) and key == node.keys[i]:\n            return node\n        \n        if node.leaf:\n            return None\n        \n        return self._search(node.children[i], key)\n    \n    def insert(self, key: Any) -> None:\n        if not self.root:\n            self.root = BTreeNode(self.t, True)\n            self.root.keys.append(key)\n            return\n        \n        if self.root.is_full():\n            new_root = BTreeNode(self.t, False)\n            new_root.children.append(self.root)\n            self._split_child(new_root, 0)\n            self.root = new_root\n        \n        self._insert_non_full(self.root, key)\n    \n    def _insert_non_full(self, node: BTreeNode, key: Any) -> None:\n        if node.leaf:\n            i = len(node.keys) - 1\n            node.keys.append(None)\n            while i >= 0 and key < node.keys[i]:\n                node.keys[i + 1] = node.keys[i]\n                i -= 1\n            node.keys[i + 1] = key\n        else:\n            i = len(node.keys) - 1\n            while i >= 0 and key < node.keys[i]:\n                i -= 1\n            i += 1\n            \n            if node.children[i].is_full():\n                self._split_child(node, i)\n                if key > node.keys[i]:\n                    i += 1\n            \n            self._insert_non_full(node.children[i], key)\n    \n    def _split_child(self, parent: BTreeNode, i: int) -> None:\n        t = self.t\n        y = parent.children[i]\n        z = BTreeNode(t, y.leaf)\n        \n        parent.children.insert(i + 1, z)\n        parent.keys.insert(i, y.keys[t - 1])\n        \n        z.keys = y.keys[t: (2 * t - 1)]\n        y.keys = y.keys[0: t - 1]\n        \n        if not y.leaf:\n            z.children = y.children[t: (2 * t)]\n            y.children = y.children[0: t]\n    \n    def delete(self, key: Any) -> bool:\n        if not self.root:\n            return False\n        \n        result = self._delete(self.root, key)\n        \n        if len(self.root.keys) == 0:\n            if not self.root.leaf:\n                self.root = self.root.children[0]\n            else:\n                self.root = None\n        \n        return result\n    \n    def _delete(self, node: BTreeNode, key: Any) -> bool:\n        t = self.t\n        \n        # Find key in node\n        i = 0\n        while i < len(node.keys) and key > node.keys[i]:\n            i += 1\n        \n        if node.leaf:\n            if i < len(node.keys) and node.keys[i] == key:\n                node.keys.pop(i)\n                return True\n            return False\n        \n        if i < len(node.keys) and node.keys[i] == key:\n            return self._delete_internal_node(node, i)\n        elif len(node.children[i].keys) >= t:\n            return self._delete(node.children[i], key)\n        else:\n            self._fill(node, i)\n            return self._delete(node.children[i], key)\n    \n    def _delete_internal_node(self, node: BTreeNode, i: int) -> bool:\n        t = self.t\n        key = node.keys[i]\n        \n        if len(node.children[i].keys) >= t:\n            pred = self._get_predecessor(node.children[i])\n            node.keys[i] = pred\n            return self._delete(node.children[i], pred)\n        elif len(node.children[i + 1].keys) >= t:\n            succ = self._get_successor(node.children[i + 1])\n            node.keys[i] = succ\n            return self._delete(node.children[i + 1], succ)\n        else:\n            self._merge(node, i)\n            return self._delete(node.children[i], key)\n    \n    def _fill(self, node: BTreeNode, i: int) -> None:\n        if i != 0 and len(node.children[i - 1].keys) >= self.t:\n            self._borrow_from_prev(node, i)\n        elif i != len(node.keys) and len(node.children[i + 1].keys) >= self.t:\n            self._borrow_from_next(node, i)\n        else:\n            if i != len(node.keys):\n                self._merge(node, i)\n            else:\n                self._merge(node, i - 1)\n    \n    def _borrow_from_prev(self, node: BTreeNode, i: int) -> None:\n        child = node.children[i]\n        sibling = node.children[i - 1]\n        \n        child.keys.insert(0, node.keys[i - 1])\n        \n        if not child.leaf:\n            child.children.insert(0, sibling.children.pop())\n        \n        node.keys[i - 1] = sibling.keys.pop()\n    \n    def _borrow_from_next(self, node: BTreeNode, i: int) -> None:\n        child = node.children[i]\n        sibling = node.children[i + 1]\n        \n        child.keys.append(node.keys[i])\n        \n        if not child.leaf:\n            child.children.append(sibling.children.pop(0))\n        \n        node.keys[i] = sibling.keys.pop(0)\n    \n    def _merge(self, node: BTreeNode, i: int) -> None:\n        child = node.children[i]\n        sibling = node.children[i + 1]\n        \n        child.keys.append(node.keys[i])\n        child.keys.extend(sibling.keys)\n        \n        if not child.leaf:\n            child.children.extend(sibling.children)\n        \n        node.keys.pop(i)\n        node.children.pop(i + 1)\n    \n    def _get_predecessor(self, node: BTreeNode) -> Any:\n        current = node\n        while not current.leaf:\n            current = current.children[-1]\n        return current.keys[-1]\n    \n    def _get_successor(self, node: BTreeNode) -> Any:\n        current = node\n        while not current.leaf:\n            current = current.children[0]\n        return current.keys[0]\n\ndef implement_b_tree(t=2):\n    return BTree(t)","assertions":"btree = implement_b_tree(t=2)\n\n# Test insert\nbtree.insert(10)\nbtree.insert(20)\nbtree.insert(5)\nbtree.insert(15)\nbtree.insert(25)\n\n# Test search\nassert btree.search(10) is not None\nassert btree.search(20) is not None\nassert btree.search(5) is not None\nassert btree.search(99) is None\n\n# Test delete\nassert btree.delete(15) == True\nassert btree.search(15) is None\nassert btree.delete(99) == False","metadata":{"language":"Python","function_name":"implement_b_tree","difficulty":"very_advanced","category":"data_structures","complexity":0.95}}
{"query_id":"synthetic-029","query_text":"Write a Python function named `distributed_rate_limiter` that implements a distributed rate limiter using Redis with sliding window and fixed window algorithms, automatic cleanup, and cluster awareness. Language: Python. Function name: distributed_rate_limiter","reference_answer":"import redis\nimport time\nimport math\nfrom typing import Optional, Dict, Any\nfrom enum import Enum\n\nclass RateLimitAlgorithm(Enum):\n    FIXED_WINDOW = \"fixed_window\"\n    SLIDING_WINDOW = \"sliding_window\"\n\nclass DistributedRateLimiter:\n    def __init__(self, redis_client: redis.Redis, algorithm: RateLimitAlgorithm = RateLimitAlgorithm.SLIDING_WINDOW):\n        self.redis = redis_client\n        self.algorithm = algorithm\n        self.script_cache: Dict[str, Any] = {}\n    \n    def is_allowed(self, key: str, limit: int, window_seconds: int) -> bool:\n        if self.algorithm == RateLimitAlgorithm.FIXED_WINDOW:\n            return self._check_fixed_window(key, limit, window_seconds)\n        else:\n            return self._check_sliding_window(key, limit, window_seconds)\n    \n    def _check_fixed_window(self, key: str, limit: int, window_seconds: int) -> bool:\n        current_window = int(time.time() / window_seconds)\n        window_key = f\"{key}:{current_window}\"\n        \n        # Use Redis pipeline for atomic operations\n        with self.redis.pipeline() as pipe:\n            pipe.incr(window_key)\n            pipe.expire(window_key, window_seconds * 2)  # Keep for 2 windows\n            count = pipe.execute()[0]\n        \n        return count <= limit\n    \n    def _check_sliding_window(self, key: str, limit: int, window_seconds: int) -> bool:\n        current_time = time.time()\n        window_start = current_time - window_seconds\n        \n        # Add current request\n        self.redis.zadd(key, {str(current_time): current_time})\n        \n        # Remove old requests outside window\n        self.redis.zremrangebyscore(key, '-inf', window_start)\n        \n        # Count requests in current window\n        count = self.redis.zcount(key, window_start, '+inf')\n        \n        # Set expiration for cleanup\n        self.redis.expire(key, window_seconds * 2)\n        \n        return count <= limit\n    \n    def get_remaining_requests(self, key: str, limit: int, window_seconds: int) -> int:\n        if self.algorithm == RateLimitAlgorithm.FIXED_WINDOW:\n            current_window = int(time.time() / window_seconds)\n            window_key = f\"{key}:{current_window}\"\n            count = int(self.redis.get(window_key) or 0)\n        else:\n            current_time = time.time()\n            window_start = current_time - window_seconds\n            count = self.redis.zcount(key, window_start, '+inf')\n        \n        return max(0, limit - count)\n    \n    def get_reset_time(self, key: str, window_seconds: int) -> float:\n        if self.algorithm == RateLimitAlgorithm.FIXED_WINDOW:\n            current_window = int(time.time() / window_seconds)\n            return (current_window + 1) * window_seconds\n        else:\n            # For sliding window, reset time is current time + window\n            return time.time() + window_seconds\n    \n    def cleanup_old_keys(self, pattern: str = \"*\") -> int:\n        # Find and cleanup expired keys\n        cleaned = 0\n        for key in self.redis.scan_iter(pattern):\n            if self.redis.ttl(key) == -1:  # Key has no expiration\n                # Check if it's a rate limit key and remove if empty\n                if self.redis.type(key) == 'zset' and self.redis.zcount(key, '-inf', '+inf') == 0:\n                    self.redis.delete(key)\n                    cleaned += 1\n        return cleaned\n\ndef distributed_rate_limiter(redis_host=\"localhost\", redis_port=6379, algorithm=\"sliding_window\"):\n    redis_client = redis.Redis(host=redis_host, port=redis_port, decode_responses=True)\n    algo = RateLimitAlgorithm.SLIDING_WINDOW if algorithm == \"sliding_window\" else RateLimitAlgorithm.FIXED_WINDOW\n    return DistributedRateLimiter(redis_client, algo)","assertions":"import time\n\n# Test basic rate limiting (would need Redis running)\nlimiter = distributed_rate_limiter()\n\ntest_key = \"test_api\"\n\n# Test sliding window\nallowed = limiter.is_allowed(test_key, limit=5, window_seconds=60)\n# Result depends on Redis availability\n\nremaining = limiter.get_remaining_requests(test_key, limit=5, window_seconds=60)\n# Result depends on Redis state\n\nreset_time = limiter.get_reset_time(test_key, window_seconds=60)\nassert reset_time > time.time()\n\n# Test cleanup\ncleaned = limiter.cleanup_old_keys(\"test_*\")\n# Result depends on Redis state\n\n# Basic structure test\nassert hasattr(limiter, 'is_allowed')\nassert hasattr(limiter, 'get_remaining_requests')","metadata":{"language":"Python","function_name":"distributed_rate_limiter","difficulty":"very_advanced","category":"concurrency","complexity":0.9}}
{"query_id":"synthetic-030","query_text":"Write a Python function named `concurrent_skip_list` that implements a concurrent skip list with lock-free operations for search, insert, and delete. The implementation should use atomic operations and provide linearizability guarantees. Language: Python. Function name: concurrent_skip_list","reference_answer":"import random\nimport threading\nfrom typing import Optional, Any, List\n\nclass ConcurrentSkipListNode:\n    def __init__(self, key: Any, value: Any, level: int):\n        self.key = key\n        self.value = value\n        self.forward: List[Optional['ConcurrentSkipListNode']] = [None] * (level + 1)\n        self.lock = threading.Lock()\n        self.marked = False  # For logical deletion\n        self.fully_linked = False  # For helping with insertions\n\nclass ConcurrentSkipList:\n    def __init__(self, max_level: int = 16, p: float = 0.5):\n        self.max_level = max_level\n        self.p = p\n        self.head = ConcurrentSkipListNode(None, None, max_level)\n        self.level = 0\n    \n    def _random_level(self) -> int:\n        level = 0\n        while random.random() < self.p and level < self.max_level:\n            level += 1\n        return level\n    \n    def find(self, key: Any) -> Optional[Any]:\n        current = self.head\n        \n        for i in range(self.level, -1, -1):\n            while (current.forward[i] and \n                   current.forward[i].key < key):\n                current = current.forward[i]\n        \n        current = current.forward[0]\n        if current and current.key == key and not current.marked:\n            return current.value\n        return None\n    \n    def insert(self, key: Any, value: Any) -> bool:\n        preds, succs = self._find_preds_succs(key)\n        \n        if succs[0] and succs[0].key == key:\n            # Key already exists, update value\n            succs[0].value = value\n            return True\n        \n        new_level = self._random_level()\n        \n        if new_level > self.level:\n            with self.head.lock:\n                if new_level > self.level:\n                    for i in range(self.level + 1, new_level + 1):\n                        preds[i] = self.head\n                    self.level = new_level\n        \n        new_node = ConcurrentSkipListNode(key, value, new_level)\n        \n        for level in range(new_level + 1):\n            new_node.forward[level] = succs[level]\n            preds[level].forward[level] = new_node\n        \n        new_node.fully_linked = True\n        return True\n    \n    def delete(self, key: Any) -> bool:\n        victim = None\n        preds, succs = self._find_preds_succs(key)\n        \n        if succs[0] and succs[0].key == key:\n            victim = succs[0]\n        \n        if not victim:\n            return False\n        \n        victim.marked = True\n        \n        # Physically remove from all levels\n        for level in range(len(victim.forward)):\n            preds[level].forward[level] = victim.forward[level]\n        \n        return True\n    \n    def _find_preds_succs(self, key: Any) -> tuple:\n        preds = [None] * (self.max_level + 1)\n        succs = [None] * (self.max_level + 1)\n        \n        current = self.head\n        \n        for level in range(self.level, -1, -1):\n            while (current.forward[level] and \n                   current.forward[level].key < key):\n                current = current.forward[level]\n            \n            preds[level] = current\n            succs[level] = current.forward[level]\n        \n        return preds, succs\n    \n    def contains(self, key: Any) -> bool:\n        return self.find(key) is not None\n\ndef concurrent_skip_list(max_level=16):\n    return ConcurrentSkipList(max_level)","assertions":"skip_list = concurrent_skip_list()\n\n# Test concurrent operations\nskip_list.insert(1, \"one\")\nskip_list.insert(3, \"three\")\nskip_list.insert(2, \"two\")\n\nassert skip_list.find(1) == \"one\"\nassert skip_list.find(2) == \"two\"\nassert skip_list.find(3) == \"three\"\nassert skip_list.find(4) is None\n\n# Test delete\nassert skip_list.delete(2) == True\nassert skip_list.find(2) is None\nassert skip_list.delete(2) == False\n\n# Test contains\nassert skip_list.contains(1) == True\nassert skip_list.contains(4) == False","metadata":{"language":"Python","function_name":"concurrent_skip_list","difficulty":"very_advanced","category":"concurrency","complexity":0.95}}
{"query_id":"synthetic-031","query_text":"Write a Python function named `implement_avl_tree` that implements an AVL tree (self-balancing binary search tree) with insert and search operations. The tree should maintain balance through rotations and provide O(log n) operations. Language: Python. Function name: implement_avl_tree","reference_answer":"class AVLNode:\n    def __init__(self, key, value=None):\n        self.key = key\n        self.value = value\n        self.left = None\n        self.right = None\n        self.height = 1\n\nclass AVLTree:\n    def __init__(self):\n        self.root = None\n    \n    def _height(self, node):\n        if not node:\n            return 0\n        return node.height\n    \n    def _balance_factor(self, node):\n        if not node:\n            return 0\n        return self._height(node.left) - self._height(node.right)\n    \n    def _update_height(self, node):\n        if node:\n            node.height = 1 + max(self._height(node.left), self._height(node.right))\n    \n    def _right_rotate(self, y):\n        x = y.left\n        T2 = x.right\n        \n        x.right = y\n        y.left = T2\n        \n        self._update_height(y)\n        self._update_height(x)\n        \n        return x\n    \n    def _left_rotate(self, x):\n        y = x.right\n        T2 = y.left\n        \n        y.left = x\n        x.right = T2\n        \n        self._update_height(x)\n        self._update_height(y)\n        \n        return y\n    \n    def _balance(self, node):\n        self._update_height(node)\n        balance = self._balance_factor(node)\n        \n        # Left heavy\n        if balance > 1:\n            if self._balance_factor(node.left) < 0:\n                node.left = self._left_rotate(node.left)\n            return self._right_rotate(node)\n        \n        # Right heavy\n        if balance < -1:\n            if self._balance_factor(node.right) > 0:\n                node.right = self._right_rotate(node.right)\n            return self._left_rotate(node)\n        \n        return node\n    \n    def insert(self, key, value=None):\n        self.root = self._insert(self.root, key, value)\n        return self.root\n    \n    def _insert(self, node, key, value):\n        if not node:\n            return AVLNode(key, value)\n        \n        if key < node.key:\n            node.left = self._insert(node.left, key, value)\n        elif key > node.key:\n            node.right = self._insert(node.right, key, value)\n        else:\n            node.value = value  # Update value if key exists\n            return node\n        \n        return self._balance(node)\n    \n    def search(self, key):\n        return self._search(self.root, key)\n    \n    def _search(self, node, key):\n        if not node or node.key == key:\n            return node\n        \n        if key < node.key:\n            return self._search(node.left, key)\n        return self._search(node.right, key)\n\ndef implement_avl_tree():\n    return AVLTree()","assertions":"avl = implement_avl_tree()\n\n# Test insertions\navl.insert(10, \"ten\")\navl.insert(20, \"twenty\")\navl.insert(5, \"five\")\navl.insert(15, \"fifteen\")\navl.insert(25, \"twenty-five\")\n\n# Test search\nassert avl.search(10).value == \"ten\"\nassert avl.search(20).value == \"twenty\"\nassert avl.search(5).value == \"five\"\nassert avl.search(99) is None\n\n# Test balance (should maintain AVL properties)\nroot = avl.root\nbalance = abs(avl._height(root.left) - avl._height(root.right))\nassert balance <= 1","metadata":{"language":"Python","function_name":"implement_avl_tree","difficulty":"very_advanced","category":"data_structures","complexity":0.8}}
{"query_id":"synthetic-032","query_text":"Write a Python function named `distributed_consensus` that implements a simplified Raft consensus algorithm with leader election, log replication, and fault tolerance for a distributed key-value store. Language: Python. Function name: distributed_consensus","reference_answer":"import time\nimport random\nimport threading\nfrom typing import Dict, List, Optional, Any\nfrom enum import Enum\nfrom dataclasses import dataclass\n\nclass NodeState(Enum):\n    FOLLOWER = \"follower\"\n    CANDIDATE = \"candidate\"\n    LEADER = \"leader\"\n\n@dataclass\nclass LogEntry:\n    term: int\n    command: str\n    key: str\n    value: Any = None\n\nclass RaftNode:\n    def __init__(self, node_id: str, peers: List[str]):\n        self.node_id = node_id\n        self.peers = peers\n        \n        # Persistent state\n        self.current_term = 0\n        self.voted_for: Optional[str] = None\n        self.log: List[LogEntry] = []\n        \n        # Volatile state\n        self.commit_index = 0\n        self.last_applied = 0\n        \n        # Leader state\n        self.next_index: Dict[str, int] = {}\n        self.match_index: Dict[str, int] = {}\n        \n        # State\n        self.state = NodeState.FOLLOWER\n        self.votes_received = 0\n        self.leader_id: Optional[str] = None\n        \n        # Timers\n        self.election_timeout = random.uniform(1.0, 2.0)\n        self.last_heartbeat = time.time()\n        \n        # Data store\n        self.store: Dict[str, Any] = {}\n        \n        # Locks\n        self.lock = threading.RLock()\n    \n    def start_election(self):\n        with self.lock:\n            self.state = NodeState.CANDIDATE\n            self.current_term += 1\n            self.voted_for = self.node_id\n            self.votes_received = 1\n            self.leader_id = None\n            self.last_heartbeat = time.time()\n            \n            # Reset election timeout\n            self.election_timeout = random.uniform(1.0, 2.0)\n    \n    def become_leader(self):\n        with self.lock:\n            self.state = NodeState.LEADER\n            self.leader_id = self.node_id\n            \n            # Initialize leader state\n            next_idx = len(self.log) + 1\n            for peer in self.peers:\n                self.next_index[peer] = next_idx\n                self.match_index[peer] = 0\n    \n    def append_entries(self, term: int, leader_id: str, prev_log_index: int, \n                      prev_log_term: int, entries: List[LogEntry], leader_commit: int):\n        with self.lock:\n            # Reply false if term < currentTerm\n            if term < self.current_term:\n                return False, self.current_term\n            \n            # Convert to follower if newer term\n            if term > self.current_term:\n                self.current_term = term\n                self.state = NodeState.FOLLOWER\n                self.voted_for = None\n                self.leader_id = leader_id\n            \n            self.last_heartbeat = time.time()\n            \n            # Reply false if log doesn't contain an entry at prevLogIndex\n            if prev_log_index > 0:\n                if len(self.log) < prev_log_index:\n                    return False, self.current_term\n                if self.log[prev_log_index - 1].term != prev_log_term:\n                    return False, self.current_term\n            \n            # Append new entries\n            for i, entry in enumerate(entries):\n                index = prev_log_index + i + 1\n                if index > len(self.log):\n                    self.log.append(entry)\n                elif self.log[index - 1].term != entry.term:\n                    # Delete conflicting entries\n                    self.log = self.log[:index - 1]\n                    self.log.append(entry)\n            \n            # Update commit index\n            if leader_commit > self.commit_index:\n                self.commit_index = min(leader_commit, len(self.log))\n                self._apply_committed_entries()\n            \n            return True, self.current_term\n    \n    def _apply_committed_entries(self):\n        while self.last_applied < self.commit_index:\n            self.last_applied += 1\n            entry = self.log[self.last_applied - 1]\n            \n            # Apply command to state machine\n            if entry.command == \"set\":\n                self.store[entry.key] = entry.value\n            elif entry.command == \"delete\":\n                self.store.pop(entry.key, None)\n    \n    def get(self, key: str) -> Any:\n        with self.lock:\n            return self.store.get(key)\n    \n    def propose(self, command: str, key: str, value: Any = None) -> bool:\n        with self.lock:\n            if self.state != NodeState.LEADER:\n                return False\n            \n            # Append to local log\n            entry = LogEntry(self.current_term, command, key, value)\n            self.log.append(entry)\n            \n            # TODO: Replicate to followers\n            # For this simplified version, just commit locally\n            self.commit_index = len(self.log)\n            self._apply_committed_entries()\n            \n            return True\n\ndef distributed_consensus(node_id, peers):\n    return RaftNode(node_id, peers)","assertions":"import time\n\n# Test basic Raft node functionality\nnode = distributed_consensus(\"node1\", [\"node2\", \"node3\"])\n\n# Test initial state\nassert node.state == NodeState.FOLLOWER\nassert node.current_term == 0\nassert node.voted_for is None\n\n# Test election\nnode.start_election()\nassert node.state == NodeState.CANDIDATE\nassert node.current_term == 1\nassert node.voted_for == \"node1\"\n\n# Test log append\nentries = [LogEntry(1, \"set\", \"key1\", \"value1\")]\nsuccess, term = node.append_entries(1, \"node1\", 0, 0, entries, 0)\nassert success == True\nassert len(node.log) == 1\n\n# Test state machine application\nnode.commit_index = 1\nnode._apply_committed_entries()\nassert node.store[\"key1\"] == \"value1\"\n\n# Test get operation\nassert node.get(\"key1\") == \"value1\"\nassert node.get(\"nonexistent\") is None","metadata":{"language":"Python","function_name":"distributed_consensus","difficulty":"very_advanced","category":"concurrency","complexity":0.95}}
{"query_id":"synthetic-033","query_text":"Write a Python function named `implement_graph_bellman_ford` that implements the Bellman-Ford algorithm for finding shortest paths in graphs with negative edge weights. The function should detect negative cycles and return distances and paths. Language: Python. Function name: implement_graph_bellman_ford","reference_answer":"from typing import Dict, List, Tuple, Optional\n\nclass BellmanFordResult:\n    def __init__(self, distances: Dict[str, float], predecessors: Dict[str, Optional[str]], \n                 has_negative_cycle: bool):\n        self.distances = distances\n        self.predecessors = predecessors\n        self.has_negative_cycle = has_negative_cycle\n\ndef implement_graph_bellman_ford(graph: Dict[str, List[Tuple[str, int]]], start: str) -> BellmanFordResult:\n    # Initialize distances and predecessors\n    distances = {node: float('inf') for node in graph}\n    distances[start] = 0\n    predecessors = {node: None for node in graph}\n    \n    # Relax edges V-1 times\n    for _ in range(len(graph) - 1):\n        for node in graph:\n            for neighbor, weight in graph[node]:\n                if distances[node] != float('inf') and distances[node] + weight < distances[neighbor]:\n                    distances[neighbor] = distances[node] + weight\n                    predecessors[neighbor] = node\n    \n    # Check for negative cycles\n    has_negative_cycle = False\n    for node in graph:\n        for neighbor, weight in graph[node]:\n            if distances[node] != float('inf') and distances[node] + weight < distances[neighbor]:\n                has_negative_cycle = True\n                break\n        if has_negative_cycle:\n            break\n    \n    return BellmanFordResult(distances, predecessors, has_negative_cycle)","assertions":"graph = {\n    'A': [('B', 4), ('C', 2)],\n    'B': [('C', 3), ('D', 2)],\n    'C': [('B', 1), ('D', 4)],\n    'D': []\n}\n\nresult = implement_graph_bellman_ford(graph, 'A')\n\nassert result.distances['A'] == 0\nassert result.distances['B'] == 3  # A->C->B (2+1) better than A->B (4)\nassert result.distances['C'] == 2\nassert result.distances['D'] == 5  # A->C->B->D (2+1+2)\nassert result.has_negative_cycle == False\n\n# Test negative cycle detection\ngraph_with_cycle = {\n    'A': [('B', 1)],\n    'B': [('C', -3)],\n    'C': [('A', 2)]\n}\n\nresult_cycle = implement_graph_bellman_ford(graph_with_cycle, 'A')\nassert result_cycle.has_negative_cycle == True","metadata":{"language":"Python","function_name":"implement_graph_bellman_ford","difficulty":"very_advanced","category":"algorithms","complexity":0.85}}
{"query_id":"synthetic-034","query_text":"Write a Python function named `concurrent_hash_map` that implements a concurrent hash map with lock striping for high-throughput concurrent operations. The map should support get, put, and remove operations with minimal contention. Language: Python. Function name: concurrent_hash_map","reference_answer":"import threading\nimport math\nfrom typing import Dict, List, Any, Optional\n\nclass ConcurrentHashMap:\n    def __init__(self, initial_capacity: int = 16, load_factor: float = 0.75):\n        self.load_factor = load_factor\n        self.capacity = initial_capacity\n        self.size = 0\n        \n        # Lock striping - use multiple locks to reduce contention\n        self.num_locks = max(1, initial_capacity // 4)  # 1 lock per 4 buckets\n        self.locks: List[threading.RLock] = [threading.RLock() for _ in range(self.num_locks)]\n        \n        # Initialize buckets\n        self.buckets: List[Dict[Any, Any]] = [{} for _ in range(self.capacity)]\n    \n    def _get_lock(self, key) -> threading.RLock:\n        # Use hash of key to determine which lock to use\n        return self.locks[hash(key) % self.num_locks]\n    \n    def _get_bucket(self, key) -> Dict[Any, Any]:\n        return self.buckets[hash(key) % self.capacity]\n    \n    def put(self, key: Any, value: Any) -> Optional[Any]:\n        lock = self._get_lock(key)\n        with lock:\n            bucket = self._get_bucket(key)\n            old_value = bucket.get(key)\n            bucket[key] = value\n            \n            if old_value is None:\n                self.size += 1\n                self._check_resize()\n            \n            return old_value\n    \n    def get(self, key: Any) -> Optional[Any]:\n        lock = self._get_lock(key)\n        with lock:\n            bucket = self._get_bucket(key)\n            return bucket.get(key)\n    \n    def remove(self, key: Any) -> Optional[Any]:\n        lock = self._get_lock(key)\n        with lock:\n            bucket = self._get_bucket(key)\n            if key in bucket:\n                self.size -= 1\n                return bucket.pop(key)\n            return None\n    \n    def contains_key(self, key: Any) -> bool:\n        lock = self._get_lock(key)\n        with lock:\n            bucket = self._get_bucket(key)\n            return key in bucket\n    \n    def _check_resize(self):\n        if self.size > self.capacity * self.load_factor:\n            self._resize(self.capacity * 2)\n    \n    def _resize(self, new_capacity: int):\n        # Acquire all locks for resizing\n        for lock in self.locks:\n            lock.acquire()\n        \n        try:\n            old_buckets = self.buckets\n            self.capacity = new_capacity\n            self.buckets = [{} for _ in range(new_capacity)]\n            \n            # Rehash all entries\n            for bucket in old_buckets:\n                for key, value in bucket.items():\n                    new_bucket = self.buckets[hash(key) % new_capacity]\n                    new_bucket[key] = value\n        finally:\n            for lock in self.locks:\n                lock.release()\n    \n    def __len__(self) -> int:\n        return self.size\n\ndef concurrent_hash_map(initial_capacity=16):\n    return ConcurrentHashMap(initial_capacity)","assertions":"hash_map = concurrent_hash_map()\n\n# Test basic operations\nhash_map.put(\"key1\", \"value1\")\nhash_map.put(\"key2\", \"value2\")\nhash_map.put(\"key3\", \"value3\")\n\nassert hash_map.get(\"key1\") == \"value1\"\nassert hash_map.get(\"key2\") == \"value2\"\nassert hash_map.get(\"nonexistent\") is None\n\nassert hash_map.contains_key(\"key1\") == True\nassert hash_map.contains_key(\"nonexistent\") == False\n\n# Test remove\nremoved = hash_map.remove(\"key2\")\nassert removed == \"value2\"\nassert hash_map.get(\"key2\") is None\nassert len(hash_map) == 2\n\n# Test update\nold_value = hash_map.put(\"key1\", \"new_value\")\nassert old_value == \"value1\"\nassert hash_map.get(\"key1\") == \"new_value\"","metadata":{"language":"Python","function_name":"concurrent_hash_map","difficulty":"very_advanced","category":"concurrency","complexity":0.85}}
{"query_id":"synthetic-035","query_text":"Write a Python function named `implement_graph_floyd_warshall` that implements the Floyd-Warshall algorithm for finding all-pairs shortest paths in a weighted graph. The function should handle negative edges and detect negative cycles. Language: Python. Function name: implement_graph_floyd_warshall","reference_answer":"import copy\nfrom typing import List, Tuple\n\nclass FloydWarshallResult:\n    def __init__(self, distances: List[List[float]], has_negative_cycle: bool):\n        self.distances = distances\n        self.has_negative_cycle = has_negative_cycle\n\ndef implement_graph_floyd_warshall(graph: List[List[float]]) -> FloydWarshallResult:\n    n = len(graph)\n    # Initialize distance matrix\n    dist = copy.deepcopy(graph)\n    \n    # Set diagonal to 0 and infinity where no edge exists\n    for i in range(n):\n        for j in range(n):\n            if i == j:\n                dist[i][j] = 0\n            elif dist[i][j] == 0:  # Assuming 0 means no edge\n                dist[i][j] = float('inf')\n    \n    # Floyd-Warshall algorithm\n    for k in range(n):\n        for i in range(n):\n            for j in range(n):\n                if dist[i][k] != float('inf') and dist[k][j] != float('inf'):\n                    if dist[i][k] + dist[k][j] < dist[i][j]:\n                        dist[i][j] = dist[i][k] + dist[k][j]\n    \n    # Check for negative cycles\n    has_negative_cycle = False\n    for i in range(n):\n        if dist[i][i] < 0:\n            has_negative_cycle = True\n            break\n    \n    return FloydWarshallResult(dist, has_negative_cycle)","assertions":"# Test with a simple graph (4 nodes)\ngraph = [\n    [0, 3, float('inf'), 5],\n    [2, 0, float('inf'), 4],\n    [float('inf'), 1, 0, float('inf')],\n    [float('inf'), float('inf'), 2, 0]\n]\n\nresult = implement_graph_floyd_warshall(graph)\n\n# Check some expected distances\nassert result.distances[0][0] == 0  # Self distance\nassert result.distances[0][1] == 3  # Direct edge\nassert result.distances[0][2] == 6  # Path: 0->3->2 (5+2-1? Wait, recalculating)\n# Actually: 0->1->3->2 should be 3+4+2=9, or 0->3->2=5+2=7\n# Let's use a simpler test\n\n# Test no negative cycle\ngraph_simple = [\n    [0, 1, float('inf')],\n    [float('inf'), 0, 2],\n    [float('inf'), float('inf'), 0]\n]\n\nresult_simple = implement_graph_floyd_warshall(graph_simple)\nassert result_simple.has_negative_cycle == False\nassert result_simple.distances[0][1] == 1\nassert result_simple.distances[0][2] == 3\n\n# Test negative cycle detection\ngraph_cycle = [\n    [0, 1, float('inf')],\n    [float('inf'), 0, -2],\n    [-1, float('inf'), 0]\n]\n\nresult_cycle = implement_graph_floyd_warshall(graph_cycle)\nassert result_cycle.has_negative_cycle == True","metadata":{"language":"Python","function_name":"implement_graph_floyd_warshall","difficulty":"very_advanced","category":"algorithms","complexity":0.9}}
{"query_id":"synthetic-036","query_text":"Write a Python function named `async_task_orchestrator` that implements an async task orchestrator with dependency management, parallel execution, and failure handling. Tasks should be executed based on their dependencies with proper error propagation. Language: Python. Function name: async_task_orchestrator","reference_answer":"import asyncio\nfrom typing import Dict, List, Set, Any, Callable, Optional\nfrom collections import defaultdict, deque\nfrom dataclasses import dataclass\nfrom enum import Enum\n\nclass TaskStatus(Enum):\n    PENDING = \"pending\"\n    RUNNING = \"running\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n\n@dataclass\nclass Task:\n    id: str\n    func: Callable[[], Any]\n    dependencies: List[str]\n    status: TaskStatus = TaskStatus.PENDING\n    result: Any = None\n    error: Optional[Exception] = None\n\nclass AsyncTaskOrchestrator:\n    def __init__(self, max_concurrent: int = 10):\n        self.max_concurrent = max_concurrent\n        self.tasks: Dict[str, Task] = {}\n        self.dependency_graph: Dict[str, Set[str]] = defaultdict(set)\n        self.reverse_deps: Dict[str, Set[str]] = defaultdict(set)\n        self.semaphore = asyncio.Semaphore(max_concurrent)\n    \n    def add_task(self, task_id: str, func: Callable[[], Any], dependencies: List[str] = None):\n        dependencies = dependencies or []\n        task = Task(task_id, func, dependencies)\n        self.tasks[task_id] = task\n        \n        for dep in dependencies:\n            self.dependency_graph[task_id].add(dep)\n            self.reverse_deps[dep].add(task_id)\n    \n    async def execute(self) -> Dict[str, Any]:\n        results = {}\n        \n        # Find tasks with no dependencies\n        ready_queue = deque()\n        for task_id, task in self.tasks.items():\n            if not task.dependencies:\n                ready_queue.append(task_id)\n        \n        running_tasks = set()\n        \n        while ready_queue or running_tasks:\n            # Start ready tasks up to concurrency limit\n            while ready_queue and len(running_tasks) < self.max_concurrent:\n                task_id = ready_queue.popleft()\n                task = self.tasks[task_id]\n                if task.status == TaskStatus.PENDING:\n                    task.status = TaskStatus.RUNNING\n                    running_tasks.add(task_id)\n                    asyncio.create_task(self._execute_task(task_id))\n            \n            # Wait for at least one task to complete\n            if running_tasks:\n                await asyncio.sleep(0.01)\n                \n                # Check for completed tasks\n                completed = [tid for tid in running_tasks \n                           if self.tasks[tid].status in (TaskStatus.COMPLETED, TaskStatus.FAILED)]\n                \n                for task_id in completed:\n                    running_tasks.remove(task_id)\n                    task = self.tasks[task_id]\n                    \n                    if task.status == TaskStatus.COMPLETED:\n                        results[task_id] = task.result\n                        # Add dependent tasks to ready queue\n                        for dependent in self.reverse_deps[task_id]:\n                            dep_task = self.tasks[dependent]\n                            if (all(self.tasks[dep].status == TaskStatus.COMPLETED \n                                  for dep in dep_task.dependencies) and \n                                dep_task.status == TaskStatus.PENDING):\n                                ready_queue.append(dependent)\n                    else:\n                        # Task failed - mark dependent tasks as failed too\n                        self._propagate_failure(task_id)\n            else:\n                break\n        \n        return results\n    \n    async def _execute_task(self, task_id: str):\n        task = self.tasks[task_id]\n        try:\n            async with self.semaphore:\n                if asyncio.iscoroutinefunction(task.func):\n                    result = await task.func()\n                else:\n                    result = await asyncio.get_event_loop().run_in_executor(None, task.func)\n                \n                task.result = result\n                task.status = TaskStatus.COMPLETED\n        except Exception as e:\n            task.error = e\n            task.status = TaskStatus.FAILED\n    \n    def _propagate_failure(self, failed_task_id: str):\n        # Recursively mark dependent tasks as failed\n        to_process = deque([failed_task_id])\n        processed = set()\n        \n        while to_process:\n            task_id = to_process.popleft()\n            if task_id in processed:\n                continue\n            processed.add(task_id)\n            \n            # Mark as failed if not already completed\n            task = self.tasks[task_id]\n            if task.status != TaskStatus.COMPLETED:\n                task.status = TaskStatus.FAILED\n                task.error = Exception(f\"Dependency {failed_task_id} failed\")\n            \n            # Add dependents to processing queue\n            for dependent in self.reverse_deps[task_id]:\n                to_process.append(dependent)\n    \n    def get_task_status(self, task_id: str) -> TaskStatus:\n        return self.tasks[task_id].status\n\ndef async_task_orchestrator(max_concurrent=10):\n    return AsyncTaskOrchestrator(max_concurrent)","assertions":"import asyncio\n\nasync def test_orchestrator():\n    orchestrator = AsyncTaskOrchestrator(max_concurrent=3)\n    \n    # Add tasks with dependencies\n    async def task_a():\n        await asyncio.sleep(0.1)\n        return \"A\"\n    \n    def task_b():\n        return \"B\"\n    \n    async def task_c():\n        await asyncio.sleep(0.05)\n        return \"C\"\n    \n    async def task_d():\n        await asyncio.sleep(0.02)\n        return f\"D-{orchestrator.tasks['task_a'].result}-{orchestrator.tasks['task_b'].result}\"\n    \n    orchestrator.add_task(\"task_a\", task_a)\n    orchestrator.add_task(\"task_b\", task_b)\n    orchestrator.add_task(\"task_c\", task_c)\n    orchestrator.add_task(\"task_d\", task_d, [\"task_a\", \"task_b\"])\n    \n    results = await orchestrator.execute()\n    \n    assert \"task_a\" in results\n    assert \"task_b\" in results\n    assert \"task_c\" in results\n    assert \"task_d\" in results\n    assert results[\"task_a\"] == \"A\"\n    assert results[\"task_b\"] == \"B\"\n    assert results[\"task_d\"] == \"D-A-B\"\n\nasyncio.run(test_orchestrator())","metadata":{"language":"Python","function_name":"async_task_orchestrator","difficulty":"very_advanced","category":"concurrency","complexity":0.9}}
{"query_id":"synthetic-037","query_text":"Write a Python function named `implement_heap_median` that implements a data structure to efficiently find the median of a stream of numbers using two heaps (max-heap for lower half, min-heap for upper half). Language: Python. Function name: implement_heap_median","reference_answer":"import heapq\nfrom typing import List\n\nclass MedianFinder:\n    def __init__(self):\n        # Max-heap for lower half (use negative values for max-heap)\n        self.lower_half = []  # Max-heap (inverted)\n        # Min-heap for upper half\n        self.upper_half = []  # Min-heap\n    \n    def add_number(self, num: int) -> None:\n        # Add to appropriate heap\n        if not self.lower_half or num <= -self.lower_half[0]:\n            heapq.heappush(self.lower_half, -num)\n        else:\n            heapq.heappush(self.upper_half, num)\n        \n        # Balance heaps\n        if len(self.lower_half) > len(self.upper_half) + 1:\n            # Move from lower to upper\n            val = -heapq.heappop(self.lower_half)\n            heapq.heappush(self.upper_half, val)\n        elif len(self.upper_half) > len(self.lower_half):\n            # Move from upper to lower\n            val = heapq.heappop(self.upper_half)\n            heapq.heappush(self.lower_half, -val)\n    \n    def find_median(self) -> float:\n        if not self.lower_half and not self.upper_half:\n            raise ValueError(\"No numbers added yet\")\n        \n        if len(self.lower_half) > len(self.upper_half):\n            # Odd number of elements\n            return -self.lower_half[0]\n        else:\n            # Even number of elements\n            return (-self.lower_half[0] + self.upper_half[0]) / 2\n\ndef implement_heap_median():\n    return MedianFinder()","assertions":"finder = implement_heap_median()\n\n# Test with odd number of elements\nfinder.add_number(1)\nassert finder.find_median() == 1.0\n\nfinder.add_number(2)\nassert finder.find_median() == 1.5\n\nfinder.add_number(3)\nassert finder.find_median() == 2.0\n\n# Test with even number\nfinder.add_number(4)\nassert finder.find_median() == 2.5\n\nfinder.add_number(5)\nassert finder.find_median() == 3.0\n\n# Test unsorted order\nfinder2 = implement_heap_median()\nnumbers = [5, 2, 8, 1, 9, 3]\nfor num in numbers:\n    finder2.add_number(num)\n\nassert finder2.find_median() == 4.0  # Sorted: [1,2,3,5,8,9], median = (3+5)/2 = 4","metadata":{"language":"Python","function_name":"implement_heap_median","difficulty":"very_advanced","category":"data_structures","complexity":0.8}}
{"query_id":"synthetic-038","query_text":"Write a Python function named `distributed_pub_sub` that implements a distributed publish-subscribe system with topic-based routing, message persistence, and fault-tolerant delivery using Redis as the backend. Language: Python. Function name: distributed_pub_sub","reference_answer":"import redis\nimport json\nimport time\nimport uuid\nfrom typing import Dict, List, Any, Callable, Optional\nfrom dataclasses import dataclass\n\n@dataclass\nclass Message:\n    id: str\n    topic: str\n    payload: Any\n    timestamp: float\n    publisher_id: str\n\nclass DistributedPubSub:\n    def __init__(self, redis_host: str = \"localhost\", redis_port: int = 6379, \n                 node_id: Optional[str] = None):\n        self.redis = redis.Redis(host=redis_host, port=redis_port, decode_responses=True)\n        self.node_id = node_id or str(uuid.uuid4())\n        \n        # Topic subscriptions: topic -> list of subscriber callbacks\n        self.subscriptions: Dict[str, List[Callable[[Message], None]]] = {}\n        \n        # Message persistence\n        self.message_ttl = 3600  # 1 hour\n        \n        # Fault tolerance\n        self.retry_attempts = 3\n        self.retry_delay = 1.0\n    \n    def publish(self, topic: str, payload: Any) -> str:\n        message = Message(\n            id=str(uuid.uuid4()),\n            topic=topic,\n            payload=payload,\n            timestamp=time.time(),\n            publisher_id=self.node_id\n        )\n        \n        # Serialize message\n        message_data = {\n            \"id\": message.id,\n            \"topic\": message.topic,\n            \"payload\": message.payload,\n            \"timestamp\": message.timestamp,\n            \"publisher_id\": message.publisher_id\n        }\n        \n        # Store message persistently\n        message_key = f\"message:{message.id}\"\n        self.redis.setex(message_key, self.message_ttl, json.dumps(message_data))\n        \n        # Add to topic queue\n        topic_key = f\"topic:{topic}\"\n        self.redis.lpush(topic_key, message.id)\n        self.redis.expire(topic_key, self.message_ttl)\n        \n        # Publish to subscribers (if any local subscribers)\n        if topic in self.subscriptions:\n            for callback in self.subscriptions[topic]:\n                try:\n                    callback(message)\n                except Exception as e:\n                    print(f\"Error in subscriber callback: {e}\")\n        \n        return message.id\n    \n    def subscribe(self, topic: str, callback: Callable[[Message], None]) -> None:\n        if topic not in self.subscriptions:\n            self.subscriptions[topic] = []\n        self.subscriptions[topic].append(callback)\n    \n    def unsubscribe(self, topic: str, callback: Callable[[Message], None]) -> bool:\n        if topic in self.subscriptions:\n            try:\n                self.subscriptions[topic].remove(callback)\n                return True\n            except ValueError:\n                pass\n        return False\n    \n    def get_topic_messages(self, topic: str, limit: int = 100) -> List[Message]:\n        topic_key = f\"topic:{topic}\"\n        message_ids = self.redis.lrange(topic_key, 0, limit - 1)\n        \n        messages = []\n        for msg_id in message_ids:\n            message_key = f\"message:{msg_id}\"\n            message_data = self.redis.get(message_key)\n            if message_data:\n                try:\n                    data = json.loads(message_data)\n                    message = Message(**data)\n                    messages.append(message)\n                except (json.JSONDecodeError, TypeError):\n                    continue\n        \n        return messages\n    \n    def acknowledge_message(self, message_id: str) -> bool:\n        # For more advanced implementations, track delivery acknowledgments\n        # For now, just mark as processed\n        ack_key = f\"ack:{message_id}\"\n        return bool(self.redis.setex(ack_key, self.message_ttl, self.node_id))\n    \n    def cleanup_expired_messages(self) -> int:\n        # Find and cleanup expired messages\n        cleaned = 0\n        \n        # Get all message keys (this is simplified - in production, use SCAN)\n        message_keys = self.redis.keys(\"message:*\")\n        for key in message_keys:\n            if not self.redis.exists(key):\n                # Message has expired\n                msg_id = key.split(\":\", 1)[1]\n                \n                # Remove from topic queues\n                topic_keys = self.redis.keys(\"topic:*\")\n                for topic_key in topic_keys:\n                    self.redis.lrem(topic_key, 0, msg_id)\n                \n                cleaned += 1\n        \n        return cleaned\n\ndef distributed_pub_sub(redis_host=\"localhost\", redis_port=6379):\n    return DistributedPubSub(redis_host, redis_port)","assertions":"# Test basic pub-sub operations (would need Redis running)\npubsub = DistributedPubSub()\n\nreceived_messages = []\n\ndef test_callback(message):\n    received_messages.append(message)\n\n# Subscribe to a topic\npubsub.subscribe(\"test_topic\", test_callback)\n\n# Publish a message\nmsg_id = pubsub.publish(\"test_topic\", {\"data\": \"test payload\"})\nassert msg_id is not None\nassert len(msg_id) > 0  # Should be a UUID string\n\n# Check that local subscriber received the message\nassert len(received_messages) == 1\nassert received_messages[0].topic == \"test_topic\"\nassert received_messages[0].payload == {\"data\": \"test payload\"}\n\n# Test getting topic messages\nmessages = pubsub.get_topic_messages(\"test_topic\", limit=10)\nassert len(messages) >= 1\nassert messages[0].topic == \"test_topic\"\n\n# Test unsubscribe\nassert pubsub.unsubscribe(\"test_topic\", test_callback) == True\nassert pubsub.unsubscribe(\"test_topic\", test_callback) == False  # Already unsubscribed","metadata":{"language":"Python","function_name":"distributed_pub_sub","difficulty":"very_advanced","category":"concurrency","complexity":0.9}}
{"query_id":"synthetic-039","query_text":"Write a Python function named `implement_segment_tree` that implements a segment tree for range minimum queries and range updates. The tree should support efficient range queries and point updates. Language: Python. Function name: implement_segment_tree","reference_answer":"import math\nfrom typing import List, Optional\n\nclass SegmentTree:\n    def __init__(self, arr: List[int]):\n        self.n = len(arr)\n        self.tree = [0] * (4 * self.n)\n        self.lazy = [0] * (4 * self.n)\n        self._build(arr, 0, 0, self.n - 1)\n    \n    def _build(self, arr: List[int], node: int, start: int, end: int):\n        if start == end:\n            self.tree[node] = arr[start]\n            return\n        \n        mid = (start + end) // 2\n        self._build(arr, 2 * node + 1, start, mid)\n        self._build(arr, 2 * node + 2, mid + 1, end)\n        self.tree[node] = min(self.tree[2 * node + 1], self.tree[2 * node + 2])\n    \n    def _propagate_lazy(self, node: int, start: int, end: int):\n        if self.lazy[node] != 0:\n            self.tree[node] += self.lazy[node]\n            if start != end:\n                self.lazy[2 * node + 1] += self.lazy[node]\n                self.lazy[2 * node + 2] += self.lazy[node]\n            self.lazy[node] = 0\n    \n    def update_range(self, left: int, right: int, val: int):\n        self._update_range(0, 0, self.n - 1, left, right, val)\n    \n    def _update_range(self, node: int, start: int, end: int, left: int, right: int, val: int):\n        self._propagate_lazy(node, start, end)\n        \n        if start > end or start > right or end < left:\n            return\n        \n        if left <= start and end <= right:\n            self.lazy[node] += val\n            self._propagate_lazy(node, start, end)\n            return\n        \n        mid = (start + end) // 2\n        self._update_range(2 * node + 1, start, mid, left, right, val)\n        self._update_range(2 * node + 2, mid + 1, end, left, right, val)\n        self.tree[node] = min(self.tree[2 * node + 1], self.tree[2 * node + 2])\n    \n    def query_range(self, left: int, right: int) -> int:\n        return self._query_range(0, 0, self.n - 1, left, right)\n    \n    def _query_range(self, node: int, start: int, end: int, left: int, right: int) -> int:\n        self._propagate_lazy(node, start, end)\n        \n        if start > end or start > right or end < left:\n            return float('inf')\n        \n        if left <= start and end <= right:\n            return self.tree[node]\n        \n        mid = (start + end) // 2\n        left_min = self._query_range(2 * node + 1, start, mid, left, right)\n        right_min = self._query_range(2 * node + 2, mid + 1, end, left, right)\n        return min(left_min, right_min)\n    \n    def update_point(self, index: int, val: int):\n        self.update_range(index, index, val - self.query_range(index, index))\n\ndef implement_segment_tree(arr):\n    return SegmentTree(arr)","assertions":"arr = [1, 3, 2, 7, 9, 11]\nseg_tree = implement_segment_tree(arr)\n\n# Test range minimum queries\nassert seg_tree.query_range(0, 2) == 1  # min(1, 3, 2)\nassert seg_tree.query_range(3, 5) == 7  # min(7, 9, 11)\nassert seg_tree.query_range(1, 4) == 2  # min(3, 2, 7, 9)\n\n# Test point updates\nseg_tree.update_point(2, 0)  # Change index 2 from 2 to 0\nassert seg_tree.query_range(0, 2) == 0  # min(1, 3, 0)\n\n# Test range updates\nseg_tree.update_range(1, 3, 10)  # Add 10 to range [1, 3]\nassert seg_tree.query_range(1, 3) == 10  # min(13, 10, 17) = 10\nassert seg_tree.query_range(0, 0) == 1   # Index 0 unchanged\nassert seg_tree.query_range(4, 5) == 9   # min(9, 11) unchanged","metadata":{"language":"Python","function_name":"implement_segment_tree","difficulty":"very_advanced","category":"data_structures","complexity":0.9}}
{"query_id":"synthetic-040","query_text":"Write a Python function named `async_circuit_breaker_advanced` that implements an advanced circuit breaker with adaptive thresholds, multiple failure modes, and recovery strategies. The breaker should automatically adjust based on system load and error patterns. Language: Python. Function name: async_circuit_breaker_advanced","reference_answer":"import asyncio\nimport time\nimport statistics\nfrom typing import Dict, List, Any, Callable, Optional\nfrom enum import Enum\nfrom dataclasses import dataclass\nfrom collections import deque\n\nclass CircuitState(Enum):\n    CLOSED = \"closed\"\n    OPEN = \"open\"\n    HALF_OPEN = \"half_open\"\n\nclass FailureMode(Enum):\n    TIMEOUT = \"timeout\"\n    EXCEPTION = \"exception\"\n    HTTP_ERROR = \"http_error\"\n    RATE_LIMIT = \"rate_limit\"\n\n@dataclass\nclass CircuitMetrics:\n    total_calls: int = 0\n    successful_calls: int = 0\n    failed_calls: int = 0\n    total_latency: float = 0.0\n    recent_latencies: deque = None\n    failure_counts: Dict[FailureMode, int] = None\n    \n    def __post_init__(self):\n        self.recent_latencies = deque(maxlen=100)\n        self.failure_counts = {mode: 0 for mode in FailureMode}\n\nclass AdvancedCircuitBreaker:\n    def __init__(self, name: str, initial_threshold: float = 0.5, \n                 min_threshold: float = 0.1, max_threshold: float = 0.8):\n        self.name = name\n        self.state = CircuitState.CLOSED\n        self.metrics = CircuitMetrics()\n        \n        # Adaptive thresholds\n        self.failure_threshold = initial_threshold\n        self.min_threshold = min_threshold\n        self.max_threshold = max_threshold\n        \n        # Timing\n        self.last_failure_time = 0\n        self.open_duration = 60.0  # 1 minute\n        self.half_open_max_calls = 3\n        self.half_open_success_count = 0\n        \n        # Adaptive parameters\n        self.adaptation_window = 300  # 5 minutes\n        self.last_adaptation = time.time()\n        \n        self.lock = asyncio.Lock()\n    \n    async def call(self, func: Callable, *args, **kwargs) -> Any:\n        async with self.lock:\n            if self.state == CircuitState.OPEN:\n                if self._should_attempt_reset():\n                    self.state = CircuitState.HALF_OPEN\n                    self.half_open_success_count = 0\n                else:\n                    raise CircuitBreakerOpenException(f\"Circuit {self.name} is OPEN\")\n            \n            try:\n                start_time = time.time()\n                result = await func(*args, **kwargs)\n                latency = time.time() - start_time\n                \n                await self._record_success(latency)\n                return result\n            \n            except asyncio.TimeoutError:\n                await self._record_failure(FailureMode.TIMEOUT)\n                raise\n            except Exception as e:\n                # Classify failure mode\n                if hasattr(e, 'status') and 400 <= e.status < 500:\n                    failure_mode = FailureMode.HTTP_ERROR\n                elif \"rate limit\" in str(e).lower():\n                    failure_mode = FailureMode.RATE_LIMIT\n                else:\n                    failure_mode = FailureMode.EXCEPTION\n                \n                await self._record_failure(failure_mode)\n                raise\n    \n    async def _record_success(self, latency: float):\n        self.metrics.total_calls += 1\n        self.metrics.successful_calls += 1\n        self.metrics.total_latency += latency\n        self.metrics.recent_latencies.append(latency)\n        \n        if self.state == CircuitState.HALF_OPEN:\n            self.half_open_success_count += 1\n            if self.half_open_success_count >= self.half_open_max_calls:\n                self.state = CircuitState.CLOSED\n                self._adapt_thresholds()\n        \n        # Adapt thresholds periodically\n        if time.time() - self.last_adaptation > self.adaptation_window:\n            self._adapt_thresholds()\n    \n    async def _record_failure(self, failure_mode: FailureMode):\n        self.metrics.total_calls += 1\n        self.metrics.failed_calls += 1\n        self.metrics.failure_counts[failure_mode] += 1\n        self.last_failure_time = time.time()\n        \n        failure_rate = self.metrics.failed_calls / self.metrics.total_calls\n        if failure_rate > self.failure_threshold:\n            self.state = CircuitState.OPEN\n    \n    def _should_attempt_reset(self) -> bool:\n        return time.time() - self.last_failure_time > self.open_duration\n    \n    def _adapt_thresholds(self):\n        if len(self.metrics.recent_latencies) < 10:\n            return\n        \n        # Calculate system health metrics\n        failure_rate = self.metrics.failed_calls / max(1, self.metrics.total_calls)\n        avg_latency = statistics.mean(self.metrics.recent_latencies)\n        \n        # Adjust threshold based on system conditions\n        if failure_rate < 0.1 and avg_latency < 1.0:\n            # System healthy, can be more tolerant\n            self.failure_threshold = min(self.max_threshold, self.failure_threshold + 0.05)\n        elif failure_rate > 0.3 or avg_latency > 5.0:\n            # System struggling, be more strict\n            self.failure_threshold = max(self.min_threshold, self.failure_threshold - 0.05)\n        \n        self.last_adaptation = time.time()\n    \n    def get_metrics(self) -> Dict[str, Any]:\n        failure_rate = self.metrics.failed_calls / max(1, self.metrics.total_calls)\n        avg_latency = (self.metrics.total_latency / max(1, self.metrics.successful_calls)) \\\n                     if self.metrics.successful_calls > 0 else 0\n        \n        return {\n            \"state\": self.state.value,\n            \"failure_rate\": failure_rate,\n            \"avg_latency\": avg_latency,\n            \"total_calls\": self.metrics.total_calls,\n            \"failure_counts\": dict(self.metrics.failure_counts)\n        }\n\nclass CircuitBreakerOpenException(Exception):\n    pass\n\ndef async_circuit_breaker_advanced(name, initial_threshold=0.5):\n    return AdvancedCircuitBreaker(name, initial_threshold)","assertions":"import asyncio\n\nasync def test_breaker():\n    breaker = AdvancedCircuitBreaker(\"test_circuit\", initial_threshold=0.6)\n    \n    call_count = 0\n    \n    async def failing_func():\n        nonlocal call_count\n        call_count += 1\n        if call_count <= 3:  # Fail first 3 calls\n            raise Exception(\"Simulated failure\")\n        return \"success\"\n    \n    # Test initial state\n    assert breaker.state == CircuitState.CLOSED\n    \n    # Cause failures\n    for _ in range(3):\n        try:\n            await breaker.call(failing_func)\n        except Exception:\n            pass\n    \n    # Should still be closed (failure rate 3/3 = 1.0, but threshold is 0.6)\n    # Actually, let's check the metrics\n    metrics = breaker.get_metrics()\n    assert metrics[\"total_calls\"] == 3\n    assert metrics[\"failure_rate\"] == 1.0\n    \n    # Breaker should be open now\n    assert breaker.state == CircuitState.OPEN\n    \n    # Test successful call after reset timeout\n    breaker.open_duration = 0.1  # Short timeout for testing\n    await asyncio.sleep(0.2)\n    \n    result = await breaker.call(failing_func)  # This should succeed\n    assert result == \"success\"\n    assert breaker.state == CircuitState.HALF_OPEN\n\nasyncio.run(test_breaker())","metadata":{"language":"Python","function_name":"async_circuit_breaker_advanced","difficulty":"very_advanced","category":"concurrency","complexity":0.95}}
{"query_id":"synthetic-041","query_text":"Write a TypeScript function named `binarySearch` that implements binary search on a sorted array. The function should return the index of the target element if found, or -1 if not found. Handle edge cases like empty arrays and single element arrays. Language: TypeScript. Function name: binarySearch","reference_answer":"function binarySearch(arr: number[], target: number): number {\n    if (arr.length === 0) {\n        return -1;\n    }\n    \n    let left = 0;\n    let right = arr.length - 1;\n    \n    while (left <= right) {\n        const mid = Math.floor(left + (right - left) / 2);\n        \n        if (arr[mid] === target) {\n            return mid;\n        } else if (arr[mid] < target) {\n            left = mid + 1;\n        } else {\n            right = mid - 1;\n        }\n    }\n    \n    return -1;\n}","assertions":"if (binarySearch([], 5) !== -1) throw new Error(\"Failed: empty array\");\nif (binarySearch([1], 1) !== 0) throw new Error(\"Failed: single element found\");\nif (binarySearch([1], 2) !== -1) throw new Error(\"Failed: single element not found\");\nif (binarySearch([1, 2, 3, 4, 5], 3) !== 2) throw new Error(\"Failed: middle element\");\nif (binarySearch([1, 2, 3, 4, 5], 6) !== -1) throw new Error(\"Failed: element not in array\");\nif (binarySearch([1, 3, 5, 7, 9], 7) !== 3) throw new Error(\"Failed: odd length array\");","metadata":{"language":"TypeScript","function_name":"binarySearch","difficulty":"medium","category":"algorithms","complexity":0.4}}
{"query_id":"synthetic-042","query_text":"Write a TypeScript function named `mergeSort` that implements the merge sort algorithm to sort an array of numbers in ascending order. The function should use a recursive approach and return a new sorted array without modifying the original. Language: TypeScript. Function name: mergeSort","reference_answer":"function mergeSort(arr: number[]): number[] {\n    if (arr.length <= 1) {\n        return arr.slice();\n    }\n    \n    const mid = Math.floor(arr.length / 2);\n    const left = mergeSort(arr.slice(0, mid));\n    const right = mergeSort(arr.slice(mid));\n    \n    return merge(left, right);\n}\n\nfunction merge(left: number[], right: number[]): number[] {\n    const result: number[] = [];\n    let i = 0;\n    let j = 0;\n    \n    while (i < left.length && j < right.length) {\n        if (left[i] <= right[j]) {\n            result.push(left[i]);\n            i++;\n        } else {\n            result.push(right[j]);\n            j++;\n        }\n    }\n    \n    return result.concat(left.slice(i)).concat(right.slice(j));\n}","assertions":"if (JSON.stringify(mergeSort([])) !== JSON.stringify([])) throw new Error(\"Failed: empty array\");\nif (JSON.stringify(mergeSort([1])) !== JSON.stringify([1])) throw new Error(\"Failed: single element\");\nif (JSON.stringify(mergeSort([3, 1, 4, 1, 5])) !== JSON.stringify([1, 1, 3, 4, 5])) throw new Error(\"Failed: unsorted array\");\nif (JSON.stringify(mergeSort([5, 4, 3, 2, 1])) !== JSON.stringify([1, 2, 3, 4, 5])) throw new Error(\"Failed: reverse sorted\");\nif (JSON.stringify(mergeSort([1, 3, 2, 5, 4])) !== JSON.stringify([1, 2, 3, 4, 5])) throw new Error(\"Failed: mixed order\");","metadata":{"language":"TypeScript","function_name":"mergeSort","difficulty":"medium","category":"algorithms","complexity":0.45}}
{"query_id":"synthetic-043","query_text":"Write a TypeScript function named `isValidParentheses` that checks if a string containing only parentheses characters '(', ')', '{', '}', '[', ']' is valid. A string is valid if all brackets are properly closed and nested. Language: TypeScript. Function name: isValidParentheses","reference_answer":"function isValidParentheses(s: string): boolean {\n    const stack: string[] = [];\n    const bracketMap: { [key: string]: string } = {\n        ')': '(',\n        '}': '{',\n        ']': '['\n    };\n    \n    for (const char of s) {\n        if (char in bracketMap) {\n            const top = stack.pop();\n            if (bracketMap[char] !== top) {\n                return false;\n            }\n        } else {\n            stack.push(char);\n        }\n    }\n    \n    return stack.length === 0;\n}","assertions":"if (!isValidParentheses(\"\")) throw new Error(\"Failed: empty string\");\nif (!isValidParentheses(\"()\")) throw new Error(\"Failed: simple pair\");\nif (!isValidParentheses(\"()[]{}\")) throw new Error(\"Failed: multiple types\");\nif (isValidParentheses(\"(]\")) throw new Error(\"Failed: mismatched brackets\");\nif (isValidParentheses(\"([)]\")) throw new Error(\"Failed: wrong order\");\nif (!isValidParentheses(\"{[]}\")) throw new Error(\"Failed: nested brackets\");\nif (isValidParentheses(\"[\")) throw new Error(\"Failed: unclosed bracket\");\nif (isValidParentheses(\"]\")) throw new Error(\"Failed: single closing bracket\");","metadata":{"language":"TypeScript","function_name":"isValidParentheses","difficulty":"medium","category":"data_structures","complexity":0.4}}
{"query_id":"synthetic-044","query_text":"Write a TypeScript function named `fibonacciMemo` that calculates the nth Fibonacci number using memoization to optimize performance. The function should handle large n values efficiently and return the result. Language: TypeScript. Function name: fibonacciMemo","reference_answer":"function fibonacciMemo(n: number): number {\n    if (n < 0) {\n        throw new Error(\"n must be non-negative\");\n    }\n    \n    const memo: { [key: number]: number } = {};\n    \n    function fib(k: number): number {\n        if (k in memo) {\n            return memo[k];\n        }\n        if (k <= 1) {\n            return k;\n        }\n        memo[k] = fib(k - 1) + fib(k - 2);\n        return memo[k];\n    }\n    \n    return fib(n);\n}","assertions":"if (fibonacciMemo(0) !== 0) throw new Error(\"Failed: F(0)\");\nif (fibonacciMemo(1) !== 1) throw new Error(\"Failed: F(1)\");\nif (fibonacciMemo(2) !== 1) throw new Error(\"Failed: F(2)\");\nif (fibonacciMemo(5) !== 5) throw new Error(\"Failed: F(5)\");\nif (fibonacciMemo(10) !== 55) throw new Error(\"Failed: F(10)\");\nif (fibonacciMemo(20) !== 6765) throw new Error(\"Failed: F(20)\");\n\ntry {\n    fibonacciMemo(-1);\n    throw new Error(\"Should have thrown for negative n\");\n} catch (e) {\n    if (!(e instanceof Error) || e.message !== \"n must be non-negative\") {\n        throw new Error(\"Wrong error for negative n\");\n    }\n}","metadata":{"language":"TypeScript","function_name":"fibonacciMemo","difficulty":"medium","category":"algorithms","complexity":0.45}}
{"query_id":"synthetic-045","query_text":"Write a TypeScript function named `reverseLinkedList` that reverses a singly linked list. The function should take the head of the linked list as input and return the new head of the reversed list. You can assume a ListNode interface with val and next properties. Language: TypeScript. Function name: reverseLinkedList","reference_answer":"interface ListNode {\n    val: number;\n    next: ListNode | null;\n}\n\nfunction reverseLinkedList(head: ListNode | null): ListNode | null {\n    let prev: ListNode | null = null;\n    let current = head;\n    \n    while (current !== null) {\n        const next = current.next;\n        current.next = prev;\n        prev = current;\n        current = next;\n    }\n    \n    return prev;\n}","assertions":"function createLinkedList(arr: number[]): ListNode | null {\n    if (arr.length === 0) return null;\n    const head: ListNode = { val: arr[0], next: null };\n    let current = head;\n    for (let i = 1; i < arr.length; i++) {\n        current.next = { val: arr[i], next: null };\n        current = current.next;\n    }\n    return head;\n}\n\nfunction linkedListToArray(head: ListNode | null): number[] {\n    const result: number[] = [];\n    let current = head;\n    while (current !== null) {\n        result.push(current.val);\n        current = current.next;\n    }\n    return result;\n}\n\nif (JSON.stringify(linkedListToArray(reverseLinkedList(createLinkedList([])))) !== JSON.stringify([])) throw new Error(\"Failed: empty list\");\nif (JSON.stringify(linkedListToArray(reverseLinkedList(createLinkedList([1])))) !== JSON.stringify([1])) throw new Error(\"Failed: single node\");\nif (JSON.stringify(linkedListToArray(reverseLinkedList(createLinkedList([1, 2, 3])))) !== JSON.stringify([3, 2, 1])) throw new Error(\"Failed: three nodes\");\nif (JSON.stringify(linkedListToArray(reverseLinkedList(createLinkedList([1, 2, 3, 4, 5])))) !== JSON.stringify([5, 4, 3, 2, 1])) throw new Error(\"Failed: five nodes\");","metadata":{"language":"TypeScript","function_name":"reverseLinkedList","difficulty":"medium","category":"data_structures","complexity":0.5}}
{"query_id":"synthetic-046","query_text":"Write a TypeScript function named `wordFrequency` that takes a string of text and returns a Map with word frequencies, ignoring case and punctuation. Words should be normalized to lowercase and punctuation should be removed. Language: TypeScript. Function name: wordFrequency","reference_answer":"function wordFrequency(text: string): Map<string, number> {\n    if (!text) {\n        return new Map();\n    }\n    \n    // Remove punctuation and convert to lowercase\n    const cleanedText = text.replace(/[^\\w\\s]/g, '').toLowerCase();\n    \n    // Split into words and count\n    const words = cleanedText.split(/\\s+/).filter(word => word.length > 0);\n    const frequency = new Map<string, number>();\n    \n    for (const word of words) {\n        frequency.set(word, (frequency.get(word) || 0) + 1);\n    }\n    \n    return frequency;\n}","assertions":"function mapToObject(map: Map<string, number>): { [key: string]: number } {\n    const obj: { [key: string]: number } = {};\n    map.forEach((value, key) => obj[key] = value);\n    return obj;\n}\n\nif (Object.keys(mapToObject(wordFrequency(\"\"))).length !== 0) throw new Error(\"Failed: empty string\");\n\nconst freq1 = mapToObject(wordFrequency(\"hello world\"));\nif (freq1[\"hello\"] !== 1 || freq1[\"world\"] !== 1) throw new Error(\"Failed: two words\");\n\nconst freq2 = mapToObject(wordFrequency(\"Hello, hello!\"));\nif (freq2[\"hello\"] !== 2) throw new Error(\"Failed: case and punctuation\");\n\nconst freq3 = mapToObject(wordFrequency(\"The quick brown fox jumps over the lazy dog.\"));\nif (freq3[\"the\"] !== 2 || freq3[\"quick\"] !== 1) throw new Error(\"Failed: longer text\");\n\nconst freq4 = mapToObject(wordFrequency(\"test, test. TEST!\"));\nif (freq4[\"test\"] !== 3) throw new Error(\"Failed: multiple punctuation\");","metadata":{"language":"TypeScript","function_name":"wordFrequency","difficulty":"medium","category":"algorithms","complexity":0.4}}
{"query_id":"synthetic-047","query_text":"Write a TypeScript function named `asyncDownload` that downloads multiple URLs concurrently using fetch API with proper timeout handling. The function should take a list of URLs and return a list of responses or error messages. Handle network errors gracefully. Language: TypeScript. Function name: asyncDownload","reference_answer":"interface DownloadResult {\n    url: string;\n    success: boolean;\n    data?: string;\n    error?: string;\n}\n\nasync function asyncDownload(urls: string[], timeoutMs: number = 10000): Promise<DownloadResult[]> {\n    const downloadSingle = async (url: string): Promise<DownloadResult> => {\n        try {\n            const controller = new AbortController();\n            const timeoutId = setTimeout(() => controller.abort(), timeoutMs);\n            \n            const response = await fetch(url, {\n                signal: controller.signal,\n                headers: {\n                    'User-Agent': 'TypeScript-Download/1.0'\n                }\n            });\n            \n            clearTimeout(timeoutId);\n            \n            if (!response.ok) {\n                return {\n                    url,\n                    success: false,\n                    error: `HTTP ${response.status}: ${response.statusText}`\n                };\n            }\n            \n            const data = await response.text();\n            return {\n                url,\n                success: true,\n                data\n            };\n        } catch (error) {\n            return {\n                url,\n                success: false,\n                error: error instanceof Error ? error.message : 'Unknown error'\n            };\n        }\n    };\n    \n    const promises = urls.map(url => downloadSingle(url));\n    return await Promise.all(promises);\n}","assertions":"// Test with invalid URLs (should handle gracefully)\nconst results = await asyncDownload([\n    \"https://invalid-domain-12345.com\",\n    \"https://another-invalid-url.com\"\n], 1000);\n\nif (results.length !== 2) throw new Error(\"Should return results for all URLs\");\n\nfor (const result of results) {\n    if (!result.url.includes(\"invalid\")) continue;\n    if (result.success) throw new Error(\"Invalid URL should not succeed\");\n    if (!result.error) throw new Error(\"Invalid URL should have error\");\n}","metadata":{"language":"TypeScript","function_name":"asyncDownload","difficulty":"advanced","category":"concurrency","complexity":0.65}}
{"query_id":"synthetic-048","query_text":"Write a TypeScript function named `knapsack01` that solves the 0/1 knapsack problem using dynamic programming. Given weights, values, and capacity, return the maximum value that can be achieved without exceeding capacity. Language: TypeScript. Function name: knapsack01","reference_answer":"function knapsack01(weights: number[], values: number[], capacity: number): number {\n    const n = weights.length;\n    if (n === 0 || capacity === 0) {\n        return 0;\n    }\n    \n    // Initialize DP table\n    const dp: number[][] = Array(n + 1).fill(null).map(() => Array(capacity + 1).fill(0));\n    \n    // Fill DP table\n    for (let i = 1; i <= n; i++) {\n        for (let w = 1; w <= capacity; w++) {\n            if (weights[i - 1] <= w) {\n                dp[i][w] = Math.max(\n                    dp[i - 1][w],\n                    dp[i - 1][w - weights[i - 1]] + values[i - 1]\n                );\n            } else {\n                dp[i][w] = dp[i - 1][w];\n            }\n        }\n    }\n    \n    return dp[n][capacity];\n}","assertions":"if (knapsack01([], [], 10) !== 0) throw new Error(\"Failed: empty arrays\");\nif (knapsack01([1], [1], 0) !== 0) throw new Error(\"Failed: zero capacity\");\nif (knapsack01([1, 2, 3], [6, 10, 12], 5) !== 22) throw new Error(\"Failed: standard case\");\nif (knapsack01([2, 3, 4], [3, 4, 5], 6) !== 7) throw new Error(\"Failed: another case\");\nif (knapsack01([1, 1, 1], [1, 2, 3], 2) !== 4) throw new Error(\"Failed: duplicate weights\");","metadata":{"language":"TypeScript","function_name":"knapsack01","difficulty":"advanced","category":"algorithms","complexity":0.7}}
{"query_id":"synthetic-049","query_text":"Write a TypeScript class named `LRUCache` that implements an LRU (Least Recently Used) cache with get and put operations. The cache should have a maximum capacity and evict the least recently used item when full. Language: TypeScript. Function name: LRUCache","reference_answer":"class LRUCache {\n    private capacity: number;\n    private cache: Map<number, number>;\n    \n    constructor(capacity: number) {\n        this.capacity = capacity;\n        this.cache = new Map();\n    }\n    \n    get(key: number): number {\n        if (!this.cache.has(key)) {\n            return -1;\n        }\n        \n        // Move to end (most recently used)\n        const value = this.cache.get(key)!;\n        this.cache.delete(key);\n        this.cache.set(key, value);\n        return value;\n    }\n    \n    put(key: number, value: number): void {\n        if (this.cache.has(key)) {\n            // Update existing key\n            this.cache.delete(key);\n        } else if (this.cache.size >= this.capacity) {\n            // Remove least recently used (first item)\n            const firstKey = this.cache.keys().next().value;\n            this.cache.delete(firstKey);\n        }\n        \n        this.cache.set(key, value);\n    }\n}","assertions":"const cache = new LRUCache(2);\ncache.put(1, 1);\ncache.put(2, 2);\nif (cache.get(1) !== 1) throw new Error(\"Failed: get existing key\");\ncache.put(3, 3); // evicts key 2\nif (cache.get(2) !== -1) throw new Error(\"Failed: evicted key should return -1\");\ncache.put(4, 4); // evicts key 1\nif (cache.get(1) !== -1) throw new Error(\"Failed: second evicted key should return -1\");\nif (cache.get(3) !== 3) throw new Error(\"Failed: key 3 should still exist\");\nif (cache.get(4) !== 4) throw new Error(\"Failed: key 4 should exist\");","metadata":{"language":"TypeScript","function_name":"LRUCache","difficulty":"advanced","category":"data_structures","complexity":0.65}}
{"query_id":"synthetic-050","query_text":"Write a TypeScript function named `findMedianSortedArrays` that finds the median of two sorted arrays using a binary search approach. The function should run in O(log(min(n,m))) time and handle edge cases. Language: TypeScript. Function name: findMedianSortedArrays","reference_answer":"function findMedianSortedArrays(nums1: number[], nums2: number[]): number {\n    if (nums1.length > nums2.length) {\n        [nums1, nums2] = [nums2, nums1];\n    }\n    \n    const m = nums1.length;\n    const n = nums2.length;\n    const total = m + n;\n    const half = Math.floor((total + 1) / 2);\n    \n    let left = 0;\n    let right = m;\n    \n    while (left <= right) {\n        const i = Math.floor((left + right) / 2);\n        const j = half - i;\n        \n        const nums1Left = i === 0 ? -Infinity : nums1[i - 1];\n        const nums1Right = i === m ? Infinity : nums1[i];\n        const nums2Left = j === 0 ? -Infinity : nums2[j - 1];\n        const nums2Right = j === n ? Infinity : nums2[j];\n        \n        if (nums1Left <= nums2Right && nums2Left <= nums1Right) {\n            if (total % 2 === 1) {\n                return Math.max(nums1Left, nums2Left);\n            } else {\n                return (Math.max(nums1Left, nums2Left) + Math.min(nums1Right, nums2Right)) / 2;\n            }\n        } else if (nums1Left > nums2Right) {\n            right = i - 1;\n        } else {\n            left = i + 1;\n        }\n    }\n    \n    throw new Error(\"Input arrays are not sorted\");\n}","assertions":"if (findMedianSortedArrays([1, 3], [2]) !== 2.0) throw new Error(\"Failed: odd total length\");\nif (findMedianSortedArrays([1, 2], [3, 4]) !== 2.5) throw new Error(\"Failed: even total length\");\nif (findMedianSortedArrays([0, 0], [0, 0]) !== 0.0) throw new Error(\"Failed: all zeros\");\nif (findMedianSortedArrays([], [1]) !== 1.0) throw new Error(\"Failed: empty first array\");\nif (findMedianSortedArrays([2], []) !== 2.0) throw new Error(\"Failed: empty second array\");","metadata":{"language":"TypeScript","function_name":"findMedianSortedArrays","difficulty":"advanced","category":"algorithms","complexity":0.75}}
{"query_id":"synthetic-051","query_text":"Write a TypeScript function named `parallelMatrixMultiply` that multiplies two matrices using Web Workers for parallel computation across multiple CPU cores. Handle matrix dimension validation and return the result matrix. Language: TypeScript. Function name: parallelMatrixMultiply","reference_answer":"function parallelMatrixMultiply(A: number[][], B: number[][]): number[][] {\n    // Validate dimensions\n    if (!A.length || !B.length || !A[0].length || !B[0].length) {\n        throw new Error(\"Empty matrices not allowed\");\n    }\n    \n    const rowsA = A.length;\n    const colsA = A[0].length;\n    const rowsB = B.length;\n    const colsB = B[0].length;\n    \n    if (colsA !== rowsB) {\n        throw new Error(\"Matrix dimensions incompatible\");\n    }\n    \n    // Initialize result matrix\n    const result: number[][] = Array(rowsA).fill(null).map(() => Array(colsB).fill(0));\n    \n    // Simple parallel computation using Promise.all\n    const promises: Promise<void>[] = [];\n    \n    for (let i = 0; i < rowsA; i++) {\n        for (let j = 0; j < colsB; j++) {\n            promises.push(\n                Promise.resolve().then(() => {\n                    let sum = 0;\n                    for (let k = 0; k < colsA; k++) {\n                        sum += A[i][k] * B[k][j];\n                    }\n                    result[i][j] = sum;\n                })\n            );\n        }\n    }\n    \n    return result;\n}","assertions":"const result = parallelMatrixMultiply([[1, 2], [3, 4]], [[5, 6], [7, 8]]);\nconst expected = [[19, 22], [43, 50]];\n\nif (result.length !== expected.length) throw new Error(\"Wrong number of rows\");\nfor (let i = 0; i < result.length; i++) {\n    for (let j = 0; j < result[i].length; j++) {\n        if (result[i][j] !== expected[i][j]) {\n            throw new Error(`Wrong value at [${i}][${j}]: got ${result[i][j]}, expected ${expected[i][j]}`);\n        }\n    }\n}\n\n// Test dimension validation\ntry {\n    parallelMatrixMultiply([[1, 2]], [[1], [2], [3]]);\n    throw new Error(\"Should raise error for incompatible dimensions\");\n} catch (e) {\n    if (!(e instanceof Error) || !e.message.includes(\"incompatible\")) {\n        throw new Error(\"Wrong error message\");\n    }\n}","metadata":{"language":"TypeScript","function_name":"parallelMatrixMultiply","difficulty":"advanced","category":"concurrency","complexity":0.7}}
{"query_id":"synthetic-052","query_text":"Write a TypeScript class named `Trie` that implements a Trie (prefix tree) data structure with insert, search, and startsWith operations. The Trie should support efficient prefix searches. Language: TypeScript. Function name: Trie","reference_answer":"class TrieNode {\n    children: Map<string, TrieNode>;\n    isEndOfWord: boolean;\n    \n    constructor() {\n        this.children = new Map();\n        this.isEndOfWord = false;\n    }\n}\n\nclass Trie {\n    private root: TrieNode;\n    \n    constructor() {\n        this.root = new TrieNode();\n    }\n    \n    insert(word: string): void {\n        let node = this.root;\n        for (const char of word) {\n            if (!node.children.has(char)) {\n                node.children.set(char, new TrieNode());\n            }\n            node = node.children.get(char)!;\n        }\n        node.isEndOfWord = true;\n    }\n    \n    search(word: string): boolean {\n        let node = this.root;\n        for (const char of word) {\n            if (!node.children.has(char)) {\n                return false;\n            }\n            node = node.children.get(char)!;\n        }\n        return node.isEndOfWord;\n    }\n    \n    startsWith(prefix: string): boolean {\n        let node = this.root;\n        for (const char of prefix) {\n            if (!node.children.has(char)) {\n                return false;\n            }\n            node = node.children.get(char)!;\n        }\n        return true;\n    }\n}","assertions":"const trie = new Trie();\ntrie.insert(\"apple\");\nif (!trie.search(\"apple\")) throw new Error(\"Failed: search existing word\");\nif (trie.search(\"app\")) throw new Error(\"Failed: search prefix should be false\");\nif (!trie.startsWith(\"app\")) throw new Error(\"Failed: startsWith existing prefix\");\ntrie.insert(\"app\");\nif (!trie.search(\"app\")) throw new Error(\"Failed: search inserted prefix word\");\nif (trie.startsWith(\"appl\")) throw new Error(\"Failed: startsWith non-existing prefix\");","metadata":{"language":"TypeScript","function_name":"Trie","difficulty":"advanced","category":"data_structures","complexity":0.6}}
{"query_id":"synthetic-053","query_text":"Write a TypeScript function named `longestCommonSubsequence` that finds the length of the longest common subsequence between two strings using dynamic programming. The function should return the length of the LCS. Language: TypeScript. Function name: longestCommonSubsequence","reference_answer":"function longestCommonSubsequence(text1: string, text2: string): number {\n    const m = text1.length;\n    const n = text2.length;\n    if (m === 0 || n === 0) {\n        return 0;\n    }\n    \n    // Initialize DP table\n    const dp: number[][] = Array(m + 1).fill(null).map(() => Array(n + 1).fill(0));\n    \n    // Fill DP table\n    for (let i = 1; i <= m; i++) {\n        for (let j = 1; j <= n; j++) {\n            if (text1[i - 1] === text2[j - 1]) {\n                dp[i][j] = dp[i - 1][j - 1] + 1;\n            } else {\n                dp[i][j] = Math.max(dp[i - 1][j], dp[i][j - 1]);\n            }\n        }\n    }\n    \n    return dp[m][n];\n}","assertions":"if (longestCommonSubsequence(\"\", \"\") !== 0) throw new Error(\"Failed: empty strings\");\nif (longestCommonSubsequence(\"abc\", \"\") !== 0) throw new Error(\"Failed: one empty string\");\nif (longestCommonSubsequence(\"abc\", \"abc\") !== 3) throw new Error(\"Failed: identical strings\");\nif (longestCommonSubsequence(\"abc\", \"def\") !== 0) throw new Error(\"Failed: no common chars\");\nif (longestCommonSubsequence(\"abcde\", \"ace\") !== 3) throw new Error(\"Failed: subsequence\");\nif (longestCommonSubsequence(\"AGGTAB\", \"GXTXAYB\") !== 4) throw new Error(\"Failed: complex case\");","metadata":{"language":"TypeScript","function_name":"longestCommonSubsequence","difficulty":"advanced","category":"algorithms","complexity":0.7}}
{"query_id":"synthetic-054","query_text":"Write a TypeScript function named `asyncFileProcessor` that processes multiple files concurrently using Promise.all. The function should read files, apply a transformation function to each, and write results to new files. Handle file I/O errors gracefully. Language: TypeScript. Function name: asyncFileProcessor","reference_answer":"import { promises as fs } from 'fs';\nimport { join } from 'path';\n\ninterface ProcessResult {\n    filePath: string;\n    success: boolean;\n    error?: string;\n}\n\nasync function asyncFileProcessor(\n    filePaths: string[],\n    transformFunc: (content: string) => string,\n    outputDir: string = \"output\"\n): Promise<ProcessResult[]> {\n    \n    const processFile = async (filePath: string): Promise<ProcessResult> => {\n        try {\n            // Read file\n            const content = await fs.readFile(filePath, 'utf-8');\n            \n            // Transform content\n            const transformed = transformFunc(content);\n            \n            // Ensure output directory exists\n            await fs.mkdir(outputDir, { recursive: true });\n            \n            // Write transformed content\n            const outputPath = join(outputDir, filePath.split('/').pop() || 'output.txt');\n            await fs.writeFile(outputPath, transformed, 'utf-8');\n            \n            return {\n                filePath: outputPath,\n                success: true\n            };\n        } catch (error) {\n            return {\n                filePath,\n                success: false,\n                error: error instanceof Error ? error.message : 'Unknown error'\n            };\n        }\n    };\n    \n    // Process all files concurrently\n    const promises = filePaths.map(filePath => processFile(filePath));\n    return await Promise.all(promises);\n}","assertions":"import { promises as fs } from 'fs';\nimport { join } from 'path';\nimport { tmpdir } from 'os';\n\n// Create temporary test files\nconst tempDir = tmpdir();\nconst file1 = join(tempDir, 'test1.txt');\nconst file2 = join(tempDir, 'test2.txt');\nconst outputDir = join(tempDir, 'output');\n\n// Write test files\nawait fs.writeFile(file1, 'hello world');\nawait fs.writeFile(file2, 'foo bar');\n\n// Process files\nconst results = await asyncFileProcessor([file1, file2], content => content.toUpperCase(), outputDir);\n\nif (results.length !== 2) throw new Error(\"Should process all files\");\n\n// Check results\nfor (const result of results) {\n    if (!result.success) throw new Error(`File processing failed: ${result.error}`);\n    \n    const content = await fs.readFile(result.filePath, 'utf-8');\n    if (result.filePath.includes('test1.txt')) {\n        if (content !== 'HELLO WORLD') throw new Error(\"Wrong transformation for file1\");\n    } else if (result.filePath.includes('test2.txt')) {\n        if (content !== 'FOO BAR') throw new Error(\"Wrong transformation for file2\");\n    }\n}\n\n// Cleanup\nawait fs.unlink(file1);\nawait fs.unlink(file2);\nawait fs.rm(outputDir, { recursive: true, force: true });","metadata":{"language":"TypeScript","function_name":"asyncFileProcessor","difficulty":"advanced","category":"concurrency","complexity":0.7}}
{"query_id":"synthetic-055","query_text":"Write a TypeScript function named `redBlackTreeInsert` that implements insertion into a Red-Black Tree. The function should maintain all Red-Black Tree properties and return the root of the tree. Language: TypeScript. Function name: redBlackTreeInsert","reference_answer":"enum Color {\n    RED = \"red\",\n    BLACK = \"black\"\n}\n\nclass RBNode {\n    key: number;\n    color: Color;\n    left: RBNode | null;\n    right: RBNode | null;\n    parent: RBNode | null;\n    \n    constructor(key: number, color: Color = Color.RED) {\n        this.key = key;\n        this.color = color;\n        this.left = null;\n        this.right = null;\n        this.parent = null;\n    }\n}\n\nclass RedBlackTree {\n    private root: RBNode | null;\n    private NIL: RBNode;\n    \n    constructor() {\n        this.NIL = new RBNode(0, Color.BLACK);\n        this.root = null;\n    }\n    \n    insert(key: number): void {\n        const newNode = new RBNode(key, Color.RED);\n        newNode.left = this.NIL;\n        newNode.right = this.NIL;\n        \n        let parent: RBNode | null = null;\n        let current = this.root;\n        \n        while (current !== null && current !== this.NIL) {\n            parent = current;\n            if (newNode.key < current.key) {\n                current = current.left;\n            } else {\n                current = current.right;\n            }\n        }\n        \n        newNode.parent = parent;\n        \n        if (parent === null) {\n            this.root = newNode;\n        } else if (newNode.key < parent.key) {\n            parent.left = newNode;\n        } else {\n            parent.right = newNode;\n        }\n        \n        if (newNode.parent === null) {\n            newNode.color = Color.BLACK;\n            return;\n        }\n        \n        if (newNode.parent.parent === null) {\n            return;\n        }\n        \n        this.fixInsert(newNode);\n    }\n    \n    private fixInsert(k: RBNode): void {\n        while (k.parent!.color === Color.RED) {\n            if (k.parent === k.parent!.parent!.right) {\n                const u = k.parent!.parent!.left;\n                if (u.color === Color.RED) {\n                    u.color = Color.BLACK;\n                    k.parent!.color = Color.BLACK;\n                    k.parent!.parent!.color = Color.RED;\n                    k = k.parent!.parent!;\n                } else {\n                    if (k === k.parent!.left) {\n                        k = k.parent!;\n                        this.rightRotate(k);\n                    }\n                    k.parent!.color = Color.BLACK;\n                    k.parent!.parent!.color = Color.RED;\n                    this.leftRotate(k.parent!.parent!);\n                }\n            } else {\n                const u = k.parent!.parent!.right;\n                if (u.color === Color.RED) {\n                    u.color = Color.BLACK;\n                    k.parent!.color = Color.BLACK;\n                    k.parent!.parent!.color = Color.RED;\n                    k = k.parent!.parent!;\n                } else {\n                    if (k === k.parent!.right) {\n                        k = k.parent!;\n                        this.leftRotate(k);\n                    }\n                    k.parent!.color = Color.BLACK;\n                    k.parent!.parent!.color = Color.RED;\n                    this.rightRotate(k.parent!.parent!);\n                }\n            }\n            \n            if (k === this.root) {\n                break;\n            }\n        }\n        \n        if (this.root) {\n            this.root.color = Color.BLACK;\n        }\n    }\n    \n    private leftRotate(x: RBNode): void {\n        const y = x.right!;\n        x.right = y.left;\n        if (y.left !== this.NIL) {\n            y.left!.parent = x;\n        }\n        y.parent = x.parent;\n        if (x.parent === null) {\n            this.root = y;\n        } else if (x === x.parent!.left) {\n            x.parent!.left = y;\n        } else {\n            x.parent!.right = y;\n        }\n        y.left = x;\n        x.parent = y;\n    }\n    \n    private rightRotate(x: RBNode): void {\n        const y = x.left!;\n        x.left = y.right;\n        if (y.right !== this.NIL) {\n            y.right!.parent = x;\n        }\n        y.parent = x.parent;\n        if (x.parent === null) {\n            this.root = y;\n        } else if (x === x.parent!.right) {\n            x.parent!.right = y;\n        } else {\n            x.parent!.left = y;\n        }\n        y.right = x;\n        x.parent = y;\n    }\n}\n\nfunction redBlackTreeInsert(tree: RedBlackTree | null, key: number): RedBlackTree {\n    if (!tree) {\n        tree = new RedBlackTree();\n    }\n    tree.insert(key);\n    return tree;\n}","assertions":"const tree = redBlackTreeInsert(null, 10);\nredBlackTreeInsert(tree, 20);\nredBlackTreeInsert(tree, 30);\nredBlackTreeInsert(tree, 15);\nredBlackTreeInsert(tree, 25);\n\n// Basic structure verification - tree should maintain Red-Black properties\n// This is a simplified test focusing on basic functionality\nlet nodeCount = 0;\nfunction countNodes(node: RBNode | null): number {\n    if (!node || node === tree['NIL']) return 0;\n    return 1 + countNodes(node.left) + countNodes(node.right);\n}\n\nnodeCount = countNodes(tree.root);\nif (nodeCount !== 5) throw new Error(`Expected 5 nodes, got ${nodeCount}`);\n\n// Check that root is black\nif (tree.root!.color !== Color.BLACK) throw new Error(\"Root should be black\");","metadata":{"language":"TypeScript","function_name":"redBlackTreeInsert","difficulty":"very_advanced","category":"data_structures","complexity":0.9}}
{"query_id":"synthetic-056","query_text":"Write a TypeScript function named `distributedCache` that implements a distributed LRU cache using Redis as the backend. The cache should support get, set, and delete operations with proper TTL handling and connection pooling. Language: TypeScript. Function name: distributedCache","reference_answer":"interface CacheOptions {\n    host?: string;\n    port?: number;\n    ttl?: number;\n}\n\nclass DistributedCache {\n    private options: Required<CacheOptions>;\n    \n    constructor(options: CacheOptions = {}) {\n        this.options = {\n            host: options.host || 'localhost',\n            port: options.port || 6379,\n            ttl: options.ttl || 3600\n        };\n    }\n    \n    async get(key: string): Promise<string | null> {\n        try {\n            // In a real implementation, this would connect to Redis\n            // For this example, we'll simulate the operations\n            console.log(`Getting key: ${key}`);\n            return null; // Simulate cache miss\n        } catch (error) {\n            console.error('Cache get error:', error);\n            return null;\n        }\n    }\n    \n    async set(key: string, value: string, ttl?: number): Promise<boolean> {\n        try {\n            const expiration = ttl || this.options.ttl;\n            console.log(`Setting key: ${key}, ttl: ${expiration}`);\n            return true; // Simulate success\n        } catch (error) {\n            console.error('Cache set error:', error);\n            return false;\n        }\n    }\n    \n    async delete(key: string): Promise<boolean> {\n        try {\n            console.log(`Deleting key: ${key}`);\n            return true; // Simulate success\n        } catch (error) {\n            console.error('Cache delete error:', error);\n            return false;\n        }\n    }\n    \n    async exists(key: string): Promise<boolean> {\n        try {\n            const value = await this.get(key);\n            return value !== null;\n        } catch (error) {\n            console.error('Cache exists error:', error);\n            return false;\n        }\n    }\n}\n\nfunction distributedCache(options?: CacheOptions): DistributedCache {\n    return new DistributedCache(options);\n}","assertions":"const cache = distributedCache({ ttl: 60 });\n\n// Test basic operations (these would work with real Redis)\nconst setResult = await cache.set(\"test_key\", \"test_value\", 60);\nif (setResult !== true) throw new Error(\"Set operation failed\");\n\n// These will return null/false in the mock implementation\n// but the functions should not throw errors\nconst getResult = await cache.get(\"test_key\");\nconst existsResult = await cache.exists(\"test_key\");\nconst deleteResult = await cache.delete(\"test_key\");\n\n// Just verify the operations complete without throwing\nif (typeof getResult !== 'string' && getResult !== null) {\n    throw new Error(\"Get should return string or null\");\n}\n\nif (typeof existsResult !== 'boolean') {\n    throw new Error(\"Exists should return boolean\");\n}\n\nif (typeof deleteResult !== 'boolean') {\n    throw new Error(\"Delete should return boolean\");\n}","metadata":{"language":"TypeScript","function_name":"distributedCache","difficulty":"very_advanced","category":"concurrency","complexity":0.85}}
{"query_id":"synthetic-057","query_text":"Write a TypeScript function named `concurrentWebCrawler` that crawls web pages concurrently with rate limiting, respecting robots.txt, and handling various error conditions. The function should return a dictionary of URL to content mappings. Language: TypeScript. Function name: concurrentWebCrawler","reference_answer":"interface CrawlResult {\n    [url: string]: {\n        content?: string;\n        error?: string;\n        statusCode?: number;\n    };\n}\n\nclass WebCrawler {\n    private visited: Set<string> = new Set();\n    private results: CrawlResult = {};\n    private semaphore: { acquire: () => Promise<void>, release: () => void } | null = null;\n    private lastRequestTime = 0;\n    private delay = 1000; // 1 second between requests\n    \n    constructor(maxConcurrent = 5) {\n        // Simple semaphore implementation\n        let permits = maxConcurrent;\n        const waiting: Array<() => void> = [];\n        \n        this.semaphore = {\n            acquire: () => new Promise(resolve => {\n                if (permits > 0) {\n                    permits--;\n                    resolve();\n                } else {\n                    waiting.push(resolve);\n                }\n            }),\n            release: () => {\n                permits++;\n                if (waiting.length > 0) {\n                    const resolve = waiting.shift()!;\n                    permits--;\n                    resolve();\n                }\n            }\n        };\n    }\n    \n    private async checkRobotsTxt(url: string): Promise<boolean> {\n        // Simplified robots.txt check - in real implementation, parse actual robots.txt\n        return true; // Assume crawling is allowed\n    }\n    \n    private async fetchPage(url: string): Promise<{ content?: string; error?: string; statusCode?: number }> {\n        try {\n            // Rate limiting\n            const now = Date.now();\n            const timeSinceLastRequest = now - this.lastRequestTime;\n            if (timeSinceLastRequest < this.delay) {\n                await new Promise(resolve => setTimeout(resolve, this.delay - timeSinceLastRequest));\n            }\n            \n            const controller = new AbortController();\n            const timeoutId = setTimeout(() => controller.abort(), 10000);\n            \n            const response = await fetch(url, {\n                signal: controller.signal,\n                headers: { 'User-Agent': 'TypeScript-WebCrawler/1.0' }\n            });\n            \n            clearTimeout(timeoutId);\n            this.lastRequestTime = Date.now();\n            \n            if (response.ok) {\n                const content = await response.text();\n                return { content, statusCode: response.status };\n            } else {\n                return { error: `HTTP ${response.status}`, statusCode: response.status };\n            }\n        } catch (error) {\n            return { \n                error: error instanceof Error ? error.message : 'Unknown error',\n                statusCode: 0 \n            };\n        }\n    }\n    \n    async crawl(startUrls: string[], maxPages = 50): Promise<CrawlResult> {\n        const queue: string[] = [...startUrls];\n        \n        while (queue.length > 0 && Object.keys(this.results).length < maxPages) {\n            const url = queue.shift()!;\n            \n            if (this.visited.has(url)) {\n                continue;\n            }\n            \n            this.visited.add(url);\n            \n            if (!(await this.checkRobotsTxt(url))) {\n                continue;\n            }\n            \n            if (this.semaphore) {\n                await this.semaphore.acquire();\n                \n                // Fetch page asynchronously\n                this.fetchPage(url).then(result => {\n                    this.results[url] = result;\n                    this.semaphore!.release();\n                }).catch(error => {\n                    this.results[url] = { error: error.message };\n                    this.semaphore!.release();\n                });\n            }\n        }\n        \n        // Wait for all requests to complete (simplified)\n        await new Promise(resolve => setTimeout(resolve, 2000));\n        \n        return this.results;\n    }\n}\n\nfunction concurrentWebCrawler(startUrls: string[], maxPages = 10): Promise<CrawlResult> {\n    const crawler = new WebCrawler();\n    return crawler.crawl(startUrls, maxPages);\n}","assertions":"// Test with invalid URLs\nconst results = await concurrentWebCrawler([\n    \"https://invalid-domain-12345.com\",\n    \"https://another-invalid-url.com\"\n], 2);\n\n// Should have attempted to crawl both URLs\nconst urls = Object.keys(results);\nif (urls.length !== 2) throw new Error(`Expected 2 results, got ${urls.length}`);\n\n// Both should have error information\nfor (const url of urls) {\n    const result = results[url];\n    if (result.content && !result.error) {\n        // If content exists, it should be valid\n        continue;\n    }\n    if (!result.error && result.statusCode === undefined) {\n        throw new Error(`URL ${url} has neither content nor error`);\n    }\n}","metadata":{"language":"TypeScript","function_name":"concurrentWebCrawler","difficulty":"very_advanced","category":"concurrency","complexity":0.9}}
{"query_id":"synthetic-058","query_text":"Write a TypeScript function named `neuralNetworkBackprop` that implements a simple neural network with backpropagation for binary classification. The function should train on given data and return the trained weights and biases. Language: TypeScript. Function name: neuralNetworkBackprop","reference_answer":"function sigmoid(x: number): number {\n    return 1 / (1 + Math.exp(-x));\n}\n\nfunction sigmoidDerivative(x: number): number {\n    return x * (1 - x);\n}\n\ninterface NeuralNetworkResult {\n    weightsInputHidden: number[][];\n    biasHidden: number[];\n    weightsHiddenOutput: number[][];\n    biasOutput: number[];\n}\n\nclass SimpleNeuralNetwork {\n    private inputSize: number;\n    private hiddenSize: number;\n    private outputSize: number;\n    private learningRate: number;\n    \n    private weightsInputHidden: number[][];\n    private biasHidden: number[];\n    private weightsHiddenOutput: number[][];\n    private biasOutput: number[];\n    \n    constructor(inputSize: number, hiddenSize: number, outputSize: number, learningRate = 0.1) {\n        this.inputSize = inputSize;\n        this.hiddenSize = hiddenSize;\n        this.outputSize = outputSize;\n        this.learningRate = learningRate;\n        \n        // Initialize weights and biases\n        this.weightsInputHidden = Array(inputSize).fill(null).map(() => \n            Array(hiddenSize).fill(null).map(() => Math.random() - 0.5)\n        );\n        this.biasHidden = Array(hiddenSize).fill(0);\n        \n        this.weightsHiddenOutput = Array(hiddenSize).fill(null).map(() => \n            Array(outputSize).fill(null).map(() => Math.random() - 0.5)\n        );\n        this.biasOutput = Array(outputSize).fill(0);\n    }\n    \n    forward(X: number[]): number[] {\n        // Hidden layer\n        const hiddenInput = X.map((x, i) => \n            this.weightsInputHidden[i].reduce((sum, w, j) => sum + x * w, 0) + this.biasHidden[i]\n        );\n        this.hiddenActivation = hiddenInput.map(sigmoid);\n        \n        // Output layer\n        const outputInput = this.hiddenActivation.map((h, i) => \n            this.weightsHiddenOutput[i].reduce((sum, w) => sum + h * w, 0)\n        ).map((sum, i) => sum + this.biasOutput[i]);\n        \n        return outputInput.map(sigmoid);\n    }\n    \n    backward(X: number[], y: number[], output: number[]): void {\n        // Calculate output layer error\n        const outputError = y.map((expected, i) => expected - output[i]);\n        const outputDelta = outputError.map((error, i) => error * sigmoidDerivative(output[i]));\n        \n        // Calculate hidden layer error\n        const hiddenError = this.weightsHiddenOutput.map((weights, i) => \n            outputDelta.reduce((sum, delta, j) => sum + delta * weights[j], 0)\n        );\n        const hiddenDelta = hiddenError.map((error, i) => error * sigmoidDerivative(this.hiddenActivation[i]));\n        \n        // Update weights and biases\n        for (let i = 0; i < this.hiddenSize; i++) {\n            for (let j = 0; j < this.outputSize; j++) {\n                this.weightsHiddenOutput[i][j] += this.hiddenActivation[i] * outputDelta[j] * this.learningRate;\n            }\n        }\n        \n        for (let i = 0; i < this.outputSize; i++) {\n            this.biasOutput[i] += outputDelta[i] * this.learningRate;\n        }\n        \n        for (let i = 0; i < this.inputSize; i++) {\n            for (let j = 0; j < this.hiddenSize; j++) {\n                this.weightsInputHidden[i][j] += X[i] * hiddenDelta[j] * this.learningRate;\n            }\n        }\n        \n        for (let i = 0; i < this.hiddenSize; i++) {\n            this.biasHidden[i] += hiddenDelta[i] * this.learningRate;\n        }\n    }\n    \n    train(X: number[][], y: number[][], epochs = 1000): NeuralNetworkResult {\n        for (let epoch = 0; epoch < epochs; epoch++) {\n            for (let i = 0; i < X.length; i++) {\n                const output = this.forward(X[i]);\n                this.backward(X[i], y[i], output);\n            }\n        }\n        \n        return {\n            weightsInputHidden: this.weightsInputHidden,\n            biasHidden: this.biasHidden,\n            weightsHiddenOutput: this.weightsHiddenOutput,\n            biasOutput: this.biasOutput\n        };\n    }\n    \n    // Store hidden activation for backprop\n    private hiddenActivation: number[] = [];\n}\n\nfunction neuralNetworkBackprop(X: number[][], y: number[][], hiddenSize = 4, epochs = 1000): NeuralNetworkResult {\n    if (X.length === 0 || y.length === 0) {\n        throw new Error(\"Empty training data\");\n    }\n    \n    const inputSize = X[0].length;\n    const outputSize = y[0].length;\n    \n    const nn = new SimpleNeuralNetwork(inputSize, hiddenSize, outputSize);\n    return nn.train(X, y, epochs);\n}","assertions":"// Create XOR dataset\nconst X = [[0, 0], [0, 1], [1, 0], [1, 1]];\nconst y = [[0], [1], [1], [0]];\n\n// Train network\nconst result = neuralNetworkBackprop(X, y, 4, 10000);\n\n// Check that weights are updated (not all zeros)\nconst hasNonZeroWeights = result.weightsInputHidden.some(row => \n    row.some(weight => weight !== 0)\n) && result.weightsHiddenOutput.some(row => \n    row.some(weight => weight !== 0)\n);\n\nif (!hasNonZeroWeights) throw new Error(\"Weights should be updated during training\");\n\n// Check dimensions\nif (result.weightsInputHidden.length !== 2) throw new Error(\"Wrong input-hidden weights dimensions\");\nif (result.weightsInputHidden[0].length !== 4) throw new Error(\"Wrong hidden layer size\");\nif (result.weightsHiddenOutput.length !== 4) throw new Error(\"Wrong hidden-output weights dimensions\");\nif (result.weightsHiddenOutput[0].length !== 1) throw new Error(\"Wrong output layer size\");\nif (result.biasHidden.length !== 4) throw new Error(\"Wrong hidden bias size\");\nif (result.biasOutput.length !== 1) throw new Error(\"Wrong output bias size\");","metadata":{"language":"TypeScript","function_name":"neuralNetworkBackprop","difficulty":"very_advanced","category":"algorithms","complexity":0.95}}
{"query_id":"synthetic-059","query_text":"Write a TypeScript function named `asyncTaskScheduler` that implements an async task scheduler with dependency management, parallel execution, and failure handling. Tasks should be executed based on their dependencies with proper error propagation. Language: TypeScript. Function name: asyncTaskScheduler","reference_answer":"interface Task {\n    id: string;\n    func: () => Promise<any> | any;\n    dependencies: string[];\n    status: 'pending' | 'running' | 'completed' | 'failed';\n    result?: any;\n    error?: Error;\n}\n\nclass AsyncTaskScheduler {\n    private tasks: Map<string, Task> = new Map();\n    private maxConcurrent: number;\n    private running = 0;\n    private completedTasks: Task[] = [];\n    \n    constructor(maxConcurrent = 5) {\n        this.maxConcurrent = maxConcurrent;\n    }\n    \n    addTask(id: string, func: () => Promise<any> | any, dependencies: string[] = []): void {\n        this.tasks.set(id, {\n            id,\n            func,\n            dependencies,\n            status: 'pending'\n        });\n    }\n    \n    async execute(): Promise<Map<string, any>> {\n        const results = new Map<string, any>();\n        const pendingTasks = Array.from(this.tasks.values());\n        \n        while (pendingTasks.length > 0 || this.running > 0) {\n            // Start ready tasks\n            const readyTasks = pendingTasks.filter(task => \n                task.status === 'pending' && \n                task.dependencies.every(depId => {\n                    const depTask = this.tasks.get(depId);\n                    return depTask?.status === 'completed';\n                })\n            );\n            \n            for (const task of readyTasks) {\n                if (this.running >= this.maxConcurrent) break;\n                \n                task.status = 'running';\n                this.running++;\n                \n                // Execute task asynchronously\n                this.executeTask(task).then(() => {\n                    this.running--;\n                }).catch(() => {\n                    this.running--;\n                });\n                \n                // Remove from pending\n                const index = pendingTasks.indexOf(task);\n                if (index > -1) pendingTasks.splice(index, 1);\n            }\n            \n            // Wait a bit for tasks to complete\n            if (this.running > 0) {\n                await new Promise(resolve => setTimeout(resolve, 10));\n            } else if (pendingTasks.length > 0) {\n                // No running tasks but still pending - possible circular dependency\n                throw new Error('Possible circular dependency or deadlocked tasks');\n            }\n        }\n        \n        // Collect results\n        for (const task of this.completedTasks) {\n            if (task.status === 'completed') {\n                results.set(task.id, task.result);\n            }\n        }\n        \n        return results;\n    }\n    \n    private async executeTask(task: Task): Promise<void> {\n        try {\n            const result = await (typeof task.func === 'function' ? task.func() : task.func);\n            task.result = result;\n            task.status = 'completed';\n            this.completedTasks.push(task);\n        } catch (error) {\n            task.error = error instanceof Error ? error : new Error(String(error));\n            task.status = 'failed';\n            this.completedTasks.push(task);\n            \n            // Mark dependent tasks as failed too\n            this.propagateFailure(task.id);\n        }\n    }\n    \n    private propagateFailure(failedTaskId: string): void {\n        for (const [id, task] of this.tasks) {\n            if (task.dependencies.includes(failedTaskId) && task.status === 'pending') {\n                task.status = 'failed';\n                task.error = new Error(`Dependency ${failedTaskId} failed`);\n                this.completedTasks.push(task);\n            }\n        }\n    }\n}\n\nfunction asyncTaskScheduler(maxConcurrent = 5): AsyncTaskScheduler {\n    return new AsyncTaskScheduler(maxConcurrent);\n}","assertions":"const scheduler = asyncTaskScheduler(3);\n\n// Add tasks with dependencies\nscheduler.addTask('task_a', async () => {\n    await new Promise(resolve => setTimeout(resolve, 100));\n    return 'A';\n});\n\nscheduler.addTask('task_b', () => 'B');\n\nscheduler.addTask('task_c', async () => {\n    await new Promise(resolve => setTimeout(resolve, 50));\n    return 'C';\n});\n\nscheduler.addTask('task_d', async () => {\n    const taskA = scheduler['tasks'].get('task_a');\n    const taskB = scheduler['tasks'].get('task_b');\n    return `D-${taskA?.result}-${taskB?.result}`;\n}, ['task_a', 'task_b']);\n\n// Execute and verify results\nconst results = await scheduler.execute();\n\nif (!results.has('task_a') || results.get('task_a') !== 'A') throw new Error('Task A failed');\nif (!results.has('task_b') || results.get('task_b') !== 'B') throw new Error('Task B failed');\nif (!results.has('task_c') || results.get('task_c') !== 'C') throw new Error('Task C failed');\nif (!results.has('task_d') || results.get('task_d') !== 'D-A-B') throw new Error('Task D failed');\n\nif (results.size !== 4) throw new Error(`Expected 4 results, got ${results.size}`);","metadata":{"language":"TypeScript","function_name":"asyncTaskScheduler","difficulty":"very_advanced","category":"concurrency","complexity":0.85}}
{"query_id":"synthetic-060","query_text":"Write a TypeScript function named `implementGraphDijkstra` that implements Dijkstra's algorithm for finding shortest paths in a weighted graph. The function should handle graphs with non-negative weights and return distances and paths. Language: TypeScript. Function name: implementGraphDijkstra","reference_answer":"interface DijkstraResult {\n    distances: Map<string, number>;\n    predecessors: Map<string, string | null>;\n}\n\nfunction implementGraphDijkstra(graph: Map<string, Array<[string, number]>>, start: string): DijkstraResult {\n    const distances = new Map<string, number>();\n    const predecessors = new Map<string, string | null>();\n    const priorityQueue: Array<[number, string]> = [];\n    \n    // Initialize distances\n    for (const node of graph.keys()) {\n        distances.set(node, node === start ? 0 : Infinity);\n        predecessors.set(node, null);\n    }\n    \n    priorityQueue.push([0, start]);\n    \n    while (priorityQueue.length > 0) {\n        // Sort by distance (simple priority queue)\n        priorityQueue.sort((a, b) => a[0] - b[0]);\n        const [currentDistance, currentNode] = priorityQueue.shift()!;\n        \n        if (currentDistance > distances.get(currentNode)!) {\n            continue;\n        }\n        \n        const neighbors = graph.get(currentNode) || [];\n        for (const [neighbor, weight] of neighbors) {\n            const distance = currentDistance + weight;\n            \n            if (distance < distances.get(neighbor)!) {\n                distances.set(neighbor, distance);\n                predecessors.set(neighbor, currentNode);\n                priorityQueue.push([distance, neighbor]);\n            }\n        }\n    }\n    \n    return { distances, predecessors };\n}","assertions":"const graph = new Map<string, Array<[string, number]>>([\n    ['A', [['B', 4], ['C', 2]]],\n    ['B', [['A', 4], ['C', 5], ['D', 10]]],\n    ['C', [['A', 2], ['B', 5], ['D', 3]]],\n    ['D', [['B', 10], ['C', 3]]]\n]);\n\nconst result = implementGraphDijkstra(graph, 'A');\n\nif (result.distances.get('A') !== 0) throw new Error('Wrong distance for A');\nif (result.distances.get('B') !== 3) throw new Error('Wrong distance for B'); // A->C->B\nif (result.distances.get('C') !== 2) throw new Error('Wrong distance for C');\nif (result.distances.get('D') !== 5) throw new Error('Wrong distance for D'); // A->C->B->D\n\n// Verify path reconstruction\nfunction reconstructPath(predecessors: Map<string, string | null>, target: string): string[] {\n    const path: string[] = [];\n    let current: string | null = target;\n    while (current) {\n        path.unshift(current);\n        current = predecessors.get(current) || null;\n    }\n    return path;\n}\n\nconst pathToD = reconstructPath(result.predecessors, 'D');\nif (JSON.stringify(pathToD) !== JSON.stringify(['A', 'C', 'D'])) {\n    throw new Error(`Wrong path to D: ${JSON.stringify(pathToD)}`);\n}","metadata":{"language":"TypeScript","function_name":"implementGraphDijkstra","difficulty":"very_advanced","category":"algorithms","complexity":0.8}}
{"query_id":"synthetic-061","query_text":"Write a TypeScript function named `bloomFilter` that implements a Bloom filter for set membership testing. The function should support add and check operations with configurable false positive rates. Language: TypeScript. Function name: bloomFilter","reference_answer":"class BloomFilter {\n    private size: number;\n    private hashCount: number;\n    private bitArray: boolean[];\n    \n    constructor(expectedItems: number, falsePositiveRate = 0.01) {\n        this.size = this.optimalSize(expectedItems, falsePositiveRate);\n        this.hashCount = this.optimalHashCount(expectedItems, this.size);\n        this.bitArray = new Array(this.size).fill(false);\n    }\n    \n    private optimalSize(n: number, p: number): number {\n        return Math.ceil(-n * Math.log(p) / (Math.log(2) ** 2));\n    }\n    \n    private optimalHashCount(n: number, m: number): number {\n        return Math.ceil((m / n) * Math.log(2));\n    }\n    \n    private hashFunctions(item: string): number[] {\n        const hashes: number[] = [];\n        const itemBytes = Buffer.from(item, 'utf8');\n        \n        for (let i = 0; i < this.hashCount; i++) {\n            // Simple hash functions using different seeds\n            let hash = 0;\n            for (let j = 0; j < itemBytes.length; j++) {\n                hash = ((hash << 5) - hash + itemBytes[j] + i) & 0xffffffff;\n            }\n            hashes.push(Math.abs(hash) % this.size);\n        }\n        \n        return hashes;\n    }\n    \n    add(item: string): void {\n        const hashes = this.hashFunctions(item);\n        for (const hash of hashes) {\n            this.bitArray[hash] = true;\n        }\n    }\n    \n    check(item: string): boolean {\n        const hashes = this.hashFunctions(item);\n        return hashes.every(hash => this.bitArray[hash]);\n    }\n    \n    estimateFalsePositiveRate(): number {\n        const filledBits = this.bitArray.filter(bit => bit).length;\n        if (filledBits === 0) return 0;\n        return Math.pow(filledBits / this.size, this.hashCount);\n    }\n}\n\nfunction bloomFilter(expectedItems: number, falsePositiveRate = 0.01): BloomFilter {\n    return new BloomFilter(expectedItems, falsePositiveRate);\n}","assertions":"const bf = bloomFilter(100, 0.01);\n\nconst testItems = ['apple', 'banana', 'cherry', 'date'];\n\n// Add items\nfor (const item of testItems) {\n    bf.add(item);\n}\n\n// Check existing items\nfor (const item of testItems) {\n    if (!bf.check(item)) throw new Error(`Failed to find existing item: ${item}`);\n}\n\n// Check non-existing items\nconst nonExisting = ['grape', 'kiwi', 'lemon'];\nlet falsePositives = 0;\nfor (const item of nonExisting) {\n    if (bf.check(item)) falsePositives++;\n}\n\n// False positive rate should be low\nif (falsePositives / nonExisting.length > 0.1) {\n    throw new Error(`High false positive rate: ${falsePositives / nonExisting.length}`);\n}\n\n// Estimate should be reasonable\nconst estimatedRate = bf.estimateFalsePositiveRate();\nif (estimatedRate < 0 || estimatedRate > 1) {\n    throw new Error(`Invalid estimated false positive rate: ${estimatedRate}`);\n}","metadata":{"language":"TypeScript","function_name":"bloomFilter","difficulty":"very_advanced","category":"data_structures","complexity":0.8}}
{"query_id":"synthetic-062","query_text":"Write a TypeScript function named `concurrentMergeSort` that implements merge sort using async operations for parallel sorting of large arrays. The function should automatically choose the optimal level of parallelism. Language: TypeScript. Function name: concurrentMergeSort","reference_answer":"async function concurrentMergeSort(arr: number[]): Promise<number[]> {\n    if (arr.length <= 1) {\n        return arr.slice();\n    }\n    \n    // Use parallelism for arrays larger than 1000 elements\n    const useParallel = arr.length > 1000;\n    \n    if (!useParallel) {\n        return mergeSortSequential(arr);\n    }\n    \n    // Split array into chunks for parallel processing\n    const numWorkers = Math.min(4, Math.max(1, Math.floor(arr.length / 1000)));\n    const chunkSize = Math.ceil(arr.length / numWorkers);\n    \n    // Create chunks\n    const chunks: number[][] = [];\n    for (let i = 0; i < arr.length; i += chunkSize) {\n        chunks.push(arr.slice(i, i + chunkSize));\n    }\n    \n    // Sort chunks in parallel\n    const sortPromises = chunks.map(chunk => mergeSortSequential(chunk));\n    const sortedChunks = await Promise.all(sortPromises);\n    \n    // Merge sorted chunks\n    while (sortedChunks.length > 1) {\n        const merged: number[][] = [];\n        for (let i = 0; i < sortedChunks.length; i += 2) {\n            if (i + 1 < sortedChunks.length) {\n                merged.push(merge(sortedChunks[i], sortedChunks[i + 1]));\n            } else {\n                merged.push(sortedChunks[i]);\n            }\n        }\n        sortedChunks.splice(0, sortedChunks.length, ...merged);\n    }\n    \n    return sortedChunks[0];\n}\n\nfunction mergeSortSequential(arr: number[]): number[] {\n    if (arr.length <= 1) {\n        return arr.slice();\n    }\n    \n    const mid = Math.floor(arr.length / 2);\n    const left = mergeSortSequential(arr.slice(0, mid));\n    const right = mergeSortSequential(arr.slice(mid));\n    \n    return merge(left, right);\n}\n\nfunction merge(left: number[], right: number[]): number[] {\n    const result: number[] = [];\n    let i = 0;\n    let j = 0;\n    \n    while (i < left.length && j < right.length) {\n        if (left[i] <= right[j]) {\n            result.push(left[i]);\n            i++;\n        } else {\n            result.push(right[j]);\n            j++;\n        }\n    }\n    \n    return result.concat(left.slice(i)).concat(right.slice(j));\n}","assertions":"// Test with small array\nlet result = await concurrentMergeSort([3, 1, 4, 1, 5]);\nif (JSON.stringify(result) !== JSON.stringify([1, 1, 3, 4, 5])) {\n    throw new Error(`Failed small array: ${JSON.stringify(result)}`);\n}\n\n// Test with larger array (should use parallel processing)\nconst largeArr = Array.from({ length: 2000 }, () => Math.floor(Math.random() * 10000));\nresult = await concurrentMergeSort(largeArr);\nconst expected = largeArr.slice().sort((a, b) => a - b);\n\nif (JSON.stringify(result) !== JSON.stringify(expected)) {\n    throw new Error('Failed large array sorting');\n}\n\n// Test edge cases\nif (JSON.stringify(await concurrentMergeSort([])) !== JSON.stringify([])) {\n    throw new Error('Failed empty array');\n}\n\nif (JSON.stringify(await concurrentMergeSort([1])) !== JSON.stringify([1])) {\n    throw new Error('Failed single element');\n}\n\nif (JSON.stringify(await concurrentMergeSort([2, 1])) !== JSON.stringify([1, 2])) {\n    throw new Error('Failed two elements');\n}","metadata":{"language":"TypeScript","function_name":"concurrentMergeSort","difficulty":"very_advanced","category":"algorithms","complexity":0.85}}
{"query_id":"synthetic-063","query_text":"Write a TypeScript function named `asyncDatabaseConnectionPool` that implements a connection pool for async database operations with proper resource management, connection health checks, and graceful degradation. Language: TypeScript. Function name: asyncDatabaseConnectionPool","reference_answer":"interface Connection {\n    id: number;\n    createdAt: number;\n    lastUsed: number;\n    isHealthy: boolean;\n}\n\nclass AsyncConnectionPool {\n    private maxConnections: number;\n    private maxIdleTime: number;\n    private connections: Connection[] = [];\n    private available: Connection[] = [];\n    private waitingQueue: Array<(conn: Connection) => void> = [];\n    private connectionIdCounter = 0;\n    \n    constructor(maxConnections = 10, maxIdleTime = 300000) { // 5 minutes\n        this.maxConnections = maxConnections;\n        this.maxIdleTime = maxIdleTime;\n    }\n    \n    private async createConnection(): Promise<Connection> {\n        // Simulate connection creation\n        await new Promise(resolve => setTimeout(resolve, 10));\n        this.connectionIdCounter++;\n        const now = Date.now();\n        return {\n            id: this.connectionIdCounter,\n            createdAt: now,\n            lastUsed: now,\n            isHealthy: true\n        };\n    }\n    \n    async acquire(): Promise<Connection> {\n        // Check for available connections\n        const availableConn = this.available.pop();\n        if (availableConn && this.isConnectionHealthy(availableConn)) {\n            availableConn.lastUsed = Date.now();\n            return availableConn;\n        }\n        \n        // Create new connection if under limit\n        if (this.connections.length < this.maxConnections) {\n            const newConn = await this.createConnection();\n            this.connections.push(newConn);\n            return newConn;\n        }\n        \n        // Wait for connection to become available\n        return new Promise((resolve) => {\n            this.waitingQueue.push(resolve);\n        });\n    }\n    \n    async release(connection: Connection): Promise<void> {\n        if (this.isConnectionHealthy(connection)) {\n            this.available.push(connection);\n            \n            // Notify waiting requests\n            if (this.waitingQueue.length > 0) {\n                const resolver = this.waitingQueue.shift()!;\n                const conn = this.available.pop();\n                if (conn) resolver(conn);\n            }\n        } else {\n            // Remove unhealthy connection\n            const index = this.connections.indexOf(connection);\n            if (index > -1) {\n                this.connections.splice(index, 1);\n            }\n        }\n    }\n    \n    private isConnectionHealthy(connection: Connection): boolean {\n        const now = Date.now();\n        const maxAge = 3600000; // 1 hour\n        return (now - connection.createdAt) < maxAge && connection.isHealthy;\n    }\n    \n    cleanup(): void {\n        const now = Date.now();\n        this.available = this.available.filter(conn => \n            (now - conn.lastUsed) < this.maxIdleTime && this.isConnectionHealthy(conn)\n        );\n        \n        this.connections = this.connections.filter(conn => \n            this.available.includes(conn) || \n            this.waitingQueue.some(() => true) // Keep connections in use\n        );\n    }\n}\n\nfunction asyncDatabaseConnectionPool(maxConnections = 10): AsyncConnectionPool {\n    return new AsyncConnectionPool(maxConnections);\n}","assertions":"const pool = asyncDatabaseConnectionPool(3);\n\n// Test acquiring connections\nlet conn1: Connection;\nlet conn2: Connection;\nlet conn3: Connection;\n\nconn1 = await pool.acquire();\nconn2 = await pool.acquire();\nconn3 = await pool.acquire();\n\nif (!conn1 || !conn2 || !conn3) throw new Error('Failed to acquire connections');\nif (conn1.id === conn2.id || conn2.id === conn3.id || conn1.id === conn3.id) {\n    throw new Error('Connections should have unique IDs');\n}\n\n// Test releasing and reusing\nawait pool.release(conn1);\nconst conn1Reacquired = await pool.acquire();\nif (conn1Reacquired.id !== conn1.id) {\n    throw new Error('Should reuse released connection');\n}\n\n// Test cleanup\npool.cleanup();\n\nawait pool.release(conn2);\nawait pool.release(conn3);\nawait pool.release(conn1Reacquired);\n\n// Verify all connections are healthy\nif (pool['available'].length !== 3) {\n    throw new Error('All connections should be available after cleanup');\n}","metadata":{"language":"TypeScript","function_name":"asyncDatabaseConnectionPool","difficulty":"very_advanced","category":"concurrency","complexity":0.9}}
{"query_id":"synthetic-064","query_text":"Write a TypeScript function named `parallelMapReduce` that implements a parallel map-reduce framework using async operations. The function should handle large datasets by chunking and parallel processing. Language: TypeScript. Function name: parallelMapReduce","reference_answer":"async function parallelMapReduce<T, U, V>(\n    data: T[],\n    mapper: (item: T) => Promise<U> | U,\n    reducer: (a: U, b: U) => U,\n    initialValue: U,\n    chunkSize = 1000,\n    maxConcurrency = 4\n): Promise<U> {\n    if (data.length === 0) {\n        return initialValue;\n    }\n    \n    // Split data into chunks\n    const chunks: T[][] = [];\n    for (let i = 0; i < data.length; i += chunkSize) {\n        chunks.push(data.slice(i, i + chunkSize));\n    }\n    \n    // Process chunks with limited concurrency\n    const semaphore = new Semaphore(maxConcurrency);\n    const chunkPromises: Promise<U>[] = chunks.map(async (chunk) => {\n        await semaphore.acquire();\n        try {\n            // Map phase for chunk\n            const mappedChunk = await Promise.all(\n                chunk.map(async (item) => await mapper(item))\n            );\n            \n            // Reduce within chunk\n            return mappedChunk.reduce(reducer, initialValue);\n        } finally {\n            semaphore.release();\n        }\n    });\n    \n    // Wait for all chunks to complete\n    const chunkResults = await Promise.all(chunkPromises);\n    \n    // Final reduce phase\n    return chunkResults.reduce(reducer, initialValue);\n}\n\nclass Semaphore {\n    private permits: number;\n    private waiting: Array<() => void> = [];\n    \n    constructor(permits: number) {\n        this.permits = permits;\n    }\n    \n    async acquire(): Promise<void> {\n        if (this.permits > 0) {\n            this.permits--;\n            return;\n        }\n        \n        return new Promise((resolve) => {\n            this.waiting.push(resolve);\n        });\n    }\n    \n    release(): void {\n        this.permits++;\n        if (this.waiting.length > 0) {\n            const resolve = this.waiting.shift()!;\n            this.permits--;\n            resolve();\n        }\n    }\n}","assertions":"// Test word count example\nconst documents = [\n    \"hello world hello\",\n    \"world test world\",\n    \"hello test hello test\"\n];\n\nasync function wordMapper(text: string): Promise<{ [word: string]: number }> {\n    const words = text.split(/\\s+/);\n    const result: { [word: string]: number } = {};\n    for (const word of words) {\n        result[word] = 1;\n    }\n    return result;\n}\n\nfunction dictReducer(a: { [word: string]: number }, b: { [word: string]: number }): { [word: string]: number } {\n    const result = { ...a };\n    for (const [word, count] of Object.entries(b)) {\n        result[word] = (result[word] || 0) + count;\n    }\n    return result;\n}\n\nconst result = await parallelMapReduce(\n    documents,\n    wordMapper,\n    dictReducer,\n    {}\n);\n\nif (result['hello'] !== 4) throw new Error(`Wrong hello count: ${result['hello']}`);\nif (result['world'] !== 3) throw new Error(`Wrong world count: ${result['world']}`);\nif (result['test'] !== 3) throw new Error(`Wrong test count: ${result['test']}`);\n\n// Test sum of squares\nasync function squareMapper(x: number): Promise<number> {\n    return x * x;\n}\n\nfunction sumReducer(a: number, b: number): number {\n    return a + b;\n}\n\nconst numbers = Array.from({ length: 100 }, (_, i) => i + 1); // 1 to 100\nconst sumSquares = await parallelMapReduce(numbers, squareMapper, sumReducer, 0);\nconst expected = numbers.reduce((sum, n) => sum + n * n, 0);\n\nif (sumSquares !== expected) {\n    throw new Error(`Wrong sum of squares: got ${sumSquares}, expected ${expected}`);\n}","metadata":{"language":"TypeScript","function_name":"parallelMapReduce","difficulty":"very_advanced","category":"concurrency","complexity":0.85}}
{"query_id":"synthetic-065","query_text":"Write a TypeScript function named `distributedLockManager` that implements a distributed lock manager using Redis with proper lease management, deadlock detection, and automatic cleanup of expired locks. Language: TypeScript. Function name: distributedLockManager","reference_answer":"interface LockOptions {\n    ttlSeconds?: number;\n    retryAttempts?: number;\n    retryDelay?: number;\n}\n\nclass DistributedLock {\n    private redis: any; // Would be Redis client in real implementation\n    private lockKey: string;\n    private ownerId: string;\n    private ttlSeconds: number;\n    private retryAttempts: number;\n    private retryDelay: number;\n    \n    constructor(lockKey: string, options: LockOptions = {}) {\n        this.redis = {}; // Mock Redis for this example\n        this.lockKey = lockKey;\n        this.ownerId = `owner_${Date.now()}_${Math.random()}`;\n        this.ttlSeconds = options.ttlSeconds || 30;\n        this.retryAttempts = options.retryAttempts || 3;\n        this.retryDelay = options.retryDelay || 100;\n    }\n    \n    async acquire(): Promise<boolean> {\n        for (let attempt = 0; attempt < this.retryAttempts; attempt++) {\n            try {\n                // Try to acquire lock\n                const acquired = await this.tryAcquireLock();\n                if (acquired) {\n                    return true;\n                }\n                \n                // Check if existing lock is expired and try to steal it\n                const stolen = await this.tryStealExpiredLock();\n                if (stolen) {\n                    return true;\n                }\n                \n                // Wait before retry\n                if (attempt < this.retryAttempts - 1) {\n                    await new Promise(resolve => setTimeout(resolve, this.retryDelay));\n                }\n            } catch (error) {\n                console.error('Lock acquisition error:', error);\n            }\n        }\n        return false;\n    }\n    \n    private async tryAcquireLock(): Promise<boolean> {\n        // Mock implementation - would use Redis SET NX PX\n        if (!this.redis[this.lockKey]) {\n            this.redis[this.lockKey] = {\n                owner: this.ownerId,\n                expires: Date.now() + (this.ttlSeconds * 1000)\n            };\n            return true;\n        }\n        return false;\n    }\n    \n    private async tryStealExpiredLock(): Promise<boolean> {\n        const lockData = this.redis[this.lockKey];\n        if (lockData && Date.now() > lockData.expires) {\n            // Lock is expired, try to steal it\n            lockData.owner = this.ownerId;\n            lockData.expires = Date.now() + (this.ttlSeconds * 1000);\n            return true;\n        }\n        return false;\n    }\n    \n    async release(): Promise<boolean> {\n        const lockData = this.redis[this.lockKey];\n        if (lockData && lockData.owner === this.ownerId) {\n            delete this.redis[this.lockKey];\n            return true;\n        }\n        return false;\n    }\n    \n    async extend(ttlSeconds?: number): Promise<boolean> {\n        const lockData = this.redis[this.lockKey];\n        if (lockData && lockData.owner === this.ownerId) {\n            lockData.expires = Date.now() + ((ttlSeconds || this.ttlSeconds) * 1000);\n            return true;\n        }\n        return false;\n    }\n}\n\nclass DistributedLockManager {\n    private redis: any;\n    private locks: Map<string, DistributedLock> = new Map();\n    \n    constructor(redisHost = 'localhost', redisPort = 6379) {\n        this.redis = {}; // Mock Redis\n    }\n    \n    getLock(lockKey: string, options?: LockOptions): DistributedLock {\n        if (!this.locks.has(lockKey)) {\n            this.locks.set(lockKey, new DistributedLock(lockKey, options));\n        }\n        return this.locks.get(lockKey)!;\n    }\n    \n    async cleanupExpiredLocks(): Promise<number> {\n        let cleaned = 0;\n        const now = Date.now();\n        \n        for (const [key, lockData] of Object.entries(this.redis)) {\n            const data = lockData as any;\n            if (data.expires && now > data.expires) {\n                delete this.redis[key];\n                cleaned++;\n            }\n        }\n        \n        return cleaned;\n    }\n}\n\nfunction distributedLockManager(redisHost = 'localhost', redisPort = 6379): DistributedLockManager {\n    return new DistributedLockManager(redisHost, redisPort);\n}","assertions":"const manager = distributedLockManager();\nconst lock = manager.getLock('test_lock', { ttlSeconds: 5 });\n\n// Test acquiring lock\nlet acquired = await lock.acquire();\nif (!acquired) throw new Error('Failed to acquire lock');\n\n// Test extending lock\nlet extended = await lock.extend(10);\nif (!extended) throw new Error('Failed to extend lock');\n\n// Test releasing lock\nlet released = await lock.release();\nif (!released) throw new Error('Failed to release lock');\n\n// Test acquiring again (should succeed now)\nacquired = await lock.acquire();\nif (!acquired) throw new Error('Failed to acquire lock after release');\n\n// Test cleanup\nawait lock.release(); // Release so cleanup can work\nconst cleaned = await manager.cleanupExpiredLocks();\nif (cleaned < 0) throw new Error('Cleanup should return non-negative count');\n\n// Verify operations completed without throwing\nconsole.log('All lock operations completed successfully');","metadata":{"language":"TypeScript","function_name":"distributedLockManager","difficulty":"very_advanced","category":"concurrency","complexity":0.9}}
{"query_id":"synthetic-066","query_text":"Write a TypeScript function named `implementSkipList` that implements a skip list data structure with search, insert, and delete operations. The skip list should provide O(log n) average time complexity. Language: TypeScript. Function name: implementSkipList","reference_answer":"class SkipListNode<T> {\n    key: T | null;\n    value: any;\n    forward: (SkipListNode<T> | null)[];\n    \n    constructor(key: T | null, value: any, level: number) {\n        this.key = key;\n        this.value = value;\n        this.forward = new Array(level + 1).fill(null);\n    }\n}\n\nclass SkipList<T> {\n    private head: SkipListNode<T>;\n    private level: number;\n    private maxLevel: number;\n    private p: number;\n    \n    constructor(maxLevel = 16, p = 0.5) {\n        this.maxLevel = maxLevel;\n        this.p = p;\n        this.level = 0;\n        this.head = new SkipListNode<T>(null, null, maxLevel);\n    }\n    \n    private randomLevel(): number {\n        let level = 0;\n        while (Math.random() < this.p && level < this.maxLevel) {\n            level++;\n        }\n        return level;\n    }\n    \n    search(key: T): any {\n        let current = this.head;\n        \n        for (let i = this.level; i >= 0; i--) {\n            while (current.forward[i] && \n                   current.forward[i]!.key !== null && \n                   (current.forward[i]!.key as any) < key) {\n                current = current.forward[i]!;\n            }\n        }\n        \n        current = current.forward[0]!;\n        if (current && current.key === key) {\n            return current.value;\n        }\n        return null;\n    }\n    \n    insert(key: T, value: any): void {\n        const update: (SkipListNode<T> | null)[] = new Array(this.maxLevel + 1).fill(null);\n        let current = this.head;\n        \n        for (let i = this.level; i >= 0; i--) {\n            while (current.forward[i] && \n                   current.forward[i]!.key !== null && \n                   (current.forward[i]!.key as any) < key) {\n                current = current.forward[i]!;\n            }\n            update[i] = current;\n        }\n        \n        current = current.forward[0]!;\n        \n        // If key already exists, update value\n        if (current && current.key === key) {\n            current.value = value;\n            return;\n        }\n        \n        const newLevel = this.randomLevel();\n        \n        if (newLevel > this.level) {\n            for (let i = this.level + 1; i <= newLevel; i++) {\n                update[i] = this.head;\n            }\n            this.level = newLevel;\n        }\n        \n        const newNode = new SkipListNode(key, value, newLevel);\n        \n        for (let i = 0; i <= newLevel; i++) {\n            newNode.forward[i] = update[i]!.forward[i];\n            update[i]!.forward[i] = newNode;\n        }\n    }\n    \n    delete(key: T): boolean {\n        const update: (SkipListNode<T> | null)[] = new Array(this.maxLevel + 1).fill(null);\n        let current = this.head;\n        \n        for (let i = this.level; i >= 0; i--) {\n            while (current.forward[i] && \n                   current.forward[i]!.key !== null && \n                   (current.forward[i]!.key as any) < key) {\n                current = current.forward[i]!;\n            }\n            update[i] = current;\n        }\n        \n        current = current.forward[0]!;\n        \n        if (!current || current.key !== key) {\n            return false;\n        }\n        \n        for (let i = 0; i <= this.level; i++) {\n            if (update[i]!.forward[i] !== current) {\n                break;\n            }\n            update[i]!.forward[i] = current.forward[i];\n        }\n        \n        while (this.level > 0 && this.head.forward[this.level] === null) {\n            this.level--;\n        }\n        \n        return true;\n    }\n    \n    contains(key: T): boolean {\n        return this.search(key) !== null;\n    }\n}\n\nfunction implementSkipList<T>(maxLevel = 16): SkipList<T> {\n    return new SkipList<T>(maxLevel);\n}","assertions":"const skipList = implementSkipList<number>();\n\n// Test insert and search\nskipList.insert(1, \"one\");\nskipList.insert(3, \"three\");\nskipList.insert(2, \"two\");\n\nif (skipList.search(1) !== \"one\") throw new Error(\"Failed: search existing key 1\");\nif (skipList.search(2) !== \"two\") throw new Error(\"Failed: search existing key 2\");\nif (skipList.search(3) !== \"three\") throw new Error(\"Failed: search existing key 3\");\nif (skipList.search(4) !== null) throw new Error(\"Failed: search non-existing key\");\n\n// Test contains\nif (!skipList.contains(1)) throw new Error(\"Failed: contains existing key\");\nif (skipList.contains(4)) throw new Error(\"Failed: contains non-existing key\");\n\n// Test delete\nif (!skipList.delete(2)) throw new Error(\"Failed: delete existing key\");\nif (skipList.search(2) !== null) throw new Error(\"Failed: search deleted key\");\nif (skipList.delete(2)) throw new Error(\"Failed: delete already deleted key\");\n\n// Test update\nskipList.insert(1, \"uno\");\nif (skipList.search(1) !== \"uno\") throw new Error(\"Failed: update existing key\");","metadata":{"language":"TypeScript","function_name":"implementSkipList","difficulty":"very_advanced","category":"data_structures","complexity":0.85}}
{"query_id":"synthetic-067","query_text":"Write a TypeScript function named `concurrentPriorityQueue` that implements a thread-safe priority queue with concurrent access, priority updates, and efficient blocking operations. Language: TypeScript. Function name: concurrentPriorityQueue","reference_answer":"interface QueueItem<T> {\n    priority: number;\n    seqNum: number;\n    item: T;\n    valid: boolean;\n}\n\nclass ConcurrentPriorityQueue<T> {\n    private heap: QueueItem<T>[] = [];\n    private itemToEntry: Map<T, { priority: number; seqNum: number }> = new Map();\n    private seqNum = 0;\n    private waiting: Array<(item: T) => void> = [];\n    private maxSize?: number;\n    \n    constructor(maxSize?: number) {\n        this.maxSize = maxSize;\n    }\n    \n    async put(item: T, priority = 0): Promise<void> {\n        // Check if item already exists\n        if (this.itemToEntry.has(item)) {\n            // Invalidate old entry (lazy deletion)\n            this.itemToEntry.set(item, { priority: -1, seqNum: -1 });\n        }\n        \n        // Check size limit\n        if (this.maxSize && this.heap.length >= this.maxSize) {\n            await new Promise<void>((resolve) => {\n                this.waiting.push(resolve);\n            });\n        }\n        \n        this.seqNum++;\n        const entry: QueueItem<T> = {\n            priority,\n            seqNum: this.seqNum,\n            item,\n            valid: true\n        };\n        \n        this.heap.push(entry);\n        this.itemToEntry.set(item, { priority, seqNum: this.seqNum });\n        \n        // Bubble up\n        this.bubbleUp(this.heap.length - 1);\n    }\n    \n    async get(): Promise<T | null> {\n        while (this.heap.length > 0) {\n            const entry = this.heap[0];\n            \n            // Check if entry is still valid\n            const currentEntry = this.itemToEntry.get(entry.item);\n            if (currentEntry && currentEntry.seqNum === entry.seqNum) {\n                // Remove from heap\n                this.heap[0] = this.heap[this.heap.length - 1];\n                this.heap.pop();\n                this.bubbleDown(0);\n                \n                this.itemToEntry.delete(entry.item);\n                \n                // Notify waiting put operations\n                if (this.waiting.length > 0) {\n                    const resolve = this.waiting.shift()!;\n                    resolve();\n                }\n                \n                return entry.item;\n            } else {\n                // Remove invalid entry\n                this.heap[0] = this.heap[this.heap.length - 1];\n                this.heap.pop();\n                this.bubbleDown(0);\n            }\n        }\n        return null;\n    }\n    \n    async updatePriority(item: T, newPriority: number): Promise<boolean> {\n        if (!this.itemToEntry.has(item)) {\n            return false;\n        }\n        \n        // Invalidate old entry\n        this.itemToEntry.set(item, { priority: -1, seqNum: -1 });\n        \n        // Add new entry with updated priority\n        await this.put(item, newPriority);\n        return true;\n    }\n    \n    peek(): T | null {\n        while (this.heap.length > 0) {\n            const entry = this.heap[0];\n            const currentEntry = this.itemToEntry.get(entry.item);\n            if (currentEntry && currentEntry.seqNum === entry.seqNum) {\n                return entry.item;\n            }\n            // Remove invalid entry\n            this.heap[0] = this.heap[this.heap.length - 1];\n            this.heap.pop();\n            this.bubbleDown(0);\n        }\n        return null;\n    }\n    \n    size(): number {\n        return this.validItemsCount();\n    }\n    \n    private validItemsCount(): number {\n        let count = 0;\n        for (const entry of this.heap) {\n            const currentEntry = this.itemToEntry.get(entry.item);\n            if (currentEntry && currentEntry.seqNum === entry.seqNum) {\n                count++;\n            }\n        }\n        return count;\n    }\n    \n    private bubbleUp(index: number): void {\n        while (index > 0) {\n            const parentIndex = Math.floor((index - 1) / 2);\n            if (this.compare(index, parentIndex) >= 0) {\n                break;\n            }\n            this.swap(index, parentIndex);\n            index = parentIndex;\n        }\n    }\n    \n    private bubbleDown(index: number): void {\n        const size = this.heap.length;\n        while (true) {\n            let smallest = index;\n            const left = 2 * index + 1;\n            const right = 2 * index + 2;\n            \n            if (left < size && this.compare(left, smallest) < 0) {\n                smallest = left;\n            }\n            if (right < size && this.compare(right, smallest) < 0) {\n                smallest = right;\n            }\n            \n            if (smallest === index) {\n                break;\n            }\n            \n            this.swap(index, smallest);\n            index = smallest;\n        }\n    }\n    \n    private compare(i: number, j: number): number {\n        const itemI = this.heap[i];\n        const itemJ = this.heap[j];\n        \n        if (itemI.priority !== itemJ.priority) {\n            return itemI.priority - itemJ.priority;\n        }\n        return itemI.seqNum - itemJ.seqNum;\n    }\n    \n    private swap(i: number, j: number): void {\n        [this.heap[i], this.heap[j]] = [this.heap[j], this.heap[i]];\n    }\n}\n\nfunction concurrentPriorityQueue<T>(maxSize?: number): ConcurrentPriorityQueue<T> {\n    return new ConcurrentPriorityQueue<T>(maxSize);\n}","assertions":"const queue = concurrentPriorityQueue<string>();\n\n// Test put and get\nawait queue.put(\"low\", 2);\nawait queue.put(\"high\", 1);\nawait queue.put(\"medium\", 1);\n\nlet item1 = await queue.get();\nlet item2 = await queue.get();\n\n// Higher priority items should come first\nif (item1 !== \"high\" && item1 !== \"medium\") {\n    throw new Error(`Unexpected first item: ${item1}`);\n}\nif (item2 !== \"high\" && item2 !== \"medium\") {\n    throw new Error(`Unexpected second item: ${item2}`);\n}\nif (item1 === item2) {\n    throw new Error(\"Should get different items\");\n}\n\n// Test priority update\nawait queue.put(\"updatable\", 3);\nawait queue.updatePriority(\"updatable\", 0);\nconst nextItem = await queue.get();\nif (nextItem !== \"updatable\") {\n    throw new Error(`Priority update failed, got: ${nextItem}`);\n}\n\n// Test peek\nawait queue.put(\"peek_test\", 1);\nconst peeked = queue.peek();\nif (peeked !== \"peek_test\") {\n    throw new Error(`Peek failed, got: ${peeked}`);\n}\n\n// Peek shouldn't remove item\nconst peekedAgain = queue.peek();\nif (peekedAgain !== \"peek_test\") {\n    throw new Error(`Peek should not remove item`);\n}","metadata":{"language":"TypeScript","function_name":"concurrentPriorityQueue","difficulty":"very_advanced","category":"concurrency","complexity":0.9}}
{"query_id":"synthetic-068","query_text":"Write a TypeScript function named `implementSegmentTree` that implements a segment tree for range minimum queries and range updates. The tree should support efficient range queries and point updates. Language: TypeScript. Function name: implementSegmentTree","reference_answer":"class SegmentTree {\n    private tree: number[];\n    private lazy: number[];\n    private n: number;\n    \n    constructor(arr: number[]) {\n        this.n = arr.length;\n        this.tree = new Array(4 * this.n).fill(0);\n        this.lazy = new Array(4 * this.n).fill(0);\n        this.build(arr, 0, 0, this.n - 1);\n    }\n    \n    private build(arr: number[], node: number, start: number, end: number): void {\n        if (start === end) {\n            this.tree[node] = arr[start];\n            return;\n        }\n        \n        const mid = Math.floor((start + end) / 2);\n        this.build(arr, 2 * node + 1, start, mid);\n        this.build(arr, 2 * node + 2, mid + 1, end);\n        this.tree[node] = Math.min(this.tree[2 * node + 1], this.tree[2 * node + 2]);\n    }\n    \n    private propagateLazy(node: number, start: number, end: number): void {\n        if (this.lazy[node] !== 0) {\n            this.tree[node] += this.lazy[node];\n            if (start !== end) {\n                this.lazy[2 * node + 1] += this.lazy[node];\n                this.lazy[2 * node + 2] += this.lazy[node];\n            }\n            this.lazy[node] = 0;\n        }\n    }\n    \n    updateRange(left: number, right: number, val: number): void {\n        this.updateRangeHelper(0, 0, this.n - 1, left, right, val);\n    }\n    \n    private updateRangeHelper(node: number, start: number, end: number, \n                              left: number, right: number, val: number): void {\n        this.propagateLazy(node, start, end);\n        \n        if (start > end || start > right || end < left) {\n            return;\n        }\n        \n        if (left <= start && end <= right) {\n            this.lazy[node] += val;\n            this.propagateLazy(node, start, end);\n            return;\n        }\n        \n        const mid = Math.floor((start + end) / 2);\n        this.updateRangeHelper(2 * node + 1, start, mid, left, right, val);\n        this.updateRangeHelper(2 * node + 2, mid + 1, end, left, right, val);\n        this.tree[node] = Math.min(this.tree[2 * node + 1], this.tree[2 * node + 2]);\n    }\n    \n    queryRange(left: number, right: number): number {\n        return this.queryRangeHelper(0, 0, this.n - 1, left, right);\n    }\n    \n    private queryRangeHelper(node: number, start: number, end: number, \n                             left: number, right: number): number {\n        this.propagateLazy(node, start, end);\n        \n        if (start > end || start > right || end < left) {\n            return Number.MAX_SAFE_INTEGER;\n        }\n        \n        if (left <= start && end <= right) {\n            return this.tree[node];\n        }\n        \n        const mid = Math.floor((start + end) / 2);\n        const leftMin = this.queryRangeHelper(2 * node + 1, start, mid, left, right);\n        const rightMin = this.queryRangeHelper(2 * node + 2, mid + 1, end, left, right);\n        return Math.min(leftMin, rightMin);\n    }\n    \n    updatePoint(index: number, val: number): void {\n        const diff = val - this.queryRange(index, index);\n        this.updateRange(index, index, diff);\n    }\n}\n\nfunction implementSegmentTree(arr: number[]): SegmentTree {\n    return new SegmentTree(arr);\n}","assertions":"const arr = [1, 3, 2, 7, 9, 11];\nconst segTree = implementSegmentTree(arr);\n\n// Test range minimum queries\nif (segTree.queryRange(0, 2) !== 1) throw new Error(\"Failed: min(1,3,2) should be 1\");\nif (segTree.queryRange(3, 5) !== 7) throw new Error(\"Failed: min(7,9,11) should be 7\");\nif (segTree.queryRange(1, 4) !== 2) throw new Error(\"Failed: min(3,2,7,9) should be 2\");\n\n// Test point updates\nsegTree.updatePoint(2, 0); // Change index 2 from 2 to 0\nif (segTree.queryRange(0, 2) !== 0) throw new Error(\"Failed: min(1,3,0) should be 0\");\n\n// Test range updates\nsegTree.updateRange(1, 3, 10); // Add 10 to range [1,3]\nif (segTree.queryRange(1, 3) !== 10) throw new Error(\"Failed: min(13,10,17) should be 10\");\nif (segTree.queryRange(0, 0) !== 1) throw new Error(\"Failed: index 0 should be unchanged\");\nif (segTree.queryRange(4, 5) !== 9) throw new Error(\"Failed: min(9,11) should be unchanged\");","metadata":{"language":"TypeScript","function_name":"implementSegmentTree","difficulty":"very_advanced","category":"data_structures","complexity":0.9}}
{"query_id":"synthetic-069","query_text":"Write a TypeScript function named `distributedRateLimiter` that implements a distributed rate limiter using Redis with sliding window and fixed window algorithms, automatic cleanup, and cluster awareness. Language: TypeScript. Function name: distributedRateLimiter","reference_answer":"enum RateLimitAlgorithm {\n    FIXED_WINDOW = \"fixed_window\",\n    SLIDING_WINDOW = \"sliding_window\"\n}\n\nclass DistributedRateLimiter {\n    private redis: any; // Mock Redis for this example\n    private algorithm: RateLimitAlgorithm;\n    \n    constructor(redisHost = 'localhost', redisPort = 6379, \n                algorithm: RateLimitAlgorithm = RateLimitAlgorithm.SLIDING_WINDOW) {\n        this.redis = {}; // Mock Redis\n        this.algorithm = algorithm;\n    }\n    \n    async isAllowed(key: string, limit: number, windowSeconds: number): Promise<boolean> {\n        if (this.algorithm === RateLimitAlgorithm.FIXED_WINDOW) {\n            return this.checkFixedWindow(key, limit, windowSeconds);\n        } else {\n            return this.checkSlidingWindow(key, limit, windowSeconds);\n        }\n    }\n    \n    private checkFixedWindow(key: string, limit: number, windowSeconds: number): boolean {\n        const currentWindow = Math.floor(Date.now() / (windowSeconds * 1000));\n        const windowKey = `${key}:${currentWindow}`;\n        \n        // Mock Redis operations\n        if (!this.redis[windowKey]) {\n            this.redis[windowKey] = { count: 0, expires: (currentWindow + 1) * windowSeconds * 1000 };\n        }\n        \n        if (this.redis[windowKey].count < limit) {\n            this.redis[windowKey].count++;\n            return true;\n        }\n        \n        return false;\n    }\n    \n    private checkSlidingWindow(key: string, limit: number, windowSeconds: number): boolean {\n        const now = Date.now();\n        const windowStart = now - (windowSeconds * 1000);\n        \n        // Add current request\n        if (!this.redis[key]) {\n            this.redis[key] = [];\n        }\n        this.redis[key].push(now);\n        \n        // Remove old requests\n        this.redis[key] = this.redis[key].filter((timestamp: number) => timestamp > windowStart);\n        \n        return this.redis[key].length <= limit;\n    }\n    \n    async getRemainingRequests(key: string, limit: number, windowSeconds: number): Promise<number> {\n        let currentCount: number;\n        \n        if (this.algorithm === RateLimitAlgorithm.FIXED_WINDOW) {\n            const currentWindow = Math.floor(Date.now() / (windowSeconds * 1000));\n            const windowKey = `${key}:${currentWindow}`;\n            currentCount = this.redis[windowKey]?.count || 0;\n        } else {\n            const now = Date.now();\n            const windowStart = now - (windowSeconds * 1000);\n            if (this.redis[key]) {\n                this.redis[key] = this.redis[key].filter((timestamp: number) => timestamp > windowStart);\n                currentCount = this.redis[key].length;\n            } else {\n                currentCount = 0;\n            }\n        }\n        \n        return Math.max(0, limit - currentCount);\n    }\n    \n    async getResetTime(key: string, windowSeconds: number): Promise<number> {\n        if (this.algorithm === RateLimitAlgorithm.FIXED_WINDOW) {\n            const currentWindow = Math.floor(Date.now() / (windowSeconds * 1000));\n            return (currentWindow + 1) * windowSeconds;\n        } else {\n            return Math.floor(Date.now() / 1000) + windowSeconds;\n        }\n    }\n}\n\nfunction distributedRateLimiter(\n    redisHost = 'localhost', \n    redisPort = 6379, \n    algorithm = 'sliding_window'\n): DistributedRateLimiter {\n    const algo = algorithm === 'sliding_window' ? \n        RateLimitAlgorithm.SLIDING_WINDOW : \n        RateLimitAlgorithm.FIXED_WINDOW;\n    return new DistributedRateLimiter(redisHost, redisPort, algo);\n}","assertions":"const limiter = distributedRateLimiter();\nconst testKey = \"test_api\";\n\n// Test basic rate limiting\nlet allowed = await limiter.isAllowed(testKey, 5, 60);\nif (!allowed) throw new Error(\"First request should be allowed\");\n\n// Test remaining requests\nlet remaining = await limiter.getRemainingRequests(testKey, 5, 60);\nif (remaining > 4) throw new Error(\"Should have 4 remaining requests\");\n\n// Test reset time\nlet resetTime = await limiter.getResetTime(testKey, 60);\nconst now = Math.floor(Date.now() / 1000);\nif (resetTime <= now) throw new Error(\"Reset time should be in the future\");\n\n// Test multiple requests\nfor (let i = 1; i < 5; i++) {\n    allowed = await limiter.isAllowed(testKey, 5, 60);\n    if (!allowed) throw new Error(`Request ${i} should be allowed`);\n}\n\n// 6th request should be denied\nallowed = await limiter.isAllowed(testKey, 5, 60);\nif (allowed) throw new Error(\"6th request should be denied\");\n\n// Check remaining requests\nremaining = await limiter.getRemainingRequests(testKey, 5, 60);\nif (remaining !== 0) throw new Error(\"Should have 0 remaining requests\");","metadata":{"language":"TypeScript","function_name":"distributedRateLimiter","difficulty":"very_advanced","category":"concurrency","complexity":0.9}}
{"query_id":"synthetic-070","query_text":"Write a TypeScript function named `concurrentSkipList` that implements a concurrent skip list with lock-free operations for search, insert, and delete. The implementation should use atomic operations and provide linearizability guarantees. Language: TypeScript. Function name: concurrentSkipList","reference_answer":"class ConcurrentSkipListNode<T> {\n    key: T | null;\n    value: any;\n    forward: (ConcurrentSkipListNode<T> | null)[];\n    lock: { acquire: () => void; release: () => void } | null;\n    marked: boolean;\n    fullyLinked: boolean;\n    \n    constructor(key: T | null, value: any, level: number) {\n        this.key = key;\n        this.value = value;\n        this.forward = new Array(level + 1).fill(null);\n        this.lock = null; // Simplified - no actual locking in this example\n        this.marked = false;\n        this.fullyLinked = false;\n    }\n}\n\nclass ConcurrentSkipList<T> {\n    private head: ConcurrentSkipListNode<T>;\n    private level: number;\n    private maxLevel: number;\n    private p: number;\n    \n    constructor(maxLevel = 16, p = 0.5) {\n        this.maxLevel = maxLevel;\n        this.p = p;\n        this.level = 0;\n        this.head = new ConcurrentSkipListNode<T>(null, null, maxLevel);\n    }\n    \n    private randomLevel(): number {\n        let level = 0;\n        while (Math.random() < this.p && level < this.maxLevel) {\n            level++;\n        }\n        return level;\n    }\n    \n    find(key: T): any {\n        let current = this.head;\n        \n        for (let i = this.level; i >= 0; i--) {\n            while (current.forward[i] && \n                   current.forward[i]!.key !== null && \n                   (current.forward[i]!.key as any) < key) {\n                current = current.forward[i]!;\n            }\n        }\n        \n        current = current.forward[0]!;\n        if (current && current.key === key && !current.marked) {\n            return current.value;\n        }\n        return null;\n    }\n    \n    insert(key: T, value: any): boolean {\n        const preds: (ConcurrentSkipListNode<T> | null)[] = new Array(this.maxLevel + 1).fill(null);\n        const succs: (ConcurrentSkipListNode<T> | null)[] = new Array(this.maxLevel + 1).fill(null);\n        \n        let current = this.head;\n        \n        for (let i = this.level; i >= 0; i--) {\n            while (current.forward[i] && \n                   current.forward[i]!.key !== null && \n                   (current.forward[i]!.key as any) < key) {\n                current = current.forward[i]!;\n            }\n            preds[i] = current;\n            succs[i] = current.forward[i];\n        }\n        \n        current = succs[0]!;\n        \n        if (current && current.key === key) {\n            current.value = value;\n            return true;\n        }\n        \n        const newLevel = this.randomLevel();\n        \n        if (newLevel > this.level) {\n            for (let i = this.level + 1; i <= newLevel; i++) {\n                preds[i] = this.head;\n            }\n            this.level = newLevel;\n        }\n        \n        const newNode = new ConcurrentSkipListNode(key, value, newLevel);\n        \n        for (let i = 0; i <= newLevel; i++) {\n            newNode.forward[i] = succs[i];\n            preds[i]!.forward[i] = newNode;\n        }\n        \n        newNode.fullyLinked = true;\n        return true;\n    }\n    \n    delete(key: T): boolean {\n        const preds: (ConcurrentSkipListNode<T> | null)[] = new Array(this.maxLevel + 1).fill(null);\n        const succs: (ConcurrentSkipListNode<T> | null)[] = new Array(this.maxLevel + 1).fill(null);\n        \n        let current = this.head;\n        \n        for (let i = this.level; i >= 0; i--) {\n            while (current.forward[i] && \n                   current.forward[i]!.key !== null && \n                   (current.forward[i]!.key as any) < key) {\n                current = current.forward[i]!;\n            }\n            preds[i] = current;\n            succs[i] = current.forward[i];\n        }\n        \n        current = succs[0]!;\n        \n        if (!current || current.key !== key) {\n            return false;\n        }\n        \n        current.marked = true;\n        \n        for (let i = 0; i <= this.level; i++) {\n            if (preds[i]!.forward[i] !== current) {\n                break;\n            }\n            preds[i]!.forward[i] = current.forward[i];\n        }\n        \n        while (this.level > 0 && this.head.forward[this.level] === null) {\n            this.level--;\n        }\n        \n        return true;\n    }\n    \n    contains(key: T): boolean {\n        return this.find(key) !== null;\n    }\n}\n\nfunction concurrentSkipList<T>(maxLevel = 16): ConcurrentSkipList<T> {\n    return new ConcurrentSkipList<T>(maxLevel);\n}","assertions":"const skipList = concurrentSkipList<number>();\n\n// Test concurrent operations\nskipList.insert(1, \"one\");\nskipList.insert(3, \"three\");\nskipList.insert(2, \"two\");\n\nif (skipList.find(1) !== \"one\") throw new Error(\"Failed: find existing key 1\");\nif (skipList.find(2) !== \"two\") throw new Error(\"Failed: find existing key 2\");\nif (skipList.find(3) !== \"three\") throw new Error(\"Failed: find existing key 3\");\nif (skipList.find(4) !== null) throw new Error(\"Failed: find non-existing key\");\n\n// Test delete\nif (!skipList.delete(2)) throw new Error(\"Failed: delete existing key\");\nif (skipList.find(2) !== null) throw new Error(\"Failed: find deleted key\");\nif (skipList.delete(2)) throw new Error(\"Failed: delete already deleted key\");\n\n// Test contains\nif (!skipList.contains(1)) throw new Error(\"Failed: contains existing key\");\nif (skipList.contains(4)) throw new Error(\"Failed: contains non-existing key\");","metadata":{"language":"TypeScript","function_name":"concurrentSkipList","difficulty":"very_advanced","category":"concurrency","complexity":0.95}}
{"query_id":"synthetic-071","query_text":"Write a TypeScript function named `implementBTree` that implements a B-Tree data structure with search, insert, and delete operations. The B-Tree should maintain balance and provide efficient disk-based storage characteristics. Language: TypeScript. Function name: implementBTree","reference_answer":"class BTreeNode<T> {\n    keys: T[];\n    children: (BTreeNode<T> | null)[];\n    isLeaf: boolean;\n    t: number; // Minimum degree\n    \n    constructor(t: number, isLeaf = false) {\n        this.t = t;\n        this.isLeaf = isLeaf;\n        this.keys = [];\n        this.children = [];\n    }\n    \n    isFull(): boolean {\n        return this.keys.length === 2 * this.t - 1;\n    }\n}\n\nclass BTree<T> {\n    private root: BTreeNode<T> | null;\n    private t: number; // Minimum degree\n    \n    constructor(t = 2) {\n        this.t = t;\n        this.root = null;\n    }\n    \n    search(key: T): BTreeNode<T> | null {\n        return this.root ? this.searchNode(this.root, key) : null;\n    }\n    \n    private searchNode(node: BTreeNode<T>, key: T): BTreeNode<T> | null {\n        let i = 0;\n        while (i < node.keys.length && (key as any) > (node.keys[i] as any)) {\n            i++;\n        }\n        \n        if (i < node.keys.length && node.keys[i] === key) {\n            return node;\n        }\n        \n        if (node.isLeaf) {\n            return null;\n        }\n        \n        return this.searchNode(node.children[i]!, key);\n    }\n    \n    insert(key: T): void {\n        if (!this.root) {\n            this.root = new BTreeNode<T>(this.t, true);\n            this.root.keys.push(key);\n            return;\n        }\n        \n        if (this.root.isFull()) {\n            const newRoot = new BTreeNode<T>(this.t, false);\n            newRoot.children.push(this.root);\n            this.splitChild(newRoot, 0);\n            this.root = newRoot;\n        }\n        \n        this.insertNonFull(this.root, key);\n    }\n    \n    private insertNonFull(node: BTreeNode<T>, key: T): void {\n        if (node.isLeaf) {\n            let i = node.keys.length - 1;\n            node.keys.push(key);\n            while (i >= 0 && (key as any) < (node.keys[i] as any)) {\n                node.keys[i + 1] = node.keys[i];\n                i--;\n            }\n            node.keys[i + 1] = key;\n        } else {\n            let i = node.keys.length - 1;\n            while (i >= 0 && (key as any) < (node.keys[i] as any)) {\n                i--;\n            }\n            i++;\n            \n            if (node.children[i]!.isFull()) {\n                this.splitChild(node, i);\n                if ((key as any) > (node.keys[i] as any)) {\n                    i++;\n                }\n            }\n            \n            this.insertNonFull(node.children[i]!, key);\n        }\n    }\n    \n    private splitChild(parent: BTreeNode<T>, i: number): void {\n        const t = this.t;\n        const y = parent.children[i]!;\n        const z = new BTreeNode<T>(t, y.isLeaf);\n        \n        parent.children.splice(i + 1, 0, z);\n        parent.keys.splice(i, 0, y.keys[t - 1]);\n        \n        z.keys = y.keys.splice(t);\n        \n        if (!y.isLeaf) {\n            z.children = y.children.splice(t);\n        }\n    }\n    \n    delete(key: T): boolean {\n        if (!this.root) {\n            return false;\n        }\n        \n        const result = this.deleteFromNode(this.root, key);\n        \n        if (this.root.keys.length === 0) {\n            if (!this.root.isLeaf) {\n                this.root = this.root.children[0];\n            } else {\n                this.root = null;\n            }\n        }\n        \n        return result;\n    }\n    \n    private deleteFromNode(node: BTreeNode<T>, key: T): boolean {\n        let i = 0;\n        while (i < node.keys.length && (key as any) > (node.keys[i] as any)) {\n            i++;\n        }\n        \n        if (node.isLeaf) {\n            if (i < node.keys.length && node.keys[i] === key) {\n                node.keys.splice(i, 1);\n                return true;\n            }\n            return false;\n        }\n        \n        if (i < node.keys.length && node.keys[i] === key) {\n            return this.deleteInternalNode(node, i);\n        } else if (node.children[i]!.keys.length >= this.t) {\n            return this.deleteFromNode(node.children[i]!, key);\n        } else {\n            this.fill(node, i);\n            return this.deleteFromNode(node.children[i]!, key);\n        }\n    }\n    \n    private deleteInternalNode(node: BTreeNode<T>, i: number): boolean {\n        const key = node.keys[i];\n        \n        if (node.children[i]!.keys.length >= this.t) {\n            const pred = this.getPredecessor(node.children[i]!);\n            node.keys[i] = pred;\n            return this.deleteFromNode(node.children[i]!, pred);\n        } else if (node.children[i + 1]!.keys.length >= this.t) {\n            const succ = this.getSuccessor(node.children[i + 1]!);\n            node.keys[i] = succ;\n            return this.deleteFromNode(node.children[i + 1]!, succ);\n        } else {\n            this.merge(node, i);\n            return this.deleteFromNode(node.children[i]!, key);\n        }\n    }\n    \n    private fill(node: BTreeNode<T>, i: number): void {\n        if (i !== 0 && node.children[i - 1]!.keys.length >= this.t) {\n            this.borrowFromPrev(node, i);\n        } else if (i !== node.keys.length && node.children[i + 1]!.keys.length >= this.t) {\n            this.borrowFromNext(node, i);\n        } else {\n            if (i !== node.keys.length) {\n                this.merge(node, i);\n            } else {\n                this.merge(node, i - 1);\n            }\n        }\n    }\n    \n    private borrowFromPrev(node: BTreeNode<T>, i: number): void {\n        const child = node.children[i]!;\n        const sibling = node.children[i - 1]!;\n        \n        child.keys.unshift(node.keys[i - 1]);\n        \n        if (!child.isLeaf) {\n            child.children.unshift(sibling.children.pop()!);\n        }\n        \n        node.keys[i - 1] = sibling.keys.pop()!;\n    }\n    \n    private borrowFromNext(node: BTreeNode<T>, i: number): void {\n        const child = node.children[i]!;\n        const sibling = node.children[i + 1]!;\n        \n        child.keys.push(node.keys[i]);\n        \n        if (!child.isLeaf) {\n            child.children.push(sibling.children.shift()!);\n        }\n        \n        node.keys[i] = sibling.keys.shift()!;\n    }\n    \n    private merge(node: BTreeNode<T>, i: number): void {\n        const child = node.children[i]!;\n        const sibling = node.children[i + 1]!;\n        \n        child.keys.push(node.keys[i]);\n        child.keys.push(...sibling.keys);\n        \n        if (!child.isLeaf) {\n            child.children.push(...sibling.children);\n        }\n        \n        node.keys.splice(i, 1);\n        node.children.splice(i + 1, 1);\n    }\n    \n    private getPredecessor(node: BTreeNode<T>): T {\n        let current = node;\n        while (!current.isLeaf) {\n            current = current.children[current.children.length - 1]!;\n        }\n        return current.keys[current.keys.length - 1];\n    }\n    \n    private getSuccessor(node: BTreeNode<T>): T {\n        let current = node;\n        while (!current.isLeaf) {\n            current = current.children[0]!;\n        }\n        return current.keys[0];\n    }\n}\n\nfunction implementBTree<T>(t = 2): BTree<T> {\n    return new BTree<T>(t);\n}","assertions":"const btree = implementBTree<number>(2);\n\n// Test insertions\nbtree.insert(10);\nbtree.insert(20);\nbtree.insert(5);\nbtree.insert(15);\nbtree.insert(25);\n\n// Test search\nif (!btree.search(10)) throw new Error(\"Failed: search existing key 10\");\nif (!btree.search(20)) throw new Error(\"Failed: search existing key 20\");\nif (btree.search(99)) throw new Error(\"Failed: search non-existing key 99\");\n\n// Test delete\nif (!btree.delete(15)) throw new Error(\"Failed: delete existing key 15\");\nif (btree.search(15)) throw new Error(\"Failed: search deleted key 15\");\nif (btree.delete(99)) throw new Error(\"Failed: delete non-existing key\");","metadata":{"language":"TypeScript","function_name":"implementBTree","difficulty":"very_advanced","category":"data_structures","complexity":0.95}}
{"query_id":"synthetic-072","query_text":"Write a TypeScript function named `heapMedian` that implements a data structure to efficiently find the median of a stream of numbers using two heaps (max-heap for lower half, min-heap for upper half). Language: TypeScript. Function name: heapMedian","reference_answer":"class MedianFinder {\n    private lowerHalf: number[]; // Max-heap (inverted)\n    private upperHalf: number[]; // Min-heap\n    \n    constructor() {\n        this.lowerHalf = [];\n        this.upperHalf = [];\n    }\n    \n    addNumber(num: number): void {\n        if (this.lowerHalf.length === 0 || num <= -this.lowerHalf[0]) {\n            this.lowerHalf.push(-num);\n            this.lowerHalf.sort((a, b) => b - a); // Max-heap\n        } else {\n            this.upperHalf.push(num);\n            this.upperHalf.sort((a, b) => a - b); // Min-heap\n        }\n        \n        // Balance heaps\n        if (this.lowerHalf.length > this.upperHalf.length + 1) {\n            const val = -this.lowerHalf.shift()!;\n            this.upperHalf.push(val);\n            this.upperHalf.sort((a, b) => a - b);\n        } else if (this.upperHalf.length > this.lowerHalf.length) {\n            const val = this.upperHalf.shift()!;\n            this.lowerHalf.push(-val);\n            this.lowerHalf.sort((a, b) => b - a);\n        }\n    }\n    \n    findMedian(): number {\n        if (this.lowerHalf.length === 0 && this.upperHalf.length === 0) {\n            throw new Error(\"No numbers added yet\");\n        }\n        \n        if (this.lowerHalf.length > this.upperHalf.length) {\n            return -this.lowerHalf[0];\n        } else {\n            return (-this.lowerHalf[0] + this.upperHalf[0]) / 2;\n        }\n    }\n}\n\nfunction heapMedian(): MedianFinder {\n    return new MedianFinder();\n}","assertions":"const finder = heapMedian();\n\n// Test with odd number of elements\nfinder.addNumber(1);\nif (finder.findMedian() !== 1.0) throw new Error(\"Failed: single element\");\n\nfinder.addNumber(2);\nif (finder.findMedian() !== 1.5) throw new Error(\"Failed: two elements\");\n\nfinder.addNumber(3);\nif (finder.findMedian() !== 2.0) throw new Error(\"Failed: three elements\");\n\n// Test with even number\nfinder.addNumber(4);\nif (finder.findMedian() !== 2.5) throw new Error(\"Failed: four elements\");\n\nfinder.addNumber(5);\nif (finder.findMedian() !== 3.0) throw new Error(\"Failed: five elements\");\n\n// Test unsorted order\nconst finder2 = heapMedian();\nconst numbers = [5, 2, 8, 1, 9, 3];\nfor (const num of numbers) {\n    finder2.addNumber(num);\n}\n\nif (finder2.findMedian() !== 4.0) throw new Error(\"Failed: unsorted input\");","metadata":{"language":"TypeScript","function_name":"heapMedian","difficulty":"very_advanced","category":"data_structures","complexity":0.8}}
{"query_id":"synthetic-073","query_text":"Write a TypeScript function named `distributedPubSub` that implements a distributed publish-subscribe system with topic-based routing, message persistence, and fault-tolerant delivery using Redis as the backend. Language: TypeScript. Function name: distributedPubSub","reference_answer":"interface Message {\n    id: string;\n    topic: string;\n    payload: any;\n    timestamp: number;\n    publisherId: string;\n}\n\ninterface PublishResult {\n    messageId: string;\n}\n\ninterface SubscribeCallback {\n    (message: Message): void;\n}\n\nclass DistributedPubSub {\n    private redis: any; // Mock Redis for this example\n    private subscriptions: Map<string, SubscribeCallback[]> = new Map();\n    private messageTtl = 3600000; // 1 hour in milliseconds\n    \n    constructor(redisHost = 'localhost', redisPort = 6379) {\n        this.redis = {}; // Mock Redis\n    }\n    \n    async publish(topic: string, payload: any): Promise<PublishResult> {\n        const message: Message = {\n            id: `msg_${Date.now()}_${Math.random()}`,\n            topic,\n            payload,\n            timestamp: Date.now(),\n            publisherId: `pub_${Date.now()}`\n        };\n        \n        // Store message persistently\n        const messageKey = `message:${message.id}`;\n        this.redis[messageKey] = {\n            ...message,\n            expires: Date.now() + this.messageTtl\n        };\n        \n        // Add to topic queue\n        const topicKey = `topic:${topic}`;\n        if (!this.redis[topicKey]) {\n            this.redis[topicKey] = [];\n        }\n        this.redis[topicKey].push(message.id);\n        \n        // Publish to local subscribers\n        const subscribers = this.subscriptions.get(topic);\n        if (subscribers) {\n            for (const callback of subscribers) {\n                try {\n                    callback(message);\n                } catch (error) {\n                    console.error('Subscriber callback error:', error);\n                }\n            }\n        }\n        \n        return { messageId: message.id };\n    }\n    \n    subscribe(topic: string, callback: SubscribeCallback): void {\n        if (!this.subscriptions.has(topic)) {\n            this.subscriptions.set(topic, []);\n        }\n        this.subscriptions.get(topic)!.push(callback);\n    }\n    \n    unsubscribe(topic: string, callback: SubscribeCallback): boolean {\n        const subscribers = this.subscriptions.get(topic);\n        if (subscribers) {\n            const index = subscribers.indexOf(callback);\n            if (index > -1) {\n                subscribers.splice(index, 1);\n                return true;\n            }\n        }\n        return false;\n    }\n    \n    async getTopicMessages(topic: string, limit = 100): Promise<Message[]> {\n        const topicKey = `topic:${topic}`;\n        const messageIds = this.redis[topicKey] || [];\n        \n        const messages: Message[] = [];\n        const endIndex = Math.min(messageIds.length, limit);\n        \n        for (let i = messageIds.length - endIndex; i < messageIds.length; i++) {\n            const messageId = messageIds[i];\n            const messageKey = `message:${messageId}`;\n            const storedMessage = this.redis[messageKey];\n            \n            if (storedMessage && Date.now() < storedMessage.expires) {\n                messages.push({\n                    id: storedMessage.id,\n                    topic: storedMessage.topic,\n                    payload: storedMessage.payload,\n                    timestamp: storedMessage.timestamp,\n                    publisherId: storedMessage.publisherId\n                });\n            }\n        }\n        \n        return messages;\n    }\n    \n    async acknowledgeMessage(messageId: string): Promise<boolean> {\n        const ackKey = `ack:${messageId}`;\n        this.redis[ackKey] = {\n            acknowledged: true,\n            timestamp: Date.now()\n        };\n        return true;\n    }\n    \n    async cleanupExpiredMessages(): Promise<number> {\n        let cleaned = 0;\n        const now = Date.now();\n        \n        // Clean up expired messages\n        for (const key of Object.keys(this.redis)) {\n            if (key.startsWith('message:') && this.redis[key].expires < now) {\n                delete this.redis[key];\n                cleaned++;\n            }\n        }\n        \n        return cleaned;\n    }\n}\n\nfunction distributedPubSub(redisHost = 'localhost', redisPort = 6379): DistributedPubSub {\n    return new DistributedPubSub(redisHost, redisPort);\n}","assertions":"const pubsub = distributedPubSub();\n\nconst receivedMessages: Message[] = [];\nconst testCallback = (message: Message) => {\n    receivedMessages.push(message);\n};\n\n// Subscribe to a topic\npubsub.subscribe('test_topic', testCallback);\n\n// Publish a message\nconst result = await pubsub.publish('test_topic', { data: 'test payload' });\nif (!result.messageId) throw new Error('Should return message ID');\n\n// Check that local subscriber received the message\nif (receivedMessages.length !== 1) throw new Error('Should receive message');\nif (receivedMessages[0].topic !== 'test_topic') throw new Error('Wrong topic');\nif (receivedMessages[0].payload.data !== 'test payload') throw new Error('Wrong payload');\n\n// Test getting topic messages\nconst messages = await pubsub.getTopicMessages('test_topic', 10);\nif (messages.length !== 1) throw new Error('Should retrieve message');\n\n// Test unsubscribe\nif (!pubsub.unsubscribe('test_topic', testCallback)) throw new Error('Should unsubscribe');\nif (pubsub.unsubscribe('test_topic', testCallback)) throw new Error('Should not unsubscribe again');\n\n// Test acknowledge\nif (!(await pubsub.acknowledgeMessage(result.messageId))) throw new Error('Should acknowledge');\n\n// Test cleanup\npubsub['redis']['message:old_msg'] = { expires: Date.now() - 1000 }; // Expired\nconst cleaned = await pubsub.cleanupExpiredMessages();\nif (cleaned < 1) throw new Error('Should clean expired messages');","metadata":{"language":"TypeScript","function_name":"distributedPubSub","difficulty":"very_advanced","category":"concurrency","complexity":0.9}}
{"query_id":"synthetic-074","query_text":"Write a TypeScript function named `asyncCircuitBreakerAdvanced` that implements an advanced circuit breaker with adaptive thresholds, multiple failure modes, and recovery strategies. The breaker should automatically adjust based on system load and error patterns. Language: TypeScript. Function name: asyncCircuitBreakerAdvanced","reference_answer":"enum CircuitState {\n    CLOSED = 'closed',\n    OPEN = 'open',\n    HALF_OPEN = 'half_open'\n}\n\nenum FailureMode {\n    TIMEOUT = 'timeout',\n    EXCEPTION = 'exception',\n    HTTP_ERROR = 'http_error',\n    RATE_LIMIT = 'rate_limit'\n}\n\ninterface CircuitMetrics {\n    totalCalls: number;\n    successfulCalls: number;\n    failedCalls: number;\n    totalLatency: number;\n    recentLatencies: number[];\n    failureCounts: Map<FailureMode, number>;\n}\n\nclass AsyncCircuitBreakerAdvanced {\n    private name: string;\n    private state: CircuitState = CircuitState.CLOSED;\n    private metrics: CircuitMetrics;\n    private failureThreshold: number;\n    private minThreshold: number;\n    private maxThreshold: number;\n    private lastFailureTime = 0;\n    private openDuration = 60000; // 1 minute\n    private halfOpenMaxCalls = 3;\n    private halfOpenSuccessCount = 0;\n    private adaptationWindow = 300000; // 5 minutes\n    private lastAdaptation = Date.now();\n    \n    constructor(name: string, initialThreshold = 0.5, minThreshold = 0.1, maxThreshold = 0.8) {\n        this.name = name;\n        this.failureThreshold = initialThreshold;\n        this.minThreshold = minThreshold;\n        this.maxThreshold = maxThreshold;\n        \n        this.metrics = {\n            totalCalls: 0,\n            successfulCalls: 0,\n            failedCalls: 0,\n            totalLatency: 0,\n            recentLatencies: [],\n            failureCounts: new Map()\n        };\n        \n        // Initialize failure counts\n        for (const mode of Object.values(FailureMode)) {\n            this.metrics.failureCounts.set(mode, 0);\n        }\n    }\n    \n    async call<T>(func: () => Promise<T>): Promise<T> {\n        if (this.state === CircuitState.OPEN) {\n            if (this.shouldAttemptReset()) {\n                this.state = CircuitState.HALF_OPEN;\n                this.halfOpenSuccessCount = 0;\n            } else {\n                throw new Error(`Circuit ${this.name} is OPEN`);\n            }\n        }\n        \n        try {\n            const startTime = Date.now();\n            const result = await func();\n            const latency = Date.now() - startTime;\n            \n            this.recordSuccess(latency);\n            return result;\n        } catch (error) {\n            const failureMode = this.classifyFailure(error);\n            this.recordFailure(failureMode);\n            throw error;\n        }\n    }\n    \n    private recordSuccess(latency: number): void {\n        this.metrics.totalCalls++;\n        this.metrics.successfulCalls++;\n        this.metrics.totalLatency += latency;\n        this.metrics.recentLatencies.push(latency);\n        \n        // Keep only recent latencies\n        if (this.metrics.recentLatencies.length > 100) {\n            this.metrics.recentLatencies.shift();\n        }\n        \n        if (this.state === CircuitState.HALF_OPEN) {\n            this.halfOpenSuccessCount++;\n            if (this.halfOpenSuccessCount >= this.halfOpenMaxCalls) {\n                this.state = CircuitState.CLOSED;\n                this.adaptThresholds();\n            }\n        }\n        \n        // Periodic adaptation\n        if (Date.now() - this.lastAdaptation > this.adaptationWindow) {\n            this.adaptThresholds();\n        }\n    }\n    \n    private recordFailure(failureMode: FailureMode): void {\n        this.metrics.totalCalls++;\n        this.metrics.failedCalls++;\n        this.metrics.failureCounts.set(\n            failureMode, \n            this.metrics.failureCounts.get(failureMode)! + 1\n        );\n        this.lastFailureTime = Date.now();\n        \n        const failureRate = this.metrics.failedCalls / this.metrics.totalCalls;\n        if (failureRate > this.failureThreshold) {\n            this.state = CircuitState.OPEN;\n        }\n    }\n    \n    private classifyFailure(error: any): FailureMode {\n        if (error.name === 'TimeoutError' || error.message?.includes('timeout')) {\n            return FailureMode.TIMEOUT;\n        }\n        if (error.status && error.status >= 400 && error.status < 500) {\n            return FailureMode.HTTP_ERROR;\n        }\n        if (error.message?.toLowerCase().includes('rate limit')) {\n            return FailureMode.RATE_LIMIT;\n        }\n        return FailureMode.EXCEPTION;\n    }\n    \n    private shouldAttemptReset(): boolean {\n        return Date.now() - this.lastFailureTime > this.openDuration;\n    }\n    \n    private adaptThresholds(): void {\n        if (this.metrics.recentLatencies.length < 10) return;\n        \n        const failureRate = this.metrics.failedCalls / Math.max(1, this.metrics.totalCalls);\n        const avgLatency = this.metrics.totalLatency / Math.max(1, this.metrics.successfulCalls);\n        \n        if (failureRate < 0.1 && avgLatency < 1000) {\n            // System healthy - can be more tolerant\n            this.failureThreshold = Math.min(this.maxThreshold, this.failureThreshold + 0.05);\n        } else if (failureRate > 0.3 || avgLatency > 5000) {\n            // System struggling - be more strict\n            this.failureThreshold = Math.max(this.minThreshold, this.failureThreshold - 0.05);\n        }\n        \n        this.lastAdaptation = Date.now();\n    }\n    \n    getMetrics() {\n        const failureRate = this.metrics.failedCalls / Math.max(1, this.metrics.totalCalls);\n        const avgLatency = this.metrics.successfulCalls > 0 ? \n            this.metrics.totalLatency / this.metrics.successfulCalls : 0;\n        \n        return {\n            state: this.state,\n            failureRate,\n            avgLatency,\n            totalCalls: this.metrics.totalCalls,\n            failureCounts: Object.fromEntries(this.metrics.failureCounts)\n        };\n    }\n}\n\nfunction asyncCircuitBreakerAdvanced(name: string, initialThreshold = 0.5): AsyncCircuitBreakerAdvanced {\n    return new AsyncCircuitBreakerAdvanced(name, initialThreshold);\n}","assertions":"const breaker = new AsyncCircuitBreakerAdvanced('test_circuit', 0.6);\n\nlet callCount = 0;\nconst failingFunc = async (): Promise<string> => {\n    callCount++;\n    if (callCount <= 3) {\n        throw new Error('Simulated failure');\n    }\n    return 'success';\n};\n\n// Test initial state\nconst initialMetrics = breaker.getMetrics();\nif (initialMetrics.state !== CircuitState.CLOSED) throw new Error('Should start closed');\n\n// Cause failures\nfor (let i = 0; i < 3; i++) {\n    try {\n        await breaker.call(failingFunc);\n    } catch (e) {\n        // Expected\n    }\n}\n\n// Check metrics after failures\nconst metricsAfterFailures = breaker.getMetrics();\nif (metricsAfterFailures.totalCalls !== 3) throw new Error('Should have 3 total calls');\nif (metricsAfterFailures.failureRate !== 1.0) throw new Error('Should have 100% failure rate');\n\n// Breaker should be open\nif (metricsAfterFailures.state !== CircuitState.OPEN) throw new Error('Should be open');\n\n// Test successful call after timeout\nbreaker['openDuration'] = 100; // Short timeout for testing\nawait new Promise(resolve => setTimeout(resolve, 150));\n\ntry {\n    const result = await breaker.call(failingFunc);\n    if (result !== 'success') throw new Error('Should succeed');\n} catch (e) {\n    throw new Error('Should not fail');\n}\n\n// Breaker should be half-open or closed\nconst finalMetrics = breaker.getMetrics();\nif (finalMetrics.state === CircuitState.OPEN) throw new Error('Should not be open after success');","metadata":{"language":"TypeScript","function_name":"asyncCircuitBreakerAdvanced","difficulty":"very_advanced","category":"concurrency","complexity":0.95}}
{"query_id":"synthetic-075","query_text":"Write a TypeScript function named `parallelMapReduce` that implements a parallel map-reduce framework using async operations. The function should handle large datasets by chunking and parallel processing. Language: TypeScript. Function name: parallelMapReduce","reference_answer":"class Semaphore {\n    private permits: number;\n    private waiters: Array<() => void> = [];\n    \n    constructor(permits: number) {\n        this.permits = permits;\n    }\n    \n    async acquire(): Promise<void> {\n        if (this.permits > 0) {\n            this.permits--;\n            return;\n        }\n        \n        return new Promise(resolve => {\n            this.waiters.push(resolve);\n        });\n    }\n    \n    release(): void {\n        this.permits++;\n        if (this.waiters.length > 0) {\n            const waiter = this.waiters.shift()!;\n            this.permits--;\n            waiter();\n        }\n    }\n}\n\nasync function parallelMapReduce<T, U, V>(\n    data: T[],\n    mapper: (item: T) => Promise<U> | U,\n    reducer: (a: U, b: U) => U,\n    initialValue: U,\n    chunkSize = 1000,\n    maxConcurrency = 4\n): Promise<U> {\n    if (data.length === 0) {\n        return initialValue;\n    }\n    \n    // Split data into chunks\n    const chunks: T[][] = [];\n    for (let i = 0; i < data.length; i += chunkSize) {\n        chunks.push(data.slice(i, i + chunkSize));\n    }\n    \n    // Process chunks with controlled concurrency\n    const semaphore = new Semaphore(maxConcurrency);\n    const chunkPromises: Promise<U>[] = chunks.map(async (chunk) => {\n        await semaphore.acquire();\n        try {\n            // Map phase for chunk\n            const mappedPromises = chunk.map(async (item) => await mapper(item));\n            const mappedChunk = await Promise.all(mappedPromises);\n            \n            // Reduce within chunk\n            return mappedChunk.reduce(reducer, initialValue);\n        } finally {\n            semaphore.release();\n        }\n    });\n    \n    // Wait for all chunks to complete\n    const chunkResults = await Promise.all(chunkPromises);\n    \n    // Final reduce phase\n    return chunkResults.reduce(reducer, initialValue);\n}","assertions":"// Test word count example\nconst documents = [\n    'hello world hello',\n    'world test world',\n    'hello test hello test'\n];\n\nconst wordMapper = async (text: string): Promise<{ [word: string]: number }> => {\n    const words = text.split(/\\s+/);\n    const result: { [word: string]: number } = {};\n    for (const word of words) {\n        result[word] = 1;\n    }\n    return result;\n};\n\nconst dictReducer = (a: { [word: string]: number }, b: { [word: string]: number }): { [word: string]: number } => {\n    const result = { ...a };\n    for (const [word, count] of Object.entries(b)) {\n        result[word] = (result[word] || 0) + count;\n    }\n    return result;\n};\n\nconst result = await parallelMapReduce(\n    documents,\n    wordMapper,\n    dictReducer,\n    {}\n);\n\nif (result['hello'] !== 4) throw new Error('Wrong hello count');\nif (result['world'] !== 3) throw new Error('Wrong world count');\nif (result['test'] !== 3) throw new Error('Wrong test count');\n\n// Test sum of squares\nconst squareMapper = async (x: number): Promise<number> => x * x;\nconst sumReducer = (a: number, b: number): number => a + b;\nconst numbers = Array.from({ length: 100 }, (_, i) => i + 1);\nconst sumSquares = await parallelMapReduce(numbers, squareMapper, sumReducer, 0);\nconst expected = numbers.reduce((sum, n) => sum + n * n, 0);\n\nif (sumSquares !== expected) throw new Error(`Wrong sum: got ${sumSquares}, expected ${expected}`);","metadata":{"language":"TypeScript","function_name":"parallelMapReduce","difficulty":"very_advanced","category":"concurrency","complexity":0.85}}
{"query_id":"synthetic-076","query_text":"Write a TypeScript function named `distributedRateLimiter` that implements a distributed rate limiter using Redis with sliding window and fixed window algorithms, automatic cleanup, and cluster awareness. Language: TypeScript. Function name: distributedRateLimiter","reference_answer":"enum RateLimitAlgorithm {\n    FIXED_WINDOW = 'fixed_window',\n    SLIDING_WINDOW = 'sliding_window'\n}\n\nclass DistributedRateLimiter {\n    private redis: any; // Mock Redis for this example\n    private algorithm: RateLimitAlgorithm;\n    \n    constructor(\n        redisHost = 'localhost', \n        redisPort = 6379, \n        algorithm: RateLimitAlgorithm = RateLimitAlgorithm.SLIDING_WINDOW\n    ) {\n        this.redis = {}; // Mock Redis\n        this.algorithm = algorithm;\n    }\n    \n    async isAllowed(key: string, limit: number, windowSeconds: number): Promise<boolean> {\n        if (this.algorithm === RateLimitAlgorithm.FIXED_WINDOW) {\n            return this.checkFixedWindow(key, limit, windowSeconds);\n        } else {\n            return this.checkSlidingWindow(key, limit, windowSeconds);\n        }\n    }\n    \n    private checkFixedWindow(key: string, limit: number, windowSeconds: number): boolean {\n        const currentWindow = Math.floor(Date.now() / (windowSeconds * 1000));\n        const windowKey = `${key}:${currentWindow}`;\n        \n        if (!this.redis[windowKey]) {\n            this.redis[windowKey] = { count: 0, expires: (currentWindow + 1) * windowSeconds * 1000 };\n        }\n        \n        if (this.redis[windowKey].count < limit) {\n            this.redis[windowKey].count++;\n            return true;\n        }\n        \n        return false;\n    }\n    \n    private checkSlidingWindow(key: string, limit: number, windowSeconds: number): boolean {\n        const now = Date.now();\n        const windowStart = now - (windowSeconds * 1000);\n        \n        if (!this.redis[key]) {\n            this.redis[key] = [];\n        }\n        \n        // Add current request\n        this.redis[key].push(now);\n        \n        // Remove old requests outside window\n        this.redis[key] = this.redis[key].filter((timestamp: number) => timestamp > windowStart);\n        \n        return this.redis[key].length <= limit;\n    }\n    \n    async getRemainingRequests(key: string, limit: number, windowSeconds: number): Promise<number> {\n        let currentCount: number;\n        \n        if (this.algorithm === RateLimitAlgorithm.FIXED_WINDOW) {\n            const currentWindow = Math.floor(Date.now() / (windowSeconds * 1000));\n            const windowKey = `${key}:${currentWindow}`;\n            currentCount = this.redis[windowKey]?.count || 0;\n        } else {\n            const now = Date.now();\n            const windowStart = now - (windowSeconds * 1000);\n            if (this.redis[key]) {\n                this.redis[key] = this.redis[key].filter((timestamp: number) => timestamp > windowStart);\n                currentCount = this.redis[key].length;\n            } else {\n                currentCount = 0;\n            }\n        }\n        \n        return Math.max(0, limit - currentCount);\n    }\n    \n    async getResetTime(key: string, windowSeconds: number): Promise<number> {\n        if (this.algorithm === RateLimitAlgorithm.FIXED_WINDOW) {\n            const currentWindow = Math.floor(Date.now() / (windowSeconds * 1000));\n            return (currentWindow + 1) * windowSeconds;\n        } else {\n            return Math.floor(Date.now() / 1000) + windowSeconds;\n        }\n    }\n    \n    async cleanupExpiredKeys(): Promise<number> {\n        let cleaned = 0;\n        const now = Date.now();\n        \n        for (const key of Object.keys(this.redis)) {\n            if (key.includes(':') && this.redis[key].expires && now > this.redis[key].expires) {\n                delete this.redis[key];\n                cleaned++;\n            }\n        }\n        \n        return cleaned;\n    }\n}\n\nfunction distributedRateLimiter(\n    redisHost = 'localhost',\n    redisPort = 6379,\n    algorithm = 'sliding_window'\n): DistributedRateLimiter {\n    const algo = algorithm === 'sliding_window' ? \n        RateLimitAlgorithm.SLIDING_WINDOW : \n        RateLimitAlgorithm.FIXED_WINDOW;\n    return new DistributedRateLimiter(redisHost, redisPort, algo);\n}","assertions":"const limiter = distributedRateLimiter();\nconst testKey = 'test_api';\n\n// Test basic rate limiting\nlet allowed = await limiter.isAllowed(testKey, 5, 60);\nif (!allowed) throw new Error('First request should be allowed');\n\n// Test remaining requests\nlet remaining = await limiter.getRemainingRequests(testKey, 5, 60);\nif (remaining > 4) throw new Error('Should have 4 remaining requests');\n\n// Test reset time\nlet resetTime = await limiter.getResetTime(testKey, 60);\nconst now = Math.floor(Date.now() / 1000);\nif (resetTime <= now) throw new Error('Reset time should be in future');\n\n// Test multiple requests\nfor (let i = 1; i < 5; i++) {\n    allowed = await limiter.isAllowed(testKey, 5, 60);\n    if (!allowed) throw new Error(`Request ${i} should be allowed`);\n}\n\n// 6th request should be denied\nallowed = await limiter.isAllowed(testKey, 5, 60);\nif (allowed) throw new Error('6th request should be denied');\n\n// Check remaining requests\nremaining = await limiter.getRemainingRequests(testKey, 5, 60);\nif (remaining !== 0) throw new Error('Should have 0 remaining requests');\n\n// Test cleanup\nconst cleaned = await limiter.cleanupExpiredKeys();\nif (typeof cleaned !== 'number') throw new Error('Cleanup should return number');","metadata":{"language":"TypeScript","function_name":"distributedRateLimiter","difficulty":"very_advanced","category":"concurrency","complexity":0.9}}
{"query_id":"synthetic-077","query_text":"Write a TypeScript function named `concurrentSkipList` that implements a concurrent skip list with lock-free operations for search, insert, and delete. The implementation should use atomic operations and provide linearizability guarantees. Language: TypeScript. Function name: concurrentSkipList","reference_answer":"class ConcurrentSkipListNode<T> {\n    key: T | null;\n    value: any;\n    forward: (ConcurrentSkipListNode<T> | null)[];\n    marked: boolean;\n    fullyLinked: boolean;\n    \n    constructor(key: T | null, value: any, level: number) {\n        this.key = key;\n        this.value = value;\n        this.forward = new Array(level + 1).fill(null);\n        this.marked = false;\n        this.fullyLinked = false;\n    }\n}\n\nclass ConcurrentSkipList<T> {\n    private head: ConcurrentSkipListNode<T>;\n    private level: number;\n    private maxLevel: number;\n    private p: number;\n    \n    constructor(maxLevel = 16, p = 0.5) {\n        this.maxLevel = maxLevel;\n        this.p = p;\n        this.level = 0;\n        this.head = new ConcurrentSkipListNode<T>(null, null, maxLevel);\n    }\n    \n    private randomLevel(): number {\n        let level = 0;\n        while (Math.random() < this.p && level < this.maxLevel) {\n            level++;\n        }\n        return level;\n    }\n    \n    find(key: T): any {\n        let current = this.head;\n        \n        for (let i = this.level; i >= 0; i--) {\n            while (current.forward[i] && \n                   current.forward[i]!.key !== null && \n                   (current.forward[i]!.key as any) < key) {\n                current = current.forward[i]!;\n            }\n        }\n        \n        current = current.forward[0]!;\n        if (current && current.key === key && !current.marked) {\n            return current.value;\n        }\n        return null;\n    }\n    \n    insert(key: T, value: any): boolean {\n        const preds: (ConcurrentSkipListNode<T> | null)[] = new Array(this.maxLevel + 1).fill(null);\n        const succs: (ConcurrentSkipListNode<T> | null)[] = new Array(this.maxLevel + 1).fill(null);\n        \n        let current = this.head;\n        \n        for (let i = this.level; i >= 0; i--) {\n            while (current.forward[i] && \n                   current.forward[i]!.key !== null && \n                   (current.forward[i]!.key as any) < key) {\n                current = current.forward[i]!;\n            }\n            preds[i] = current;\n            succs[i] = current.forward[i];\n        }\n        \n        current = succs[0]!;\n        \n        if (current && current.key === key) {\n            current.value = value;\n            return true;\n        }\n        \n        const newLevel = this.randomLevel();\n        \n        if (newLevel > this.level) {\n            for (let i = this.level + 1; i <= newLevel; i++) {\n                preds[i] = this.head;\n            }\n            this.level = newLevel;\n        }\n        \n        const newNode = new ConcurrentSkipListNode(key, value, newLevel);\n        \n        for (let i = 0; i <= newLevel; i++) {\n            newNode.forward[i] = succs[i];\n            preds[i]!.forward[i] = newNode;\n        }\n        \n        newNode.fullyLinked = true;\n        return true;\n    }\n    \n    delete(key: T): boolean {\n        const preds: (ConcurrentSkipListNode<T> | null)[] = new Array(this.maxLevel + 1).fill(null);\n        const succs: (ConcurrentSkipListNode<T> | null)[] = new Array(this.maxLevel + 1).fill(null);\n        \n        let current = this.head;\n        \n        for (let i = this.level; i >= 0; i--) {\n            while (current.forward[i] && \n                   current.forward[i]!.key !== null && \n                   (current.forward[i]!.key as any) < key) {\n                current = current.forward[i]!;\n            }\n            preds[i] = current;\n            succs[i] = current.forward[i];\n        }\n        \n        current = succs[0]!;\n        \n        if (!current || current.key !== key) {\n            return false;\n        }\n        \n        current.marked = true;\n        \n        for (let i = 0; i <= this.level; i++) {\n            if (preds[i]!.forward[i] !== current) {\n                break;\n            }\n            preds[i]!.forward[i] = current.forward[i];\n        }\n        \n        while (this.level > 0 && this.head.forward[this.level] === null) {\n            this.level--;\n        }\n        \n        return true;\n    }\n    \n    contains(key: T): boolean {\n        return this.find(key) !== null;\n    }\n}\n\nfunction concurrentSkipList<T>(maxLevel = 16): ConcurrentSkipList<T> {\n    return new ConcurrentSkipList<T>(maxLevel);\n}","assertions":"const skipList = concurrentSkipList<number>();\n\n// Test insert and search\nskipList.insert(1, 'one');\nskipList.insert(3, 'three');\nskipList.insert(2, 'two');\n\nif (skipList.find(1) !== 'one') throw new Error('Failed: find existing key 1');\nif (skipList.find(2) !== 'two') throw new Error('Failed: find existing key 2');\nif (skipList.find(3) !== 'three') throw new Error('Failed: find existing key 3');\nif (skipList.find(4) !== null) throw new Error('Failed: find non-existing key');\n\n// Test delete\nif (!skipList.delete(2)) throw new Error('Failed: delete existing key');\nif (skipList.find(2) !== null) throw new Error('Failed: find deleted key');\nif (skipList.delete(2)) throw new Error('Failed: delete already deleted key');\n\n// Test contains\nif (!skipList.contains(1)) throw new Error('Failed: contains existing key');\nif (skipList.contains(4)) throw new Error('Failed: contains non-existing key');","metadata":{"language":"TypeScript","function_name":"concurrentSkipList","difficulty":"very_advanced","category":"concurrency","complexity":0.95}}
{"query_id":"synthetic-078","query_text":"Write a TypeScript function named `implementSegmentTree` that implements a segment tree for range minimum queries and range updates. The tree should support efficient range queries and point updates. Language: TypeScript. Function name: implementSegmentTree","reference_answer":"class SegmentTree {\n    private tree: number[];\n    private lazy: number[];\n    private n: number;\n    \n    constructor(arr: number[]) {\n        this.n = arr.length;\n        this.tree = new Array(4 * this.n).fill(0);\n        this.lazy = new Array(4 * this.n).fill(0);\n        this.build(arr, 0, 0, this.n - 1);\n    }\n    \n    private build(arr: number[], node: number, start: number, end: number): void {\n        if (start === end) {\n            this.tree[node] = arr[start];\n            return;\n        }\n        \n        const mid = Math.floor((start + end) / 2);\n        this.build(arr, 2 * node + 1, start, mid);\n        this.build(arr, 2 * node + 2, mid + 1, end);\n        this.tree[node] = Math.min(this.tree[2 * node + 1], this.tree[2 * node + 2]);\n    }\n    \n    private propagateLazy(node: number, start: number, end: number): void {\n        if (this.lazy[node] !== 0) {\n            this.tree[node] += this.lazy[node];\n            if (start !== end) {\n                this.lazy[2 * node + 1] += this.lazy[node];\n                this.lazy[2 * node + 2] += this.lazy[node];\n            }\n            this.lazy[node] = 0;\n        }\n    }\n    \n    updateRange(left: number, right: number, val: number): void {\n        this.updateRangeHelper(0, 0, this.n - 1, left, right, val);\n    }\n    \n    private updateRangeHelper(node: number, start: number, end: number, \n                              left: number, right: number, val: number): void {\n        this.propagateLazy(node, start, end);\n        \n        if (start > end || start > right || end < left) {\n            return;\n        }\n        \n        if (left <= start && end <= right) {\n            this.lazy[node] += val;\n            this.propagateLazy(node, start, end);\n            return;\n        }\n        \n        const mid = Math.floor((start + end) / 2);\n        this.updateRangeHelper(2 * node + 1, start, mid, left, right, val);\n        this.updateRangeHelper(2 * node + 2, mid + 1, end, left, right, val);\n        this.tree[node] = Math.min(this.tree[2 * node + 1], this.tree[2 * node + 2]);\n    }\n    \n    queryRange(left: number, right: number): number {\n        return this.queryRangeHelper(0, 0, this.n - 1, left, right);\n    }\n    \n    private queryRangeHelper(node: number, start: number, end: number, \n                             left: number, right: number): number {\n        this.propagateLazy(node, start, end);\n        \n        if (start > end || start > right || end < left) {\n            return Number.MAX_SAFE_INTEGER;\n        }\n        \n        if (left <= start && end <= right) {\n            return this.tree[node];\n        }\n        \n        const mid = Math.floor((start + end) / 2);\n        const leftMin = this.queryRangeHelper(2 * node + 1, start, mid, left, right);\n        const rightMin = this.queryRangeHelper(2 * node + 2, mid + 1, end, left, right);\n        return Math.min(leftMin, rightMin);\n    }\n    \n    updatePoint(index: number, val: number): void {\n        const diff = val - this.queryRange(index, index);\n        this.updateRange(index, index, diff);\n    }\n}\n\nfunction implementSegmentTree(arr: number[]): SegmentTree {\n    return new SegmentTree(arr);\n}","assertions":"const arr = [1, 3, 2, 7, 9, 11];\nconst segTree = implementSegmentTree(arr);\n\n// Test range minimum queries\nif (segTree.queryRange(0, 2) !== 1) throw new Error('Failed: min(1,3,2) should be 1');\nif (segTree.queryRange(3, 5) !== 7) throw new Error('Failed: min(7,9,11) should be 7');\nif (segTree.queryRange(1, 4) !== 2) throw new Error('Failed: min(3,2,7,9) should be 2');\n\n// Test point updates\nsegTree.updatePoint(2, 0); // Change index 2 from 2 to 0\nif (segTree.queryRange(0, 2) !== 0) throw new Error('Failed: min(1,3,0) should be 0');\n\n// Test range updates\nsegTree.updateRange(1, 3, 10); // Add 10 to range [1,3]\nif (segTree.queryRange(1, 3) !== 10) throw new Error('Failed: min(13,10,17) should be 10');\nif (segTree.queryRange(0, 0) !== 1) throw new Error('Failed: index 0 should be unchanged');\nif (segTree.queryRange(4, 5) !== 9) throw new Error('Failed: min(9,11) should be unchanged');","metadata":{"language":"TypeScript","function_name":"implementSegmentTree","difficulty":"very_advanced","category":"data_structures","complexity":0.9}}
{"query_id":"synthetic-079","query_text":"Write a TypeScript function named `concurrentPriorityQueue` that implements a thread-safe priority queue with concurrent access, priority updates, and efficient blocking operations. Language: TypeScript. Function name: concurrentPriorityQueue","reference_answer":"interface QueueItem<T> {\n    priority: number;\n    seqNum: number;\n    item: T;\n    valid: boolean;\n}\n\nclass ConcurrentPriorityQueue<T> {\n    private heap: QueueItem<T>[] = [];\n    private itemToEntry: Map<T, { priority: number; seqNum: number }> = new Map();\n    private seqNum = 0;\n    private waitingPut: Array<() => void> = [];\n    private maxSize?: number;\n    \n    constructor(maxSize?: number) {\n        this.maxSize = maxSize;\n    }\n    \n    async put(item: T, priority = 0): Promise<void> {\n        // Check if item already exists\n        if (this.itemToEntry.has(item)) {\n            // Invalidate old entry (lazy deletion)\n            this.itemToEntry.set(item, { priority: -1, seqNum: -1 });\n        }\n        \n        // Check size limit\n        if (this.maxSize && this.heap.length >= this.maxSize) {\n            await new Promise<void>((resolve) => {\n                this.waitingPut.push(resolve);\n            });\n        }\n        \n        this.seqNum++;\n        const entry: QueueItem<T> = {\n            priority,\n            seqNum: this.seqNum,\n            item,\n            valid: true\n        };\n        \n        this.heap.push(entry);\n        this.itemToEntry.set(item, { priority, seqNum: this.seqNum });\n        \n        // Bubble up\n        this.bubbleUp(this.heap.length - 1);\n    }\n    \n    async get(): Promise<T | null> {\n        while (this.heap.length > 0) {\n            const entry = this.heap[0];\n            \n            // Check if entry is still valid\n            const currentEntry = this.itemToEntry.get(entry.item);\n            if (currentEntry && currentEntry.seqNum === entry.seqNum) {\n                // Remove from heap\n                this.heap[0] = this.heap[this.heap.length - 1];\n                this.heap.pop();\n                this.bubbleDown(0);\n                \n                this.itemToEntry.delete(entry.item);\n                \n                // Notify waiting put operations\n                if (this.waitingPut.length > 0) {\n                    const resolve = this.waitingPut.shift()!;\n                    resolve();\n                }\n                \n                return entry.item;\n            } else {\n                // Remove invalid entry\n                this.heap[0] = this.heap[this.heap.length - 1];\n                this.heap.pop();\n                this.bubbleDown(0);\n            }\n        }\n        return null;\n    }\n    \n    async updatePriority(item: T, newPriority: number): Promise<boolean> {\n        if (!this.itemToEntry.has(item)) {\n            return false;\n        }\n        \n        // Invalidate old entry\n        this.itemToEntry.set(item, { priority: -1, seqNum: -1 });\n        \n        // Add new entry with updated priority\n        await this.put(item, newPriority);\n        return true;\n    }\n    \n    peek(): T | null {\n        while (this.heap.length > 0) {\n            const entry = this.heap[0];\n            const currentEntry = this.itemToEntry.get(entry.item);\n            if (currentEntry && currentEntry.seqNum === entry.seqNum) {\n                return entry.item;\n            }\n            // Remove invalid entry\n            this.heap[0] = this.heap[this.heap.length - 1];\n            this.heap.pop();\n            this.bubbleDown(0);\n        }\n        return null;\n    }\n    \n    size(): number {\n        return this.validItemsCount();\n    }\n    \n    private validItemsCount(): number {\n        let count = 0;\n        for (const entry of this.heap) {\n            const currentEntry = this.itemToEntry.get(entry.item);\n            if (currentEntry && currentEntry.seqNum === entry.seqNum) {\n                count++;\n            }\n        }\n        return count;\n    }\n    \n    private bubbleUp(index: number): void {\n        while (index > 0) {\n            const parentIndex = Math.floor((index - 1) / 2);\n            if (this.compare(index, parentIndex) >= 0) {\n                break;\n            }\n            this.swap(index, parentIndex);\n            index = parentIndex;\n        }\n    }\n    \n    private bubbleDown(index: number): void {\n        const size = this.heap.length;\n        while (true) {\n            let smallest = index;\n            const left = 2 * index + 1;\n            const right = 2 * index + 2;\n            \n            if (left < size && this.compare(left, smallest) < 0) {\n                smallest = left;\n            }\n            if (right < size && this.compare(right, smallest) < 0) {\n                smallest = right;\n            }\n            \n            if (smallest === index) {\n                break;\n            }\n            \n            this.swap(index, smallest);\n            index = smallest;\n        }\n    }\n    \n    private compare(i: number, j: number): number {\n        const itemI = this.heap[i];\n        const itemJ = this.heap[j];\n        \n        if (itemI.priority !== itemJ.priority) {\n            return itemI.priority - itemJ.priority;\n        }\n        return itemI.seqNum - itemJ.seqNum;\n    }\n    \n    private swap(i: number, j: number): void {\n        [this.heap[i], this.heap[j]] = [this.heap[j], this.heap[i]];\n    }\n}\n\nfunction concurrentPriorityQueue<T>(maxSize?: number): ConcurrentPriorityQueue<T> {\n    return new ConcurrentPriorityQueue<T>(maxSize);\n}","assertions":"const queue = concurrentPriorityQueue<string>();\n\n// Test put and get\nawait queue.put('low', 2);\nawait queue.put('high', 1);\nawait queue.put('medium', 1);\n\nlet item1 = await queue.get();\nlet item2 = await queue.get();\n\n// Higher priority items should come first\nif (item1 !== 'high' && item1 !== 'medium') {\n    throw new Error(`Unexpected first item: ${item1}`);\n}\nif (item2 !== 'high' && item2 !== 'medium') {\n    throw new Error(`Unexpected second item: ${item2}`);\n}\nif (item1 === item2) {\n    throw new Error('Should get different items');\n}\n\n// Test priority update\nawait queue.put('updatable', 3);\nawait queue.updatePriority('updatable', 0);\nconst nextItem = await queue.get();\nif (nextItem !== 'updatable') {\n    throw new Error(`Priority update failed, got: ${nextItem}`);\n}\n\n// Test peek\nawait queue.put('peek_test', 1);\nconst peeked = queue.peek();\nif (peeked !== 'peek_test') {\n    throw new Error(`Peek failed, got: ${peeked}`);\n}\n\n// Peek shouldn't remove item\nconst peekedAgain = queue.peek();\nif (peekedAgain !== 'peek_test') {\n    throw new Error('Peek should not remove item');\n}","metadata":{"language":"TypeScript","function_name":"concurrentPriorityQueue","difficulty":"very_advanced","category":"concurrency","complexity":0.9}}
{"query_id":"synthetic-080","query_text":"Write a TypeScript function named `distributedLockManager` that implements a distributed lock manager using Redis with proper lease management, deadlock detection, and automatic cleanup of expired locks. Language: TypeScript. Function name: distributedLockManager","reference_answer":"interface LockOptions {\n    ttlSeconds?: number;\n    retryAttempts?: number;\n    retryDelay?: number;\n}\n\nclass DistributedLock {\n    private redis: any; // Mock Redis for this example\n    private lockKey: string;\n    private ownerId: string;\n    private ttlSeconds: number;\n    private retryAttempts: number;\n    private retryDelay: number;\n    \n    constructor(lockKey: string, options: LockOptions = {}) {\n        this.redis = {}; // Mock Redis\n        this.lockKey = lockKey;\n        this.ownerId = `owner_${Date.now()}_${Math.random()}`;\n        this.ttlSeconds = options.ttlSeconds || 30;\n        this.retryAttempts = options.retryAttempts || 3;\n        this.retryDelay = options.retryDelay || 100;\n    }\n    \n    async acquire(): Promise<boolean> {\n        for (let attempt = 0; attempt < this.retryAttempts; attempt++) {\n            try {\n                // Try to acquire lock\n                const acquired = await this.tryAcquireLock();\n                if (acquired) {\n                    return true;\n                }\n                \n                // Check if existing lock is expired and try to steal it\n                const stolen = await this.tryStealExpiredLock();\n                if (stolen) {\n                    return true;\n                }\n                \n                // Wait before retry\n                if (attempt < this.retryAttempts - 1) {\n                    await new Promise(resolve => setTimeout(resolve, this.retryDelay));\n                }\n            } catch (error) {\n                console.error('Lock acquisition error:', error);\n            }\n        }\n        return false;\n    }\n    \n    private async tryAcquireLock(): Promise<boolean> {\n        // Mock implementation - would use Redis SET NX PX\n        if (!this.redis[this.lockKey]) {\n            this.redis[this.lockKey] = {\n                owner: this.ownerId,\n                expires: Date.now() + (this.ttlSeconds * 1000)\n            };\n            return true;\n        }\n        return false;\n    }\n    \n    private async tryStealExpiredLock(): Promise<boolean> {\n        const lockData = this.redis[this.lockKey];\n        if (lockData && Date.now() > lockData.expires) {\n            // Lock is expired, try to steal it\n            lockData.owner = this.ownerId;\n            lockData.expires = Date.now() + (this.ttlSeconds * 1000);\n            return true;\n        }\n        return false;\n    }\n    \n    async release(): Promise<boolean> {\n        const lockData = this.redis[this.lockKey];\n        if (lockData && lockData.owner === this.ownerId) {\n            delete this.redis[this.lockKey];\n            return true;\n        }\n        return false;\n    }\n    \n    async extend(ttlSeconds?: number): Promise<boolean> {\n        const lockData = this.redis[this.lockKey];\n        if (lockData && lockData.owner === this.ownerId) {\n            lockData.expires = Date.now() + ((ttlSeconds || this.ttlSeconds) * 1000);\n            return true;\n        }\n        return false;\n    }\n}\n\nclass DistributedLockManager {\n    private redis: any;\n    private locks: Map<string, DistributedLock> = new Map();\n    \n    constructor(redisHost = 'localhost', redisPort = 6379) {\n        this.redis = {}; // Mock Redis\n    }\n    \n    getLock(lockKey: string, options?: LockOptions): DistributedLock {\n        if (!this.locks.has(lockKey)) {\n            this.locks.set(lockKey, new DistributedLock(lockKey, options));\n        }\n        return this.locks.get(lockKey)!;\n    }\n    \n    async cleanupExpiredLocks(): Promise<number> {\n        let cleaned = 0;\n        const now = Date.now();\n        \n        for (const [key, lockData] of Object.entries(this.redis)) {\n            const data = lockData as any;\n            if (data.expires && now > data.expires) {\n                delete this.redis[key];\n                cleaned++;\n            }\n        }\n        \n        return cleaned;\n    }\n}\n\nfunction distributedLockManager(redisHost = 'localhost', redisPort = 6379): DistributedLockManager {\n    return new DistributedLockManager(redisHost, redisPort);\n}","assertions":"const manager = distributedLockManager();\nconst lock = manager.getLock('test_lock', { ttlSeconds: 5 });\n\n// Test acquiring lock\nlet acquired = await lock.acquire();\nif (!acquired) throw new Error('Failed to acquire lock');\n\n// Test extending lock\nlet extended = await lock.extend(10);\nif (!extended) throw new Error('Failed to extend lock');\n\n// Test releasing lock\nlet released = await lock.release();\nif (!released) throw new Error('Failed to release lock');\n\n// Test acquiring again (should succeed now)\nacquired = await lock.acquire();\nif (!acquired) throw new Error('Failed to acquire lock after release');\n\n// Test cleanup\nawait lock.release(); // Release so cleanup can work\nconst cleaned = await manager.cleanupExpiredLocks();\nif (cleaned < 0) throw new Error('Cleanup should return non-negative count');\n\n// Verify operations completed without throwing\nconsole.log('All lock operations completed successfully');","metadata":{"language":"TypeScript","function_name":"distributedLockManager","difficulty":"very_advanced","category":"concurrency","complexity":0.9}}
{"query_id":"synthetic-081","query_text":"Write a Go function named `binarySearch` that implements binary search on a sorted slice of integers. The function should return the index of the target element if found, or -1 if not found. Handle edge cases like empty slices and single element slices. Language: Go. Function name: binarySearch","reference_answer":"package main\n\nfunc binarySearch(arr []int, target int) int {\n    if len(arr) == 0 {\n        return -1\n    }\n    \n    left, right := 0, len(arr)-1\n    \n    for left <= right {\n        mid := left + (right-left)/2\n        \n        if arr[mid] == target {\n            return mid\n        } else if arr[mid] < target {\n            left = mid + 1\n        } else {\n            right = mid - 1\n        }\n    }\n    \n    return -1\n}","assertions":"if binarySearch([]int{}, 5) != -1 { panic(\"Failed: empty slice\") }\nif binarySearch([]int{1}, 1) != 0 { panic(\"Failed: single element found\") }\nif binarySearch([]int{1}, 2) != -1 { panic(\"Failed: single element not found\") }\nif binarySearch([]int{1, 2, 3, 4, 5}, 3) != 2 { panic(\"Failed: middle element\") }\nif binarySearch([]int{1, 2, 3, 4, 5}, 6) != -1 { panic(\"Failed: element not in slice\") }\nif binarySearch([]int{1, 3, 5, 7, 9}, 7) != 3 { panic(\"Failed: odd length slice\") }","metadata":{"language":"Go","function_name":"binarySearch","difficulty":"medium","category":"algorithms","complexity":0.4}}
{"query_id":"synthetic-082","query_text":"Write a Go function named `mergeSort` that implements the merge sort algorithm to sort a slice of integers in ascending order. The function should use a recursive approach and return a new sorted slice without modifying the original. Language: Go. Function name: mergeSort","reference_answer":"package main\n\nfunc mergeSort(arr []int) []int {\n    if len(arr) <= 1 {\n        return append([]int(nil), arr...)\n    }\n    \n    mid := len(arr) / 2\n    left := mergeSort(arr[:mid])\n    right := mergeSort(arr[mid:])\n    \n    return merge(left, right)\n}\n\nfunc merge(left, right []int) []int {\n    result := make([]int, 0, len(left)+len(right))\n    i, j := 0, 0\n    \n    for i < len(left) && j < len(right) {\n        if left[i] <= right[j] {\n            result = append(result, left[i])\n            i++\n        } else {\n            result = append(result, right[j])\n            j++\n        }\n    }\n    \n    result = append(result, left[i:]...)\n    result = append(result, right[j:]...)\n    return result\n}","assertions":"if !equal(mergeSort([]int{}), []int{}) { panic(\"Failed: empty slice\") }\nif !equal(mergeSort([]int{1}), []int{1}) { panic(\"Failed: single element\") }\nif !equal(mergeSort([]int{3, 1, 4, 1, 5}), []int{1, 1, 3, 4, 5}) { panic(\"Failed: unsorted slice\") }\nif !equal(mergeSort([]int{5, 4, 3, 2, 1}), []int{1, 2, 3, 4, 5}) { panic(\"Failed: reverse sorted\") }\nif !equal(mergeSort([]int{1, 3, 2, 5, 4}), []int{1, 2, 3, 4, 5}) { panic(\"Failed: mixed order\") }\n\nfunc equal(a, b []int) bool {\n    if len(a) != len(b) { return false }\n    for i := range a {\n        if a[i] != b[i] { return false }\n    }\n    return true\n}","metadata":{"language":"Go","function_name":"mergeSort","difficulty":"medium","category":"algorithms","complexity":0.45}}
{"query_id":"synthetic-083","query_text":"Write a Go function named `isValidParentheses` that checks if a string containing only parentheses characters '(', ')', '{', '}', '[', ']' is valid. A string is valid if all brackets are properly closed and nested. Language: Go. Function name: isValidParentheses","reference_answer":"package main\n\nfunc isValidParentheses(s string) bool {\n    stack := make([]rune, 0)\n    bracketMap := map[rune]rune{\n        ')': '(',\n        '}': '{',\n        ']': '[',\n    }\n    \n    for _, char := range s {\n        if expected, exists := bracketMap[char]; exists {\n            if len(stack) == 0 || stack[len(stack)-1] != expected {\n                return false\n            }\n            stack = stack[:len(stack)-1]\n        } else {\n            stack = append(stack, char)\n        }\n    }\n    \n    return len(stack) == 0\n}","assertions":"if !isValidParentheses(\"\") { panic(\"Failed: empty string\") }\nif !isValidParentheses(\"()\") { panic(\"Failed: simple pair\") }\nif !isValidParentheses(\"()[]{}\") { panic(\"Failed: multiple types\") }\nif isValidParentheses(\"(]\") { panic(\"Failed: mismatched brackets\") }\nif isValidParentheses(\"([)]\") { panic(\"Failed: wrong order\") }\nif !isValidParentheses(\"{[]}\") { panic(\"Failed: nested brackets\") }\nif isValidParentheses(\"[\") { panic(\"Failed: unclosed bracket\") }\nif isValidParentheses(\"]\") { panic(\"Failed: single closing bracket\") }","metadata":{"language":"Go","function_name":"isValidParentheses","difficulty":"medium","category":"data_structures","complexity":0.4}}
{"query_id":"synthetic-084","query_text":"Write a Go function named `fibonacciMemo` that calculates the nth Fibonacci number using memoization to optimize performance. The function should handle large n values efficiently and return the result. Language: Go. Function name: fibonacciMemo","reference_answer":"package main\n\nimport \"fmt\"\n\nfunc fibonacciMemo(n int) int {\n    if n < 0 {\n        panic(\"n must be non-negative\")\n    }\n    \n    memo := make(map[int]int)\n    \n    var fib func(int) int\n    fib = func(k int) int {\n        if val, exists := memo[k]; exists {\n            return val\n        }\n        if k <= 1 {\n            return k\n        }\n        memo[k] = fib(k-1) + fib(k-2)\n        return memo[k]\n    }\n    \n    return fib(n)\n}","assertions":"if fibonacciMemo(0) != 0 { panic(\"Failed: F(0)\") }\nif fibonacciMemo(1) != 1 { panic(\"Failed: F(1)\") }\nif fibonacciMemo(2) != 1 { panic(\"Failed: F(2)\") }\nif fibonacciMemo(5) != 5 { panic(\"Failed: F(5)\") }\nif fibonacciMemo(10) != 55 { panic(\"Failed: F(10)\") }\nif fibonacciMemo(20) != 6765 { panic(\"Failed: F(20)\") }\n\ndefer func() {\n    if r := recover(); r == nil {\n        panic(\"Should have panicked for negative n\")\n    }\n}()\nfibonacciMemo(-1)","metadata":{"language":"Go","function_name":"fibonacciMemo","difficulty":"medium","category":"algorithms","complexity":0.45}}
{"query_id":"synthetic-085","query_text":"Write a Go function named `reverseLinkedList` that reverses a singly linked list. The function should take the head of the linked list as input and return the new head of the reversed list. You can assume a ListNode struct with Val and Next fields. Language: Go. Function name: reverseLinkedList","reference_answer":"package main\n\ntype ListNode struct {\n    Val  int\n    Next *ListNode\n}\n\nfunc reverseLinkedList(head *ListNode) *ListNode {\n    var prev *ListNode\n    current := head\n    \n    for current != nil {\n        next := current.Next\n        current.Next = prev\n        prev = current\n        current = next\n    }\n    \n    return prev\n}","assertions":"func createLinkedList(arr []int) *ListNode {\n    if len(arr) == 0 {\n        return nil\n    }\n    head := &ListNode{Val: arr[0]}\n    current := head\n    for _, val := range arr[1:] {\n        current.Next = &ListNode{Val: val}\n        current = current.Next\n    }\n    return head\n}\n\nfunc linkedListToSlice(head *ListNode) []int {\n    result := make([]int, 0)\n    current := head\n    for current != nil {\n        result = append(result, current.Val)\n        current = current.Next\n    }\n    return result\n}\n\nif !equal(linkedListToSlice(reverseLinkedList(createLinkedList([]int{}))), []int{}) { panic(\"Failed: empty list\") }\nif !equal(linkedListToSlice(reverseLinkedList(createLinkedList([]int{1}))), []int{1}) { panic(\"Failed: single node\") }\nif !equal(linkedListToSlice(reverseLinkedList(createLinkedList([]int{1, 2, 3}))), []int{3, 2, 1}) { panic(\"Failed: three nodes\") }\nif !equal(linkedListToSlice(reverseLinkedList(createLinkedList([]int{1, 2, 3, 4, 5}))), []int{5, 4, 3, 2, 1}) { panic(\"Failed: five nodes\") }\n\nfunc equal(a, b []int) bool {\n    if len(a) != len(b) { return false }\n    for i := range a {\n        if a[i] != b[i] { return false }\n    }\n    return true\n}","metadata":{"language":"Go","function_name":"reverseLinkedList","difficulty":"medium","category":"data_structures","complexity":0.5}}
{"query_id":"synthetic-086","query_text":"Write a Go function named `wordFrequency` that takes a string of text and returns a map with word frequencies, ignoring case and punctuation. Words should be normalized to lowercase and punctuation should be removed. Language: Go. Function name: wordFrequency","reference_answer":"package main\n\nimport (\n    \"strings\"\n    \"unicode\"\n)\n\nfunc wordFrequency(text string) map[string]int {\n    if text == \"\" {\n        return make(map[string]int)\n    }\n    \n    // Remove punctuation and convert to lowercase\n    cleaned := strings.ToLower(text)\n    var result strings.Builder\n    for _, r := range cleaned {\n        if unicode.IsLetter(r) || unicode.IsSpace(r) {\n            result.WriteRune(r)\n        } else {\n            result.WriteRune(' ')\n        }\n    }\n    \n    // Split into words and count\n    words := strings.Fields(result.String())\n    frequency := make(map[string]int)\n    \n    for _, word := range words {\n        if word != \"\" {\n            frequency[word]++\n        }\n    }\n    \n    return frequency\n}","assertions":"freq1 := wordFrequency(\"hello world\")\nif freq1[\"hello\"] != 1 || freq1[\"world\"] != 1 { panic(\"Failed: two words\") }\n\nfreq2 := wordFrequency(\"Hello, hello!\")\nif freq2[\"hello\"] != 2 { panic(\"Failed: case and punctuation\") }\n\nfreq3 := wordFrequency(\"The quick brown fox jumps over the lazy dog.\")\nif freq3[\"the\"] != 2 || freq3[\"quick\"] != 1 { panic(\"Failed: longer text\") }\n\nfreq4 := wordFrequency(\"test, test. TEST!\")\nif freq4[\"test\"] != 3 { panic(\"Failed: multiple punctuation\") }\n\nfreq5 := wordFrequency(\"\")\nif len(freq5) != 0 { panic(\"Failed: empty string\") }","metadata":{"language":"Go","function_name":"wordFrequency","difficulty":"medium","category":"algorithms","complexity":0.4}}
{"query_id":"synthetic-087","query_text":"Write a Go function named `concurrentWebCrawler` that crawls web pages concurrently with rate limiting, respecting robots.txt, and handling various error conditions. The function should return a map of URL to content. Language: Go. Function name: concurrentWebCrawler","reference_answer":"package main\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"io\"\n    \"net/http\"\n    \"strings\"\n    \"sync\"\n    \"time\"\n)\n\ntype CrawlResult struct {\n    Content string\n    Error   string\n}\n\nfunc concurrentWebCrawler(startUrls []string, maxPages int) map[string]CrawlResult {\n    results := make(map[string]CrawlResult)\n    visited := make(map[string]bool)\n    var mu sync.Mutex\n    semaphore := make(chan struct{}, 5) // Max 5 concurrent requests\n    lastRequestTime := time.Now()\n    delay := 1000 * time.Millisecond\n    \n    var wg sync.WaitGroup\n    \n    var crawl func(string)\n    crawl = func(url string) {\n        defer wg.Done()\n        \n        mu.Lock()\n        if visited[url] {\n            mu.Unlock()\n            return\n        }\n        visited[url] = true\n        mu.Unlock()\n        \n        // Rate limiting\n        elapsed := time.Since(lastRequestTime)\n        if elapsed < delay {\n            time.Sleep(delay - elapsed)\n        }\n        \n        // Acquire semaphore\n        semaphore <- struct{}{}\n        defer func() { <-semaphore }()\n        \n        // Fetch page\n        client := &http.Client{Timeout: 10 * time.Second}\n        resp, err := client.Get(url)\n        lastRequestTime = time.Now()\n        \n        if err != nil {\n            mu.Lock()\n            results[url] = CrawlResult{Error: err.Error()}\n            mu.Unlock()\n            return\n        }\n        defer resp.Body.Close()\n        \n        if resp.StatusCode != 200 {\n            mu.Lock()\n            results[url] = CrawlResult{Error: fmt.Sprintf(\"HTTP %d\", resp.StatusCode)}\n            mu.Unlock()\n            return\n        }\n        \n        body, err := io.ReadAll(resp.Body)\n        if err != nil {\n            mu.Lock()\n            results[url] = CrawlResult{Error: err.Error()}\n            mu.Unlock()\n            return\n        }\n        \n        mu.Lock()\n        results[url] = CrawlResult{Content: string(body)}\n        mu.Unlock()\n    }\n    \n    // Start crawling\n    for _, url := range startUrls {\n        if len(results) >= maxPages {\n            break\n        }\n        wg.Add(1)\n        go crawl(url)\n    }\n    \n    wg.Wait()\n    return results\n}","assertions":"results := concurrentWebCrawler([]string{\"https://invalid-domain-12345.com\", \"https://another-invalid-url.com\"}, 2)\n\nif len(results) != 2 {\n    panic(\"Should return results for all URLs\")\n}\n\nfor url, result := range results {\n    if strings.Contains(url, \"invalid\") {\n        if result.Content != \"\" || result.Error == \"\" {\n            panic(fmt.Sprintf(\"Invalid URL %s should have error\", url))\n        }\n    }\n}","metadata":{"language":"Go","function_name":"concurrentWebCrawler","difficulty":"advanced","category":"concurrency","complexity":0.8}}
{"query_id":"synthetic-088","query_text":"Write a Rust function named `binary_search` that implements binary search on a sorted vector of integers. The function should return the index of the target element if found, or None if not found. Handle edge cases like empty vectors and single element vectors. Language: Rust. Function name: binary_search","reference_answer":"fn binary_search(arr: &[i32], target: i32) -> Option<usize> {\n    if arr.is_empty() {\n        return None;\n    }\n    \n    let mut left = 0;\n    let mut right = arr.len() - 1;\n    \n    while left <= right {\n        let mid = left + (right - left) / 2;\n        \n        if arr[mid] == target {\n            return Some(mid);\n        } else if arr[mid] < target {\n            left = mid + 1;\n        } else {\n            right = mid.saturating_sub(1);\n        }\n    }\n    \n    None\n}","assertions":"assert_eq!(binary_search(&[], 5), None);\nassert_eq!(binary_search(&[1], 1), Some(0));\nassert_eq!(binary_search(&[1], 2), None);\nassert_eq!(binary_search(&[1, 2, 3, 4, 5], 3), Some(2));\nassert_eq!(binary_search(&[1, 2, 3, 4, 5], 6), None);\nassert_eq!(binary_search(&[1, 3, 5, 7, 9], 7), Some(3));","metadata":{"language":"Rust","function_name":"binary_search","difficulty":"medium","category":"algorithms","complexity":0.4}}
{"query_id":"synthetic-089","query_text":"Write a Rust function named `merge_sort` that implements the merge sort algorithm to sort a vector of integers in ascending order. The function should use a recursive approach and return a new sorted vector without modifying the original. Language: Rust. Function name: merge_sort","reference_answer":"fn merge_sort(arr: &[i32]) -> Vec<i32> {\n    if arr.len() <= 1 {\n        return arr.to_vec();\n    }\n    \n    let mid = arr.len() / 2;\n    let left = merge_sort(&arr[..mid]);\n    let right = merge_sort(&arr[mid..]);\n    \n    merge(&left, &right)\n}\n\nfn merge(left: &[i32], right: &[i32]) -> Vec<i32> {\n    let mut result = Vec::with_capacity(left.len() + right.len());\n    let mut i = 0;\n    let mut j = 0;\n    \n    while i < left.len() && j < right.len() {\n        if left[i] <= right[j] {\n            result.push(left[i]);\n            i += 1;\n        } else {\n            result.push(right[j]);\n            j += 1;\n        }\n    }\n    \n    result.extend_from_slice(&left[i..]);\n    result.extend_from_slice(&right[j..]);\n    result\n}","assertions":"assert_eq!(merge_sort(&[]), Vec::<i32>::new());\nassert_eq!(merge_sort(&[1]), vec![1]);\nassert_eq!(merge_sort(&[3, 1, 4, 1, 5]), vec![1, 1, 3, 4, 5]);\nassert_eq!(merge_sort(&[5, 4, 3, 2, 1]), vec![1, 2, 3, 4, 5]);\nassert_eq!(merge_sort(&[1, 3, 2, 5, 4]), vec![1, 2, 3, 4, 5]);","metadata":{"language":"Rust","function_name":"merge_sort","difficulty":"medium","category":"algorithms","complexity":0.45}}
{"query_id":"synthetic-090","query_text":"Write a Rust function named `is_valid_parentheses` that checks if a string containing only parentheses characters '(', ')', '{', '}', '[', ']' is valid. A string is valid if all brackets are properly closed and nested. Language: Rust. Function name: is_valid_parentheses","reference_answer":"fn is_valid_parentheses(s: &str) -> bool {\n    let mut stack = Vec::new();\n    let bracket_map = std::collections::HashMap::from([\n        (')', '('),\n        ('}', '{'),\n        (']', '['),\n    ]);\n    \n    for ch in s.chars() {\n        if let Some(&expected) = bracket_map.get(&ch) {\n            if stack.last() != Some(&expected) {\n                return false;\n            }\n            stack.pop();\n        } else {\n            stack.push(ch);\n        }\n    }\n    \n    stack.is_empty()\n}","assertions":"assert_eq!(is_valid_parentheses(\"\"), true);\nassert_eq!(is_valid_parentheses(\"()\"), true);\nassert_eq!(is_valid_parentheses(\"()[]{}\"), true);\nassert_eq!(is_valid_parentheses(\"(]\"), false);\nassert_eq!(is_valid_parentheses(\"([)]\"), false);\nassert_eq!(is_valid_parentheses(\"{[]}\"), true);\nassert_eq!(is_valid_parentheses(\"[\"), false);\nassert_eq!(is_valid_parentheses(\"]\"), false);","metadata":{"language":"Rust","function_name":"is_valid_parentheses","difficulty":"medium","category":"data_structures","complexity":0.4}}
{"query_id":"synthetic-091","query_text":"Write a Java function named `binarySearch` that implements binary search on a sorted array of integers. The function should return the index of the target element if found, or -1 if not found. Handle edge cases like empty arrays and single element arrays. Language: Java. Function name: binarySearch","reference_answer":"public class Main {\n    public static int binarySearch(int[] arr, int target) {\n        if (arr == null || arr.length == 0) {\n            return -1;\n        }\n        \n        int left = 0;\n        int right = arr.length - 1;\n        \n        while (left <= right) {\n            int mid = left + (right - left) / 2;\n            \n            if (arr[mid] == target) {\n                return mid;\n            } else if (arr[mid] < target) {\n                left = mid + 1;\n            } else {\n                right = mid - 1;\n            }\n        }\n        \n        return -1;\n    }\n}","assertions":"assert binarySearch(new int[]{}, 5) == -1;\nassert binarySearch(new int[]{1}, 1) == 0;\nassert binarySearch(new int[]{1}, 2) == -1;\nassert binarySearch(new int[]{1, 2, 3, 4, 5}, 3) == 2;\nassert binarySearch(new int[]{1, 2, 3, 4, 5}, 6) == -1;\nassert binarySearch(new int[]{1, 3, 5, 7, 9}, 7) == 3;","metadata":{"language":"Java","function_name":"binarySearch","difficulty":"medium","category":"algorithms","complexity":0.4}}
{"query_id":"synthetic-092","query_text":"Write a JavaScript function named `mergeSort` that implements the merge sort algorithm to sort an array of numbers in ascending order. The function should use a recursive approach and return a new sorted array without modifying the original. Language: JavaScript. Function name: mergeSort","reference_answer":"function mergeSort(arr) {\n    if (arr.length <= 1) {\n        return [...arr];\n    }\n    \n    const mid = Math.floor(arr.length / 2);\n    const left = mergeSort(arr.slice(0, mid));\n    const right = mergeSort(arr.slice(mid));\n    \n    return merge(left, right);\n}\n\nfunction merge(left, right) {\n    const result = [];\n    let i = 0;\n    let j = 0;\n    \n    while (i < left.length && j < right.length) {\n        if (left[i] <= right[j]) {\n            result.push(left[i]);\n            i++;\n        } else {\n            result.push(right[j]);\n            j++;\n        }\n    }\n    \n    return result.concat(left.slice(i)).concat(right.slice(j));\n}","assertions":"if (JSON.stringify(mergeSort([])) !== JSON.stringify([])) throw new Error('Failed: empty array');\nif (JSON.stringify(mergeSort([1])) !== JSON.stringify([1])) throw new Error('Failed: single element');\nif (JSON.stringify(mergeSort([3, 1, 4, 1, 5])) !== JSON.stringify([1, 1, 3, 4, 5])) throw new Error('Failed: unsorted array');\nif (JSON.stringify(mergeSort([5, 4, 3, 2, 1])) !== JSON.stringify([1, 2, 3, 4, 5])) throw new Error('Failed: reverse sorted');\nif (JSON.stringify(mergeSort([1, 3, 2, 5, 4])) !== JSON.stringify([1, 2, 3, 4, 5])) throw new Error('Failed: mixed order');","metadata":{"language":"JavaScript","function_name":"mergeSort","difficulty":"medium","category":"algorithms","complexity":0.45}}
{"query_id":"synthetic-093","query_text":"Write a C++ function named `isValidParentheses` that checks if a string containing only parentheses characters '(', ')', '{', '}', '[', ']' is valid. A string is valid if all brackets are properly closed and nested. Language: C++. Function name: isValidParentheses","reference_answer": "#include <string>\n#include <stack>\n#include <unordered_map>\n\nbool isValidParentheses(std::string s) {\n    std::stack<char> stk;\n    std::unordered_map<char, char> bracket_map = {\n        {')', '('},\n        {'}', '{'},\n        {']', '['}\n    };\n    \n    for (char ch : s) {\n        auto it = bracket_map.find(ch);\n        if (it != bracket_map.end()) {\n            if (stk.empty() || stk.top() != it->second) {\n                return false;\n            }\n            stk.pop();\n        } else {\n            stk.push(ch);\n        }\n    }\n    \n    return stk.empty();\n}","assertions":"assert(isValidParentheses(\"\") == true);\nassert(isValidParentheses(\"()\") == true);\nassert(isValidParentheses(\"()[]{}\") == true);\nassert(isValidParentheses(\"(]\") == false);\nassert(isValidParentheses(\"([)]\") == false);\nassert(isValidParentheses(\"{[]}\") == true);\nassert(isValidParentheses(\"[\") == false);\nassert(isValidParentheses(\"]\") == false);","metadata":{"language":"C++","function_name":"isValidParentheses","difficulty":"medium","category":"data_structures","complexity":0.4}}
{"query_id":"synthetic-094","query_text":"Write a Ruby function named `fibonacci_memo` that calculates the nth Fibonacci number using memoization to optimize performance. The function should handle large n values efficiently and return the result. Language: Ruby. Function name: fibonacci_memo","reference_answer":"def fibonacci_memo(n)\n  raise ArgumentError, 'n must be non-negative' if n < 0\n  \n  memo = {}\n  \n  fib = lambda do |k|\n    return memo[k] if memo.key?(k)\n    return k if k <= 1\n    memo[k] = fib.call(k - 1) + fib.call(k - 2)\n  end\n  \n  fib.call(n)\nend","assertions":"raise 'Failed: F(0)' unless fibonacci_memo(0) == 0\nraise 'Failed: F(1)' unless fibonacci_memo(1) == 1\nraise 'Failed: F(2)' unless fibonacci_memo(2) == 1\nraise 'Failed: F(5)' unless fibonacci_memo(5) == 5\nraise 'Failed: F(10)' unless fibonacci_memo(10) == 55\nraise 'Failed: F(20)' unless fibonacci_memo(20) == 6765\n\nbegin\n  fibonacci_memo(-1)\n  raise 'Should have raised ArgumentError for negative n'\nrescue ArgumentError\n  # Expected\nend","metadata":{"language":"Ruby","function_name":"fibonacci_memo","difficulty":"medium","category":"algorithms","complexity":0.45}}
{"query_id":"synthetic-095","query_text":"Write a Swift function named `reverseLinkedList` that reverses a singly linked list. The function should take the head of the linked list as input and return the new head of the reversed list. You can assume a ListNode class with val and next properties. Language: Swift. Function name: reverseLinkedList","reference_answer":"class ListNode {\n    var val: Int\n    var next: ListNode?\n    \n    init(_ val: Int) {\n        self.val = val\n        self.next = nil\n    }\n}\n\nfunc reverseLinkedList(_ head: ListNode?) -> ListNode? {\n    var prev: ListNode? = nil\n    var current = head\n    \n    while current != nil {\n        let next = current?.next\n        current?.next = prev\n        prev = current\n        current = next\n    }\n    \n    return prev\n}","assertions":"func createLinkedList(_ arr: [Int]) -> ListNode? {\n    guard !arr.isEmpty else { return nil }\n    let head = ListNode(arr[0])\n    var current = head\n    for val in arr[1...] {\n        current.next = ListNode(val)\n        current = current.next!\n    }\n    return head\n}\n\nfunc linkedListToArray(_ head: ListNode?) -> [Int] {\n    var result: [Int] = []\n    var current = head\n    while current != nil {\n        result.append(current!.val)\n        current = current!.next\n    }\n    return result\n}\n\nassert(linkedListToArray(reverseLinkedList(createLinkedList([]))) == [])\nassert(linkedListToArray(reverseLinkedList(createLinkedList([1]))) == [1])\nassert(linkedListToArray(reverseLinkedList(createLinkedList([1, 2, 3]))) == [3, 2, 1])\nassert(linkedListToArray(reverseLinkedList(createLinkedList([1, 2, 3, 4, 5]))) == [5, 4, 3, 2, 1])","metadata":{"language":"Swift","function_name":"reverseLinkedList","difficulty":"medium","category":"data_structures","complexity":0.5}}
{"query_id":"synthetic-096","query_text":"Write a Kotlin function named `wordFrequency` that takes a string of text and returns a map with word frequencies, ignoring case and punctuation. Words should be normalized to lowercase and punctuation should be removed. Language: Kotlin. Function name: wordFrequency","reference_answer":"fun wordFrequency(text: String): Map<String, Int> {\n    if (text.isEmpty()) {\n        return emptyMap()\n    }\n    \n    // Remove punctuation and convert to lowercase\n    val cleanedText = text.toLowerCase().replace(Regex(\"[^\\\\w\\\\s]\"), \" \")\n    \n    // Split into words and count\n    val words = cleanedText.split(Regex(\"\\\\s+\")).filter { it.isNotEmpty() }\n    val frequency = mutableMapOf<String, Int>()\n    \n    for (word in words) {\n        frequency[word] = frequency.getOrDefault(word, 0) + 1\n    }\n    \n    return frequency\n}","assertions":"val freq1 = wordFrequency(\"hello world\")\nassert(freq1[\"hello\"] == 1 && freq1[\"world\"] == 1)\n\nval freq2 = wordFrequency(\"Hello, hello!\")\nassert(freq2[\"hello\"] == 2)\n\nval freq3 = wordFrequency(\"The quick brown fox jumps over the lazy dog.\")\nassert(freq3[\"the\"] == 2 && freq3[\"quick\"] == 1)\n\nval freq4 = wordFrequency(\"test, test. TEST!\")\nassert(freq4[\"test\"] == 3)\n\nval freq5 = wordFrequency(\"\")\nassert(freq5.isEmpty())","metadata":{"language":"Kotlin","function_name":"wordFrequency","difficulty":"medium","category":"algorithms","complexity":0.4}}
{"query_id":"synthetic-097","query_text":"Write a C# function named `isValidParentheses` that checks if a string containing only parentheses characters '(', ')', '{', '}', '[', ']' is valid. A string is valid if all brackets are properly closed and nested. Language: C#. Function name: isValidParentheses","reference_answer":"using System;\nusing System.Collections.Generic;\n\npublic class Program {\n    public static bool IsValidParentheses(string s) {\n        Stack<char> stack = new Stack<char>();\n        Dictionary<char, char> bracketMap = new Dictionary<char, char> {\n            {')', '('},\n            {'}', '{'},\n            {']', '['}\n        };\n        \n        foreach (char ch in s) {\n            if (bracketMap.ContainsKey(ch)) {\n                char expected = bracketMap[ch];\n                if (stack.Count == 0 || stack.Peek() != expected) {\n                    return false;\n                }\n                stack.Pop();\n            } else {\n                stack.Push(ch);\n            }\n        }\n        \n        return stack.Count == 0;\n    }\n}","assertions":"Debug.Assert(IsValidParentheses(\"\") == true);\nDebug.Assert(IsValidParentheses(\"()\") == true);\nDebug.Assert(IsValidParentheses(\"()[]{}\") == true);\nDebug.Assert(IsValidParentheses(\"(]\") == false);\nDebug.Assert(IsValidParentheses(\"([)]\") == false);\nDebug.Assert(IsValidParentheses(\"{[]}\") == true);\nDebug.Assert(IsValidParentheses(\"[\") == false);\nDebug.Assert(IsValidParentheses(\"]\") == false);","metadata":{"language":"C#","function_name":"isValidParentheses","difficulty":"medium","category":"data_structures","complexity":0.4}}
{"query_id":"synthetic-098","query_text":"Write a PHP function named `fibonacciMemo` that calculates the nth Fibonacci number using memoization to optimize performance. The function should handle large n values efficiently and return the result. Language: PHP. Function name: fibonacciMemo","reference_answer":"<?php\nfunction fibonacciMemo($n) {\n    if ($n < 0) {\n        throw new InvalidArgumentException('n must be non-negative');\n    }\n    \n    $memo = [];\n    \n    $fib = function($k) use (&$memo, &$fib) {\n        if (isset($memo[$k])) {\n            return $memo[$k];\n        }\n        if ($k <= 1) {\n            return $k;\n        }\n        $memo[$k] = $fib($k - 1) + $fib($k - 2);\n        return $memo[$k];\n    };\n    \n    return $fib($n);\n}\n?>","assertions":"assert(fibonacciMemo(0) == 0);\nassert(fibonacciMemo(1) == 1);\nassert(fibonacciMemo(2) == 1);\nassert(fibonacciMemo(5) == 5);\nassert(fibonacciMemo(10) == 55);\nassert(fibonacciMemo(20) == 6765);\n\ntry {\n    fibonacciMemo(-1);\n    assert(false, 'Should have thrown exception for negative n');\n} catch (InvalidArgumentException $e) {\n    // Expected\n}","metadata":{"language":"PHP","function_name":"fibonacciMemo","difficulty":"medium","category":"algorithms","complexity":0.45}}
{"query_id":"synthetic-099","query_text":"Write a Scala function named `mergeSort` that implements the merge sort algorithm to sort a list of integers in ascending order. The function should use a recursive approach and return a new sorted list without modifying the original. Language: Scala. Function name: mergeSort","reference_answer":"object Main {\n  def mergeSort(arr: List[Int]): List[Int] = {\n    if (arr.length <= 1) {\n      return arr\n    }\n    \n    val mid = arr.length / 2\n    val left = mergeSort(arr.take(mid))\n    val right = mergeSort(arr.drop(mid))\n    \n    merge(left, right)\n  }\n  \n  def merge(left: List[Int], right: List[Int]): List[Int] = {\n    @scala.annotation.tailrec\n    def mergeHelper(l: List[Int], r: List[Int], acc: List[Int]): List[Int] = (l, r) match {\n      case (Nil, _) => acc.reverse ++ r\n      case (_, Nil) => acc.reverse ++ l\n      case (lh :: lt, rh :: rt) =>\n        if (lh <= rh) mergeHelper(lt, r, lh :: acc)\n        else mergeHelper(l, rt, rh :: acc)\n    }\n    \n    mergeHelper(left, right, Nil)\n  }\n}","assertions":"assert(mergeSort(List()) == List())\nassert(mergeSort(List(1)) == List(1))\nassert(mergeSort(List(3, 1, 4, 1, 5)) == List(1, 1, 3, 4, 5))\nassert(mergeSort(List(5, 4, 3, 2, 1)) == List(1, 2, 3, 4, 5))\nassert(mergeSort(List(1, 3, 2, 5, 4)) == List(1, 2, 3, 4, 5))","metadata":{"language":"Scala","function_name":"mergeSort","difficulty":"medium","category":"algorithms","complexity":0.45}}
{"query_id":"synthetic-100","query_text":"Write a Haskell function named `isValidParentheses` that checks if a string containing only parentheses characters '(', ')', '{', '}', '[', ']' is valid. A string is valid if all brackets are properly closed and nested. Language: Haskell. Function name: isValidParentheses","reference_answer":"isValidParentheses :: String -> Bool\nisValidParentheses s = go s []\n  where\n    go [] [] = True\n    go [] _ = False\n    go (x:xs) stack\n      | x == '(' = go xs ('(':stack)\n      | x == '{' = go xs ('{':stack)\n      | x == '[' = go xs ('[':stack)\n      | x == ')' = checkStack stack '(' xs\n      | x == '}' = checkStack stack '{' xs\n      | x == ']' = checkStack stack '[' xs\n      | otherwise = go xs stack\n    \n    checkStack [] _ _ = False\n    checkStack (top:rest) expected xs\n      | top == expected = go xs rest\n      | otherwise = False","assertions":"main = do\n    assert (isValidParentheses \"\") True \"empty string\"\n    assert (isValidParentheses \"()\") True \"simple pair\"\n    assert (isValidParentheses \"()[]{}\") True \"multiple types\"\n    assert (isValidParentheses \"(]\") False \"mismatched brackets\"\n    assert (isValidParentheses \"([)]\") False \"wrong order\"\n    assert (isValidParentheses \"{[]}\") True \"nested brackets\"\n    assert (isValidParentheses \"[\") False \"unclosed bracket\"\n    assert (isValidParentheses \"]\") False \"single closing bracket\"\n\nassert :: Bool -> Bool -> String -> IO ()\nassert actual expected msg =\n    if actual == expected\n        then putStrLn (\" \" ++ msg)\n        else error (\" \" ++ msg ++ \": expected \" ++ show expected ++ \", got \" ++ show actual)","metadata":{"language":"Haskell","function_name":"isValidParentheses","difficulty":"medium","category":"data_structures","complexity":0.4}}
